{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "def pytorch3d_to_trimesh(p3d_mesh):\n",
    "    # Get vertices and faces from the PyTorch3D mesh\n",
    "    vertices = p3d_mesh.verts_packed().detach().cpu().numpy()\n",
    "    faces = p3d_mesh.faces_packed().detach().cpu().numpy()\n",
    "\n",
    "    # Create a Trimesh object\n",
    "    return trimesh.Trimesh(vertices=vertices, faces=faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed volumes: tensor([0.0833, 0.0833])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Dummy source class to mock required methods\n",
    "class DummySource:\n",
    "    def __init__(self, num_verts_per_mesh, faces_packed, faces_packed_to_mesh_idx):\n",
    "        self._num_verts_per_mesh = num_verts_per_mesh\n",
    "        self._faces_packed = faces_packed\n",
    "        self._faces_packed_to_mesh_idx = faces_packed_to_mesh_idx\n",
    "\n",
    "    def num_verts_per_mesh(self):\n",
    "        return self._num_verts_per_mesh\n",
    "\n",
    "    def faces_packed(self):\n",
    "        return self._faces_packed\n",
    "\n",
    "    def faces_packed_to_mesh_idx(self):\n",
    "        return self._faces_packed_to_mesh_idx\n",
    "\n",
    "    def num_faces_per_mesh(self):\n",
    "        return torch.tensor([len(self._faces_packed) // len(self._num_verts_per_mesh)] * len(self._num_verts_per_mesh))\n",
    "\n",
    "    def mesh_to_faces_packed_first_idx(self):\n",
    "        return torch.cumsum(torch.tensor([0] + self.num_faces_per_mesh().tolist()[:-1]), dim=0)\n",
    "\n",
    "# Define batch size and varying number of vertices per mesh\n",
    "num_verts_per_mesh = torch.tensor([8, 4])  # Mesh 1 has 5 verts, Mesh 2 has 3 verts\n",
    "\n",
    "verts = torch.tensor([\n",
    "    [-0.5, -0.5, -0.5],  # 0\n",
    "    [ 0.5, -0.5, -0.5],  # 1\n",
    "    [ 0.5,  0.5, -0.5],  # 2\n",
    "    [-0.5,  0.5, -0.5],  # 3\n",
    "    [-0.5, -0.5,  0.5],  # 4\n",
    "    [ 0.5, -0.5,  0.5],  # 5\n",
    "    [ 0.5,  0.5,  0.5],  # 6\n",
    "    [-0.5,  0.5,  0.5]   # 7\n",
    "], dtype=torch.float32)\n",
    "faces = torch.tensor([\n",
    "    [0, 2, 1], [0, 3, 2],  # Front\n",
    "    [1, 6, 5], [1, 2, 6],  # Right\n",
    "    [5, 7, 4], [5, 6, 7],  # Back\n",
    "    [4, 3, 0], [4, 7, 3],  # Left\n",
    "    [3, 6, 2], [3, 7, 6],  # Top\n",
    "    [4, 1, 5], [4, 0, 1]   # Bottom\n",
    "], dtype=torch.int64)\n",
    "\n",
    "verts2 = torch.tensor([\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [0,1,0], \n",
    "    [0,0,0]], dtype=torch.float32)\n",
    "faces2 = torch.tensor([\n",
    "    [3, 1, 2],\n",
    "    [3, 1, 0],\n",
    "    [3, 0, 2],\n",
    "    [0, 1, 2]\n",
    "], dtype=torch.int64)\n",
    "\n",
    "# Pad sequences to match the batch shape (B, max Vi, 3)\n",
    "y = pad_sequence([verts, verts2], batch_first=True)\n",
    "# Define face indices assuming the first mesh has faces [(0,1,2), (1,2,3)] and second has [(0,1,2)]\n",
    "faces_packed = torch.cat([faces, faces2])\n",
    "\n",
    "# Face-to-mesh mapping (0 for first mesh, 1 for second)\n",
    "faces_packed_to_mesh_idx = torch.tensor([0] * 12 + [1] * 4)\n",
    "\n",
    "# Create a dummy source object\n",
    "dummy_src = DummySource(num_verts_per_mesh, faces_packed, faces_packed_to_mesh_idx)\n",
    "\n",
    "# Define a dummy class with the method\n",
    "class DummyClass:\n",
    "    def __init__(self, src):\n",
    "        self.src = src\n",
    "\n",
    "    def equality_constraints(self, xs, y, scatter_add=True):\n",
    "        # Original function here\n",
    "        n_batches = len(self.src.num_verts_per_mesh())\n",
    "\n",
    "        lengths = self.src.num_verts_per_mesh()\n",
    "        sorted_lengths, sort_indices = torch.sort(lengths, descending=True)\n",
    "        y_sorted = y[sort_indices]  # Reorder y to match sorted order\n",
    "        y_packed_seq = torch.nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_lengths, batch_first=True)\n",
    "\n",
    "        # Later, unsort if necessary\n",
    "        verts_packed = y_packed_seq.data\n",
    "\n",
    "        faces_packed = self.src.faces_packed()  # (sum(F_i), 3)\n",
    "        face_vertices = verts_packed[faces_packed]  # (sum(F_i), 3, 3)\n",
    "\n",
    "        v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "        cross_product = torch.cross(v0, v1, dim=-1)  # (F, 3)\n",
    "        face_volumes = torch.sum(cross_product * v2, dim=-1) / 6.0  # (F,)\n",
    "        volumes = torch.zeros(n_batches, device=verts_packed.device, dtype=face_volumes.dtype)\n",
    "        \n",
    "        if scatter_add:\n",
    "            volumes.scatter_add_(0, self.src.faces_packed_to_mesh_idx(), face_volumes)\n",
    "        else:\n",
    "            n_faces_per_mesh = self.src.num_faces_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_face = self.src.mesh_to_faces_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_face[i]\n",
    "                end = start + n_faces_per_mesh[i]\n",
    "                volumes[i] = face_volumes[start:end].sum()  # Sum over all faces\n",
    "\n",
    "        volumes = volumes.abs()\n",
    "        return volumes  # Shape: (B,)\n",
    "\n",
    "# Instantiate and test\n",
    "dummy_instance = DummyClass(dummy_src)\n",
    "xs_placeholder = torch.zeros_like(y)  # Placeholder tensor\n",
    "\n",
    "volumes = dummy_instance.equality_constraints(xs_placeholder, y)\n",
    "print(\"Computed volumes:\", volumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_constraints(self, xs: torch.Tensor, y: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Enforces volume constraint\n",
    "    Assumes same number of vertices in each projected mesh currently\n",
    "\n",
    "    Args:\n",
    "        xs (tensor): vertices of original mesh, B x V x 3\n",
    "        y (tensor): vertices of projected mesh, B x V x 3\n",
    "    \"\"\"\n",
    "    n_batches = len(xs)\n",
    "    verts = y.view(n_batches,-1,3) # (B, V, 3)\n",
    "\n",
    "    faces = self.src.faces_padded().view(n_batches, -1, 3).detach()  # (B, max F_i, 3)\n",
    "    _, n_faces, _ = faces.size()\n",
    "    batch_indices = torch.arange(n_batches)[:, None, None].expand(-1, n_faces, 3).detach() # detached\n",
    "\n",
    "    face_vertices = verts[batch_indices, faces]  # (B, F, 3, 3)\n",
    "    # Calculate volume\n",
    "    v0, v1, v2 = face_vertices[:, :, 0, :], face_vertices[:, :, 1, :], face_vertices[:, :, 2, :]\n",
    "    cross = torch.cross(v1, v2, dim=-1)  # (B, F, 3)\n",
    "    face_volumes = torch.einsum('bfi,bfi->bf', v0, cross) / 6.0  # (B, F)\n",
    "\n",
    "    volumes = torch.sum(face_volumes, dim=1).abs() # (B,)\n",
    "    return volumes  # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signed_tet_volume(face_vertices: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute signed tetrahedron volumes for a batch of faces.\n",
    "\n",
    "    Args:\n",
    "        face_vertices (torch.Tensor): Tensor of shape (F, 3, 3), where\n",
    "                                      F is the number of faces, and each face\n",
    "                                      consists of 3 vertices in 3D.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (F,) containing signed volumes.\n",
    "    \"\"\"\n",
    "    v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "    \n",
    "    # Compute determinant of the 3x3 matrix [v0, v1, v2]\n",
    "    volumes = torch.det(torch.stack([v0, v1, v2], dim=-1)) / 6.0  # Shape: (F,)\n",
    "\n",
    "    return volumes\n",
    "\n",
    "def get_volume_batch(meshes: Meshes):\n",
    "    verts_packed = meshes.verts_packed()  # (sum(V_i), 3)\n",
    "    faces_packed = meshes.faces_packed()  # (sum(F_i), 3)\n",
    "    mesh_to_face = meshes.mesh_to_faces_packed_first_idx()  # Index of first face per mesh\n",
    "    n_meshes = len(meshes)\n",
    "    volumes = torch.zeros(n_meshes, device=verts_packed.device)\n",
    "\n",
    "    for i in range(n_meshes):\n",
    "        start = mesh_to_face[i]\n",
    "        end = start + meshes.num_faces_per_mesh()[i]\n",
    "        face_vertices = verts_packed[faces_packed[start:end]]  # (F, 3, 3)\n",
    "        volumes[i] = get_signed_tet_volume(face_vertices).sum()  # Sum over all faces\n",
    "\n",
    "    return volumes.abs()  # Returns a tensor of shape (num_meshes,)\n",
    "\n",
    "def least_squares(u0, target):\n",
    "    \"\"\"\n",
    "    u0 are vertices\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(u0):\n",
    "        u0 = torch.tensor(u0)\n",
    "    if not torch.is_tensor(target):\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "    res = torch.square(u0 - target).sum()\n",
    "    print(\"lstsq\", res)\n",
    "    return res.double()\n",
    "\n",
    "def least_squares_grad(u0, target):\n",
    "    if torch.is_tensor(u0):\n",
    "        u0 = u0.detach().clone()\n",
    "    else:\n",
    "        u0 = torch.tensor(u0)\n",
    "        \n",
    "    if torch.is_tensor(target):\n",
    "        target = target.detach().clone()\n",
    "    else:\n",
    "        target = torch.tensor(target)\n",
    "        \n",
    "    # Ensure that u0 requires gradients\n",
    "    u0.requires_grad = True\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        res = torch.square(u0 - target).sum()\n",
    "\n",
    "    # Compute the gradient\n",
    "    obj_grad = torch.autograd.grad(res, u0)[0]\n",
    "    print(\"obj_grad\", obj_grad)\n",
    "    return obj_grad.double()\n",
    "\n",
    "def get_volume(u, faces, init_vol):\n",
    "    if not torch.is_tensor(u):\n",
    "        u = torch.tensor(u)\n",
    "    if not torch.is_tensor(faces):\n",
    "        faces = torch.tensor(faces)\n",
    "    if not torch.is_tensor(init_vol):\n",
    "        init_vol = torch.tensor(init_vol)\n",
    "    \n",
    "    vertices = u.view(-1,3)\n",
    "    face_vertices = vertices[faces]  # (F, 3, 3)\n",
    "    volume = get_signed_tet_volume(face_vertices).sum()\n",
    "    res = volume.abs() - init_vol\n",
    "    print(\"vol\", res)\n",
    "    return res.double()\n",
    "\n",
    "def get_volume_grad(u, faces, init_vol):\n",
    "    if not torch.is_tensor(u):\n",
    "        u = torch.tensor(u, dtype=torch.float64, requires_grad=True)\n",
    "    else:\n",
    "        u = u.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    if not torch.is_tensor(faces):\n",
    "        faces = torch.tensor(faces, dtype=torch.long)\n",
    "    \n",
    "    if not torch.is_tensor(init_vol):\n",
    "        init_vol = torch.tensor(init_vol, dtype=torch.float64)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        vertices = u.view(-1, 3)\n",
    "        face_vertices = vertices[faces]  # (F, 3, 3)\n",
    "        volume = get_signed_tet_volume(face_vertices).sum()\n",
    "        res = volume.abs() - init_vol\n",
    "    \n",
    "    volume_grad = torch.autograd.grad(res, u, retain_graph=True)[0]\n",
    "    print(\"volume grad\", volume_grad)\n",
    "    \n",
    "    return volume_grad.double()\n",
    "\n",
    "def project(meshes: Meshes, targets: Meshes):\n",
    "    n_batches = len(meshes)\n",
    "    n_vtxs = len(meshes[0].verts_packed())\n",
    "    results = torch.zeros(n_batches, n_vtxs, 3, dtype=torch.double)\n",
    "    losses = torch.zeros(n_batches, 1, dtype=torch.double)\n",
    "    for batch_number, mesh in enumerate(meshes):\n",
    "        init_vol = get_volume_batch(mesh).double().detach().cpu().numpy()\n",
    "        print(\"batch number\", batch_number)\n",
    "        vertices = mesh.verts_packed().flatten().detach().numpy().astype(np.float64)\n",
    "        faces = mesh.faces_packed().detach().numpy().astype(np.int64)\n",
    "        target_vtx = targets[batch_number].verts_packed().flatten().detach().numpy().astype(np.float64)\n",
    "        eq_const = {\n",
    "            'type': 'eq',\n",
    "            'fun' : lambda u: get_volume(u, faces, init_vol).cpu().numpy().astype(np.float64),\n",
    "            'jac' : lambda u: get_volume_grad(u, faces, init_vol).cpu().numpy().astype(np.float64)\n",
    "        }\n",
    "        print(\"starting optimisation\")\n",
    "        res = opt.minimize(\n",
    "            lambda u: least_squares(u, target_vtx).detach().cpu().numpy().astype(np.float64),\n",
    "            vertices, \n",
    "            jac=lambda u: least_squares_grad(u, target_vtx).cpu().numpy().astype(np.float64),\n",
    "            method='SLSQP', \n",
    "            constraints=[eq_const],\n",
    "            options={'ftol': 1e-4, 'disp': True, 'maxiter': 100}\n",
    "        )   \n",
    "        print(\"finished\")\n",
    "        if not res.success:\n",
    "            print(\"FIT failed:\", res.message)\n",
    "        results[batch_number] = torch.tensor(res.x, dtype=torch.double, requires_grad=True).view(-1,3)\n",
    "        losses[batch_number] = torch.tensor(res.fun, dtype=torch.double, requires_grad=False)\n",
    "    return results, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n",
      "Chamfer Distance: 0.028457235544919968\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_points = 25\n",
    "dim = 2\n",
    "\n",
    "# Generate two random batches of point clouds\n",
    "x = torch.rand((batch_size,num_points, dim))  # (N, P1, D)\n",
    "y = torch.rand((batch_size,num_points, dim))  # (N, P2, D)\n",
    "\n",
    "print(x.dtype, y.dtype)\n",
    "\n",
    "# Compute Chamfer distance\n",
    "loss, _ = chamfer_distance(x, y)\n",
    "print(\"Chamfer Distance:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.66666667e-01  5.39323902e-18  0.00000000e+00]\n",
      " [ 1.65108562e-17  1.33333333e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00]]\n",
      "[[ 1.50000000e+00 -6.06739390e-18  0.00000000e+00]\n",
      " [-1.85747132e-17  7.50000000e-01  0.00000000e+00]\n",
      " [-0.00000000e+00 -0.00000000e+00 -1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "# P = np.array([[1,0,0,0],\n",
    "#               [0,1,0,0],\n",
    "#               [0,0,0,1]])\n",
    "\n",
    "P = np.array([[-1/sqrt(2),1/sqrt(2),0,0],\n",
    "              [-1/sqrt(6),-1/sqrt(6),2/sqrt(6),0],\n",
    "              [0,0,0,1]])\n",
    "\n",
    "# P = np.array([[-1/sqrt(5),2/sqrt(5),0,0],\n",
    "#               [-2/sqrt(30),-1/sqrt(30),5/sqrt(30),0],\n",
    "#               [0,0,0,1]])\n",
    "\n",
    "\n",
    "Q = 1/3 * np.array([[4,2, 0, 0],\n",
    "                    [2,4,0,0],\n",
    "                    [0,0,3,0],\n",
    "                    [0,0,0,-3]])\n",
    "# Cstar = P @ np.linalg.inv(Q) @ P.T\n",
    "Cstar = P @ Q @ P.T\n",
    "print(Cstar)\n",
    "print(np.linalg.inv(Cstar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1117, 1.2023, 1.0289],\n",
      "        [1.2023, 5.9874, 0.6625],\n",
      "        [1.0289, 0.6625, 1.0273]])\n",
      "tensor([[1.1117, 1.2023, 1.0289],\n",
      "        [1.2023, 5.9874, 0.6625],\n",
      "        [1.0289, 0.6625, 1.0273]])\n",
      "tensor([[ 3.3644,  2.2658,  0.1740],\n",
      "        [ 2.2658,  4.7303, -0.0371],\n",
      "        [ 0.1740, -0.0371,  0.0318]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/p7wxm9ss4y79jh19st9d10h80000gn/T/ipykernel_22037/1183037652.py:4: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1699.)\n",
      "  l = torch.cholesky(a)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(3, 3)\n",
    "a = a @ a.mT + 1e-3 # make symmetric positive-definite\n",
    "l = torch.cholesky(a)\n",
    "print(a)\n",
    "print(l @ l.mT)\n",
    "print(l.mT @ l)\n",
    "# a = torch.randn(3, 2, 2) # Example for batched input\n",
    "# a = a @ a.mT + 1e-03 # make symmetric positive-definite\n",
    "# l = torch.cholesky(a)\n",
    "# z = l @ l.mT\n",
    "# torch.dist(z, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5124073655203634\n"
     ]
    }
   ],
   "source": [
    "print(np.pi * sqrt(- np.linalg.det(Cstar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.512407365520363"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi * sqrt(3/2) * sqrt(5/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.4330127  0.        -0.25     ]\n",
      " [ 0.         1.         0.       ]\n",
      " [-0.25       0.         0.5669873]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.32278096],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [1.        ]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R =np.array([[0.5, 0, sqrt(3)/2],\n",
    "              [0, 1, 0],\n",
    "              [-sqrt(3)/2, 0 , 0.5]])  @ np.array([[-1, 0, 0],\n",
    "              [0, -1, 0],\n",
    "              [0, 0 , 1]])\n",
    "A = np.array([[1, 0, -0.5],\n",
    "              [0, 1, 0],\n",
    "              [-0.5, 0, 1]])\n",
    "\n",
    "M  = R @ A @ R.T\n",
    "print(M)\n",
    "def schur_complement_batch(M):\n",
    "    A, B, C, D, E, F = M[:,0,0], M[:, 1,1], M[:, 2,2], M[:, 0,1], M[:, 0,2], M[:, 1,2]\n",
    "    return np.stack([np.stack([A - E**2/C, D - E*F/C]),\n",
    "                        np.stack([D - E*F/C, B - F**2/C])])\n",
    "\n",
    "schur_complement_batch(M[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8660254, 0.       , 0.5      ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R @ np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33333333, 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A =    np.array([[1,0,-1/2,0],\n",
    "                [0,1,0,0],\n",
    "                [-1/2, 0, 1,0],\n",
    "                [0,0,0,1]])\n",
    "P = np.array([[1,0,0,0],\n",
    "              [0,1,0,0],\n",
    "              [0,0,0,1]])\n",
    "\n",
    "R =np.array([[0.5, 0, sqrt(3)/2],\n",
    "              [0, 1, 0],\n",
    "              [-sqrt(3)/2, 0 , 0.5]])  @ np.array([[-1, 0, 0],\n",
    "              [0, -1, 0],\n",
    "              [0, 0 , 1]])\n",
    "A = np.array([[1, 0, -0.5],\n",
    "              [0, 1, 0],\n",
    "              [-0.5, 0, 1]])\n",
    "\n",
    "M  = R @ A @ R.T\n",
    "\n",
    "P = np.array([[-0.5,0,sqrt(3)/2,0],\n",
    "              [0,1,0,0],\n",
    "              [0,0,0,1]])\n",
    "def make_homogeneous(mat3x3):\n",
    "    \"\"\"Convert a 3x3 matrix to a 4x4 homogeneous matrix.\"\"\"\n",
    "    mat4x4 = np.eye(4)  # Start with an identity matrix\n",
    "    mat4x4[:3, :3] = mat3x3  # Insert the 3x3 matrix\n",
    "    return mat4x4\n",
    "\n",
    "P @ np.linalg.inv(make_homogeneous(M)) @ P.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0daf5460e7e70b267b98b1da0f26ec996de3765b5ed627292ed8b6734d003d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
