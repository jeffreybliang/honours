{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torch import cos, sin\n",
    "import scipy.optimize as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ddn/\")\n",
    "from ddn.pytorch.node import *\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import sample_farthest_points\n",
    "from descartes import PolygonPatch\n",
    "from pytorch3d.io import IO, load_obj, save_obj,load_objs_as_meshes\n",
    "from pytorch3d.structures import join_meshes_as_scene, Meshes, Pointclouds\n",
    "\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from alpha_shapes import Alpha_Shaper, plot_alpha_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "faulthandler.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def least_squares(u0, tgt_vtxs):\n",
    "    \"\"\"\n",
    "    u0 are vertices\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(u0):\n",
    "        u0 = torch.tensor(u0)\n",
    "    if not torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "\n",
    "    res = torch.square(u0 - tgt_vtxs).sum()\n",
    "    return res.double()\n",
    "\n",
    "def least_squares_grad(u0, tgt_vtxs):\n",
    "    if torch.is_tensor(u0):\n",
    "        u0 = u0.detach().clone()\n",
    "    else:\n",
    "        u0 = torch.tensor(u0)\n",
    "    if torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = tgt_vtxs.detach().clone()\n",
    "    else:\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "        \n",
    "    # Ensure that u0 requires gradients\n",
    "    gradient = 2 * (u0 - tgt_vtxs)\n",
    "    return gradient.double()\n",
    "\n",
    "\n",
    "def calculate_volume(vertices, faces):\n",
    "    face_vertices = vertices[faces]  # (F, 3, 3)\n",
    "    v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "    \n",
    "    # Compute determinant of the 3x3 matrix [v0, v1, v2]\n",
    "    face_volumes = torch.det(torch.stack([v0, v1, v2], dim=-1)) / 6.0  # Shape: (F,)\n",
    "    volume = face_volumes.sum()\n",
    "    return volume.abs()\n",
    "\n",
    "\n",
    "def volume_constraint(x, faces, tgt_vol):\n",
    "    \"\"\"\n",
    "    Calculate the volume of a mesh using PyTorch tensors.\n",
    "    Args:\n",
    "        vertices_torch: Nx3 tensor of vertex coordinates\n",
    "        faces: Mx3 array of face indices\n",
    "    Returns:\n",
    "        volume: Total volume of the mesh as a PyTorch scalar\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x)\n",
    "    if not torch.is_tensor(faces):\n",
    "        faces = torch.tensor(faces)\n",
    "    if not torch.is_tensor(tgt_vol):\n",
    "        tgt_vol = torch.tensor(tgt_vol)\n",
    "\n",
    "    vertices = x.view(-1,3)\n",
    "    faces = faces.view(-1,3)    \n",
    "    volume = calculate_volume(vertices, faces)\n",
    "    res = volume.abs() - tgt_vol\n",
    "    return res.double()\n",
    "\n",
    "def volume_constraint_grad(x, faces):\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.detach().clone()\n",
    "    else:\n",
    "        x = torch.tensor(x)\n",
    "    if torch.is_tensor(faces):\n",
    "        faces = faces.detach().clone()\n",
    "    else:\n",
    "        faces = torch.tensor(faces)\n",
    "\n",
    "    vertices_torch = x.view(-1, 3)\n",
    "    p0 = vertices_torch[faces[:, 0]]  # (F, 3)\n",
    "    p1 = vertices_torch[faces[:, 1]]  # (F, 3)\n",
    "    p2 = vertices_torch[faces[:, 2]]  # (F, 3)\n",
    "\n",
    "    grad_p0 = torch.cross(p1, p2, dim=1) / 6.0\n",
    "    grad_p1 = torch.cross(p2, p0, dim=1) / 6.0\n",
    "    grad_p2 = torch.cross(p0, p1, dim=1) / 6.0\n",
    "\n",
    "    grad_verts = torch.zeros_like(vertices_torch)\n",
    "    grad_verts.scatter_add_(0, faces[:, 0].unsqueeze(1).expand(-1, 3), grad_p0)\n",
    "    grad_verts.scatter_add_(0, faces[:, 1].unsqueeze(1).expand(-1, 3), grad_p1)\n",
    "    grad_verts.scatter_add_(0, faces[:, 2].unsqueeze(1).expand(-1, 3), grad_p2)\n",
    "\n",
    "    analytical_grad = grad_verts.flatten()\n",
    "    return analytical_grad \n",
    "\n",
    "\n",
    "class ConstrainedProjectionNode(EqConstDeclarativeNode):\n",
    "\n",
    "    def __init__(self, src: Meshes, tgt: Meshes):\n",
    "        super().__init__(eps=1.0e-6) # relax tolerance on optimality test \n",
    "        self.src = src # source meshes (B,)\n",
    "        self.tgt = tgt # target meshes (B,)\n",
    "\n",
    "    def objective(self, xs: torch.Tensor, y: torch.Tensor, scatter_add=True):\n",
    "        \"\"\"\n",
    "        Calculates sum of squared differences between source and target meshes.\n",
    "\n",
    "        Args:\n",
    "            xs (tensor): vertices of original mesh, sum(V_i) x 3\n",
    "            y (tensor): vertices of projected mesh, sum(V_i) x 3\n",
    "        \"\"\"\n",
    "        src_verts = y.view(-1,3) # (sum(V_i), 3)\n",
    "        tgt_verts = self.tgt.verts_packed().detach() # (sum(V_i), 3)\n",
    "        sqr_diffs = torch.square(src_verts - tgt_verts) # (sum(V_i), 3)\n",
    "\n",
    "        n_batches = len(self.src)\n",
    "        sse = torch.zeros(n_batches, dtype=sqr_diffs.dtype)\n",
    "        if scatter_add:\n",
    "            sse.scatter_add_(0, self.src.verts_packed_to_mesh_idx(), sqr_diffs)\n",
    "        else:\n",
    "            n_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_vert = self.src.mesh_to_verts_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_vert[i]\n",
    "                end = start + n_verts_per_mesh[i]\n",
    "                sse[i] = sqr_diffs[start:end].sum()  # Sum over all faces\n",
    "        return sse\n",
    "\n",
    "    def equality_constraints(self, xs, y, scatter_add=True):\n",
    "        \"\"\"\n",
    "        Enforces volume constraint\n",
    "        Assumes same number of vertices in each projected mesh currently\n",
    "\n",
    "        Args:\n",
    "            xs (tensor): vertices of original mesh, sum(V_i) x 3\n",
    "            y (tensor): vertices of projected mesh, sum(V_i) x 3\n",
    "        \"\"\"\n",
    "        n_batches = len(self.src)\n",
    "        verts_packed = y.view(-1,3) # (sum(V_i), 3)\n",
    "\n",
    "        faces_packed = self.src.faces_packed()  # (sum(F_i), 3)\n",
    "        face_vertices = verts_packed[faces_packed]  # (sum(F_i), 3, 3)\n",
    "        \n",
    "        # Calculate tetrahedron volumes for each face\n",
    "        v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "        cross_product = torch.cross(v0, v1, dim=-1)  # (F, 3)\n",
    "        face_volumes = torch.sum(cross_product * v2, dim=-1) / 6.0  # (F,)\n",
    "        volumes = torch.zeros(n_batches, device=verts_packed.device, dtype=face_volumes.\n",
    "                                dtype)\n",
    "        if scatter_add:\n",
    "            volumes.scatter_add_(0, self.src.faces_packed_to_mesh_idx(), face_volumes)\n",
    "        else:\n",
    "            n_faces_per_mesh = self.src.num_faces_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_face = self.src.mesh_to_faces_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_face[i]\n",
    "                end = start + n_faces_per_mesh[i]\n",
    "                volumes[i] = face_volumes[start:end].sum()  # Sum over all faces\n",
    "\n",
    "        volumes = volumes.abs()\n",
    "        return volumes  # Shape: (B,)    \n",
    "    \n",
    "    def solve(self, xs: torch.Tensor):\n",
    "        n_batches = len(self.src)\n",
    "        start_vtx = self.src.mesh_to_verts_packed_first_idx()\n",
    "        end_vtx = start_vtx + self.src.num_verts_per_mesh()\n",
    "        \n",
    "        n_vtx = len(self.src.verts_packed())\n",
    "        results = torch.zeros(n_vtx, 3, dtype=torch.double)\n",
    "        for batch in range(n_batches):\n",
    "            start,end = start_vtx[batch],end_vtx[batch]\n",
    "            verts = xs[start:end].flatten().detach().double().cpu().numpy()\n",
    "            faces = self.src[batch].faces_packed().detach().double().cpu().numpy()\n",
    "            tgt_vtx = self.tgt[batch].verts_packed().detach()\n",
    "            tgt_faces = self.tgt[batch].faces_packed().detach()\n",
    "            with torch.no_grad():\n",
    "                tgt_vol = volume_constraint(tgt_vtx, tgt_faces)\n",
    "\n",
    "            eq_constraint = {\n",
    "                'type': 'eq',\n",
    "                'fun' : lambda u: volume_constraint(u, faces, tgt_vol).cpu().numpy(),\n",
    "                'jac' : lambda u: volume_constraint_grad(u, faces).cpu().numpy()\n",
    "            }\n",
    "\n",
    "            res = opt.minimize(\n",
    "                lambda u: least_squares(u, tgt_vtx),\n",
    "                verts,\n",
    "                method='SLSQP',\n",
    "                jac=lambda u: least_squares_grad(u, tgt_vtx),\n",
    "                constraints=[eq_constraint],\n",
    "                options={'ftol': 1e-6, 'iprint': 2, 'maxiter': 100}\n",
    "            )\n",
    "\n",
    "            if not res.success:\n",
    "                print(\"FAILED:\", res.message)\n",
    "            results[start:end, :] = torch.tensor(res.x, dtype=torch.double, requires_grad=True).view(-1,3)\n",
    "        return results,None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo code:\n",
    "- load in the meshes\n",
    "- inner problem needs access to the vertices, number of meshes, faces, and indexing\n",
    "- outer problem needs access to projected vertices, number of meshes, and indexing. Also needs projection matrices, and edge maps of renders, so perform edge detection of renders beforehand.\n",
    "\n",
    "just provide both with the meshes lol\n",
    "\n",
    "Projection:\n",
    "Get the indexing correct for the vertices, take the projection of these vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2.typing import MatLike\n",
    "\n",
    "# Apply Canny edge detection\n",
    "def canny_edge_map(img: MatLike):\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=50, threshold2=250)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "def get_edgemaps(renders):    \n",
    "    edgemaps = {k: list(map(canny_edge_map,v)) for k,v in renders.items()}\n",
    "    return edgemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera3_RT.npy\n",
      "Camera0_K.npy\n",
      "Camera1_RT.npy\n",
      "Camera2_K.npy\n",
      "Camera3_K.npy\n",
      "Camera1_K.npy\n",
      "Camera1_P.npy\n",
      "Camera3_P.npy\n",
      "Camera2_RT.npy\n",
      "Camera0_RT.npy\n",
      "Camera2_P.npy\n",
      "Camera0_P.npy\n"
     ]
    }
   ],
   "source": [
    "from utils import load_renders, load_camera_matrices\n",
    "\n",
    "renders_path = \"../../../Blender/renders/\"\n",
    "renders = load_renders(renders_path)\n",
    "edgemaps = get_edgemaps(renders)\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "\n",
    "def load_camera_matrices(path):\n",
    "    cameras = defaultdict(dict)\n",
    "    file_pattern = re.compile(r\"^(.*)_(K|RT|P)\\.npy$\")\n",
    "    for filename in os.listdir(path):\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            print(filename)\n",
    "            cam_name, matrix_type = match.groups()\n",
    "            filepath = os.path.join(path, filename)\n",
    "            cameras[cam_name][matrix_type] = torch.tensor(np.load(filepath), dtype=torch.double)\n",
    "    return cameras\n",
    "\n",
    "matrices_path = \"../../../Blender/cameras\"\n",
    "matrices = load_camera_matrices(matrices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer problem\n",
    "def create_padded_tensor(vertices, vert2mesh, max_V, B):\n",
    "    padded = torch.zeros((B, max_V, 3),device=vertices.device)\n",
    "    for i in range(B):\n",
    "        mesh_vertices = vertices[vert2mesh == i]\n",
    "        num_vertices = mesh_vertices.shape[0]\n",
    "        padded[i, :num_vertices, :] = mesh_vertices\n",
    "    return padded\n",
    "\n",
    "class PyTorchChamferLoss(nn.Module):\n",
    "    def __init__(self, src: Meshes, tgt: Meshes, projmatrices, edgemaps):\n",
    "        super().__init__()\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "        self.projmatrices = projmatrices\n",
    "        self.edgemaps = edgemaps\n",
    "    \n",
    "    def project_vertices(self, vertices):\n",
    "        \"\"\"\n",
    "        Projects a set of vertices into multiple views using different projection matrices.\n",
    "\n",
    "        Args:\n",
    "            vertices: Tensor of shape (N, 3), representing 3D vertex positions.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (P, N, 2), containing projected 2D points in each view.\n",
    "        \"\"\"\n",
    "        V = vertices.shape[0]\n",
    "        projection_matrices = self.projmatrices\n",
    "\n",
    "        ones = torch.ones((V, 1), dtype=vertices.dtype, device=vertices.device)\n",
    "        vertices_homogeneous = torch.cat([vertices, ones], dim=1)  # Shape: (V, 4)\n",
    "\n",
    "        # Perform batched matrix multiplication (P, 3, 4) @ (V, 4, 1) -> (P, V, 3)\n",
    "        projected = torch.einsum(\"pij,vj->pvi\", projection_matrices, vertices_homogeneous)  # (P, V, 3)\n",
    "        \n",
    "        projected_cartesian = projected[:, :, :2] / projected[:, :, 2:3]  # (P, V, 2)\n",
    "\n",
    "        return projected_cartesian\n",
    "\n",
    "    def get_boundary(self, projected_pts, alpha=10.0):\n",
    "        shaper = Alpha_Shaper(projected_pts)\n",
    "        alpha_shape = shaper.get_shape(alpha)\n",
    "        boundary = torch.tensor(alpha_shape.exterior.coords.xy)\n",
    "        boundary_pts = projected_pts[\n",
    "            torch.any(torch.isclose(projected_pts[:, None], boundary.T, atol=1e-6).all(dim=-1), dim=1)\n",
    "        ]\n",
    "        return boundary_pts\n",
    "\n",
    "    def forward(self, y):\n",
    "        # y Shape: (sum Vi, 3) -> reshape nicely into (B, maxV, 3)\n",
    "        B, max_V = len(self.src), self.src.num_verts_per_mesh().max().item()\n",
    "        vertices = create_padded_tensor(y, self.src.verts_packed_to_mesh_idx(), max_V, B) # (B, maxV, 3)\n",
    "\n",
    "        # project vertices\n",
    "        projected_vertices = [] # (B, P, V, 2)\n",
    "        for b in range(B):\n",
    "            projverts = self.project_vertices(vertices[b])  # Shape: (P, V, 2)\n",
    "            projected_vertices.append(projverts)  # Store without padding\n",
    "\n",
    "        # get boundaries\n",
    "        boundaries = [] \n",
    "        for batch in projected_vertices:\n",
    "            boundaries_b = []\n",
    "            for projverts in batch:\n",
    "                boundary = self.get_boundary(projverts)\n",
    "                boundaries_b.append(boundary)\n",
    "            stacked_boundaries = torch.stack(boundaries_b)\n",
    "            # padded_boundaries = torch.nn.utils.rnn.pad_sequence(boundaries_b, batch_first=True, padding_value=0.0)\n",
    "            boundaries.append(stacked_boundaries)\n",
    "\n",
    "        # perform chamfer\n",
    "        chamfer_loss = torch.zeros(B)\n",
    "        for b in range(B):\n",
    "            boundaries_b = boundaries[b]\n",
    "            edgemaps_b = self.edgemaps[b]\n",
    "            res, _ = chamfer_distance(x=boundaries_b.float(),\n",
    "                                                y=edgemaps_b.float(),batch_reduction=\"mean\",point_reduction=\"mean\")\n",
    "            chamfer_loss[b] = res.sum()\n",
    "        return chamfer_loss.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def project_vertices(vertices, projection_matrix):\n",
    "    ones = torch.ones((vertices.shape[0], 1), dtype=vertices.dtype, device=vertices.device)\n",
    "    vertices_homogeneous = torch.cat([vertices, ones], dim=1)  \n",
    "    \n",
    "    projected = projection_matrix @ vertices_homogeneous.T  \n",
    "    \n",
    "    projected = projected.T  # Shape becomes Nx3\n",
    "    projected_cartesian = projected[:, :2] / projected[:, 2:3] \n",
    "    \n",
    "    return projected_cartesian\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(9.6, 5.4)) \n",
    "# plt.scatter(points_2d[:, 0], points_2d[:, 1], s=1, c='blue', alpha=0.5)\n",
    "# plt.xlim(0, 1920)\n",
    "# plt.ylim(0, 1080)\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates (0 at top)\n",
    "\n",
    "# plt.title('Projected Vertices')\n",
    "# plt.xlabel('X (pixels)')\n",
    "# plt.ylabel('Y (pixels)')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('projected_vertices.png', dpi=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = [os.path.join(\"../../../Blender/\", f\"{name}_2.obj\") for name in [\"sphere\", \"balloon\", \"parabola\", \"rstrawberry\"]]\n",
    "sphere, balloon, parabola, rstrawberry = load_objs_as_meshes(paths)\n",
    "\n",
    "P = matrices[\"Camera0\"][\"P\"]  # Shape is 3x4\n",
    "vertices = parabola.verts_packed().double()  # Shape is Nx3\n",
    "points_2d = project_vertices(vertices, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted boundary points:\n",
      "tensor([[ 620.6065,  542.3839],\n",
      "        [ 645.6539,  400.9917],\n",
      "        [ 646.5989,  497.4448],\n",
      "        [ 652.8959,  606.0431],\n",
      "        [ 660.6537,  663.5051],\n",
      "        [ 714.6081,  293.5973],\n",
      "        [ 725.3716,  320.6722],\n",
      "        [ 732.1652,  694.8917],\n",
      "        [ 741.6011,  706.7673],\n",
      "        [ 797.1500,  250.9754],\n",
      "        [ 810.4565,  712.7552],\n",
      "        [ 820.5273,  221.8992],\n",
      "        [ 873.6121,  728.9413],\n",
      "        [ 888.9455,  222.3212],\n",
      "        [ 903.5753,  756.9889],\n",
      "        [ 915.0647,  810.5560],\n",
      "        [ 918.4108,  228.9707],\n",
      "        [ 956.4047,  830.6323],\n",
      "        [ 959.7287,  244.2515],\n",
      "        [ 995.0637,  281.5897],\n",
      "        [1001.4562,  849.5047],\n",
      "        [1006.5479,  320.6073],\n",
      "        [1028.8410,  835.9146],\n",
      "        [1035.5187,  344.4571],\n",
      "        [1096.9772,  832.4019],\n",
      "        [1110.5111,  331.4659],\n",
      "        [1113.7154,  791.3713],\n",
      "        [1128.1780,  310.4889],\n",
      "        [1176.4475,  718.1627],\n",
      "        [1192.5360,  749.2712],\n",
      "        [1192.6640,  329.7535],\n",
      "        [1211.1661,  336.4183],\n",
      "        [1251.4780,  642.9324],\n",
      "        [1251.6624,  552.4827],\n",
      "        [1257.4081,  447.0898],\n",
      "        [1265.8660,  383.3129],\n",
      "        [1287.3276,  509.5912]], dtype=torch.float64)\n",
      "\n",
      "Sorted exterior coordinates:\n",
      "[[ 620.60653729  542.38389933]\n",
      " [ 620.60653729  542.38389933]\n",
      " [ 645.65388586  400.99170312]\n",
      " [ 646.59893682  497.4448498 ]\n",
      " [ 652.89590322  606.04307149]\n",
      " [ 660.65370466  663.50512241]\n",
      " [ 714.60809661  293.59731346]\n",
      " [ 725.37159979  320.67220458]\n",
      " [ 732.16522057  694.89165206]\n",
      " [ 741.60114806  706.76725146]\n",
      " [ 797.15000172  250.97543486]\n",
      " [ 810.45653692  712.75520417]\n",
      " [ 820.52730016  221.89922938]\n",
      " [ 873.61213154  728.94130499]\n",
      " [ 888.94551455  222.32115024]\n",
      " [ 903.57531709  756.9888727 ]\n",
      " [ 915.06467294  810.55595521]\n",
      " [ 918.41076473  228.97067179]\n",
      " [ 956.40472014  830.63226073]\n",
      " [ 959.72874419  244.25148275]\n",
      " [ 995.06374134  281.58969969]\n",
      " [1001.45623832  849.50473254]\n",
      " [1006.54785048  320.60731145]\n",
      " [1028.8409566   835.9146034 ]\n",
      " [1035.51865007  344.4571032 ]\n",
      " [1096.97719731  832.40190068]\n",
      " [1110.51110013  331.46594635]\n",
      " [1113.71537729  791.37128349]\n",
      " [1128.17804019  310.48885743]\n",
      " [1176.44747707  718.16269806]\n",
      " [1192.53604054  749.27120504]\n",
      " [1192.66399318  329.75345703]\n",
      " [1211.1661315   336.41829431]\n",
      " [1251.47798344  642.9323702 ]\n",
      " [1251.66240892  552.48274014]\n",
      " [1257.40813921  447.08980203]\n",
      " [1265.86602121  383.31289817]\n",
      " [1287.32755364  509.59118948]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 10.0\n",
    "shaper = Alpha_Shaper(points_2d)\n",
    "# alpha_opt, alpha_shape = shaper.optimize()\n",
    "alpha_shape = shaper.get_shape(alpha=alpha)\n",
    "# print(torch.tensor(alpha_shape.exterior.coords.xy))\n",
    "\n",
    "# print(points_2d[:, None, :].size(), points_2d.size())\n",
    "\n",
    "boundary = torch.tensor(alpha_shape.exterior.coords.xy, dtype=points_2d.dtype)\n",
    "boundary_pts = points_2d[\n",
    "    torch.any(torch.isclose(points_2d[:, None], boundary.T, atol=1e-6).all(dim=-1), dim=1)\n",
    "]\n",
    "# print(boundary_pts)\n",
    "\n",
    "sorted_boundary_pts = boundary_pts[boundary_pts[:, 0].argsort()]\n",
    "\n",
    "# For the exterior coordinates, convert to numpy array first\n",
    "exterior_coords = np.array(alpha_shape.exterior.coords.xy).T  # Transpose to get (n_points, 2)\n",
    "sorted_exterior_coords = exterior_coords[exterior_coords[:, 0].argsort()]\n",
    "\n",
    "print(\"Sorted boundary points:\")\n",
    "print(sorted_boundary_pts)\n",
    "print(\"\\nSorted exterior coordinates:\")\n",
    "print(sorted_exterior_coords)\n",
    "\n",
    "# fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "# ax0.scatter(*zip(*points_2d))\n",
    "# ax0.set_title('data')\n",
    "# ax1.scatter(*zip(*points_2d))\n",
    "# ax0.invert_yaxis()\n",
    "# ax1.invert_yaxis()\n",
    "# plot_alpha_shape(ax1, alpha_shape)\n",
    "# ax1.set_title(f\"$\\\\alpha={alpha:.3}$\")\n",
    "\n",
    "# for ax in (ax0, ax1):\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "# for v in points_2d:\n",
    "#     if tuple(v) == (620.6065372882819, 542.3838993304273):\n",
    "#         print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient exists: True\n",
      "Gradient:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vertices = torch.tensor([\n",
    "    [0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9],\n",
    "    [1.0, 1.1, 1.2], [1.3, 1.4, 1.5],\n",
    "    [1.6, 1.7, 1.8], [1.9, 2.0, 2.1],\n",
    "], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "mesh_data = torch.tensor([0, 0, 0, 1, 1, 2, 2])\n",
    "B, max_V = 3, 3\n",
    "\n",
    "def create_padded_tensor(vertices, mesh_data, max_V, B):\n",
    "    padded = torch.zeros((B, max_V, 3), device=vertices.device)\n",
    "    \n",
    "    for i in range(B):\n",
    "        mask = (mesh_data == i)\n",
    "        mesh_vertices = vertices[mask]\n",
    "        num_vertices = mesh_vertices.shape[0]\n",
    "        padded[i, :num_vertices, :] = mesh_vertices\n",
    "    \n",
    "    return padded\n",
    "\n",
    "# Test gradient flow\n",
    "padded = create_padded_tensor(vertices, mesh_data, max_V, B)\n",
    "loss = padded.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(\"Gradient exists:\", vertices.grad is not None)\n",
    "print(\"Gradient:\")\n",
    "print(vertices.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
