{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torch import cos, sin\n",
    "import scipy.optimize as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ddn/\")\n",
    "from ddn.pytorch.node import *\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import sample_farthest_points\n",
    "from descartes import PolygonPatch\n",
    "from pytorch3d.io import IO, load_obj, save_obj,load_objs_as_meshes\n",
    "from pytorch3d.structures import join_meshes_as_scene, Meshes, Pointclouds\n",
    "\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from alpha_shapes import Alpha_Shaper, plot_alpha_shape\n",
    "from torch import Tensor, tensor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def least_squares(u0, tgt_vtxs):\n",
    "    \"\"\"\n",
    "    u0 are vertices\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(u0):\n",
    "        u0 = torch.tensor(u0)\n",
    "    if not torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "    res = torch.square(u0 - tgt_vtxs.flatten()).sum()\n",
    "    return res.double()\n",
    "\n",
    "def least_squares_grad(u0, tgt_vtxs):\n",
    "    if torch.is_tensor(u0):\n",
    "        u0 = u0.detach().clone()\n",
    "    else:\n",
    "        u0 = torch.tensor(u0)\n",
    "    if torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = tgt_vtxs.detach().clone()\n",
    "    else:\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "        \n",
    "    # Ensure that u0 requires gradients\n",
    "    gradient = 2 * (u0 - tgt_vtxs.flatten())\n",
    "    return gradient.double()\n",
    "\n",
    "\n",
    "def calculate_volume(vertices, faces):\n",
    "    face_vertices = vertices[faces]  # (F, 3, 3)\n",
    "    v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "    \n",
    "    # Compute determinant of the 3x3 matrix [v0, v1, v2]\n",
    "    face_volumes = torch.det(torch.stack([v0, v1, v2], dim=-1)) / 6.0  # Shape: (F,)\n",
    "    volume = face_volumes.sum()\n",
    "    return volume.abs()\n",
    "\n",
    "\n",
    "def volume_constraint(x, faces, tgt_vol):\n",
    "    \"\"\"\n",
    "    Calculate the volume of a mesh using PyTorch tensors.\n",
    "    Args:\n",
    "        vertices_torch: Nx3 tensor of vertex coordinates\n",
    "        faces: Mx3 array of face indices\n",
    "    Returns:\n",
    "        volume: Total volume of the mesh as a PyTorch scalar\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x)\n",
    "    if not torch.is_tensor(faces):\n",
    "        faces = torch.tensor(faces)\n",
    "    if not torch.is_tensor(tgt_vol):\n",
    "        tgt_vol = torch.tensor(tgt_vol)\n",
    "\n",
    "    vertices = x.view(-1,3)\n",
    "    faces = faces.view(-1,3).int()    \n",
    "    volume = calculate_volume(vertices, faces)\n",
    "    res = volume.abs() - tgt_vol\n",
    "    return res.double()\n",
    "\n",
    "def volume_constraint_grad(x, faces):\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.detach().clone()\n",
    "    else:\n",
    "        x = torch.tensor(x)\n",
    "    if torch.is_tensor(faces):\n",
    "        faces = faces.detach().clone()\n",
    "    else:\n",
    "        faces = torch.tensor(faces)\n",
    "    faces = faces.to(dtype=torch.int64)\n",
    "\n",
    "    vertices_torch = x.view(-1, 3)\n",
    "    p0 = vertices_torch[faces[:, 0]]  # (F, 3)\n",
    "    p1 = vertices_torch[faces[:, 1]]  # (F, 3)\n",
    "    p2 = vertices_torch[faces[:, 2]]  # (F, 3)\n",
    "\n",
    "    grad_p0 = torch.cross(p1, p2, dim=1) / 6.0\n",
    "    grad_p1 = torch.cross(p2, p0, dim=1) / 6.0\n",
    "    grad_p2 = torch.cross(p0, p1, dim=1) / 6.0\n",
    "\n",
    "    grad_verts = torch.zeros_like(vertices_torch)\n",
    "    grad_verts.scatter_add_(0, faces[:, 0].unsqueeze(1).expand(-1, 3), grad_p0)\n",
    "    grad_verts.scatter_add_(0, faces[:, 1].unsqueeze(1).expand(-1, 3), grad_p1)\n",
    "    grad_verts.scatter_add_(0, faces[:, 2].unsqueeze(1).expand(-1, 3), grad_p2)\n",
    "\n",
    "    analytical_grad = grad_verts.flatten()\n",
    "    return analytical_grad \n",
    "\n",
    "\n",
    "class ConstrainedProjectionNode(EqConstDeclarativeNode):\n",
    "\n",
    "    def __init__(self, src: Meshes, tgt: Meshes):\n",
    "        super().__init__(eps=1.0e-6) # relax tolerance on optimality test \n",
    "        self.src = src # source meshes (B,)\n",
    "        self.tgt = tgt # target meshes (B,)\n",
    "\n",
    "    def objective(self, xs: torch.Tensor, y: torch.Tensor, scatter_add=True):\n",
    "        \"\"\"\n",
    "        Calculates sum of squared differences between source and target meshes.\n",
    "\n",
    "        Args:\n",
    "            xs (tensor): vertices of original mesh, sum(V_i) x 3\n",
    "            y (tensor): vertices of projected mesh, sum(V_i) x 3\n",
    "        \"\"\"\n",
    "        src_verts = y.view(-1,3) # (sum(V_i), 3)\n",
    "        tgt_verts = self.tgt.verts_packed().detach() # (sum(V_i), 3)\n",
    "        sqr_diffs = torch.square(src_verts - tgt_verts) # (sum(V_i), 3)\n",
    "\n",
    "        n_batches = len(self.src)\n",
    "        sse = torch.zeros(n_batches, dtype=sqr_diffs.dtype)\n",
    "        if scatter_add:\n",
    "            sse.scatter_add_(0, self.src.verts_packed_to_mesh_idx(), sqr_diffs)\n",
    "        else:\n",
    "            n_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_vert = self.src.mesh_to_verts_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_vert[i]\n",
    "                end = start + n_verts_per_mesh[i]\n",
    "                sse[i] = sqr_diffs[start:end].sum()  # Sum over all faces\n",
    "        return sse\n",
    "\n",
    "    def equality_constraints(self, xs, y, scatter_add=True):\n",
    "        \"\"\"\n",
    "        Enforces volume constraint\n",
    "        Assumes same number of vertices in each projected mesh currently\n",
    "\n",
    "        Args:\n",
    "            xs (tensor): vertices of original mesh, sum(V_i) x 3\n",
    "            y (tensor): vertices of projected mesh, sum(V_i) x 3\n",
    "        \"\"\"\n",
    "        n_batches = len(self.src)\n",
    "        verts_packed = y.view(-1,3) # (sum(V_i), 3)\n",
    "\n",
    "        faces_packed = self.src.faces_packed()  # (sum(F_i), 3)\n",
    "        face_vertices = verts_packed[faces_packed]  # (sum(F_i), 3, 3)\n",
    "        \n",
    "        # Calculate tetrahedron volumes for each face\n",
    "        v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "        cross_product = torch.cross(v0, v1, dim=-1)  # (F, 3)\n",
    "        face_volumes = torch.sum(cross_product * v2, dim=-1) / 6.0  # (F,)\n",
    "        volumes = torch.zeros(n_batches, device=verts_packed.device, dtype=face_volumes.\n",
    "                                dtype)\n",
    "        if scatter_add:\n",
    "            volumes.scatter_add_(0, self.src.faces_packed_to_mesh_idx(), face_volumes)\n",
    "        else:\n",
    "            n_faces_per_mesh = self.src.num_faces_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_face = self.src.mesh_to_faces_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_face[i]\n",
    "                end = start + n_faces_per_mesh[i]\n",
    "                volumes[i] = face_volumes[start:end].sum()  # Sum over all faces\n",
    "\n",
    "        volumes = volumes.abs()\n",
    "        return volumes  # Shape: (B,)    \n",
    "    \n",
    "    def solve(self, xs: torch.Tensor):\n",
    "        \"\"\"Projects the vertices onto the target mesh vertices across batches.\n",
    "\n",
    "        Args:\n",
    "            xs (torch.Tensor): a (sum Vi, 3) packed tensor of vertices in the batched meshes\n",
    "\n",
    "        Returns:\n",
    "            results (torch.Tensor): a (sum Vi, 3) packed tensor of the projected vertices\n",
    "        \"\"\"\n",
    "        n_batches = len(self.src)\n",
    "        start_vtx = self.src.mesh_to_verts_packed_first_idx()\n",
    "        end_vtx = start_vtx + self.src.num_verts_per_mesh()\n",
    "        \n",
    "        n_vtx = len(xs)\n",
    "        results = torch.zeros(n_vtx, 3, dtype=torch.double)\n",
    "        for batch in range(n_batches):\n",
    "            start,end = start_vtx[batch],end_vtx[batch]\n",
    "            verts = xs[start:end].flatten().detach().double().cpu().numpy()\n",
    "            faces = self.src[batch].faces_packed().detach().int().cpu().numpy()\n",
    "            tgt_vtx = self.tgt[batch].verts_packed().detach()\n",
    "            tgt_faces = self.tgt[batch].faces_packed().detach()\n",
    "            with torch.no_grad():\n",
    "                tgt_vol = calculate_volume(tgt_vtx, tgt_faces)\n",
    "\n",
    "            eq_constraint = {\n",
    "                'type': 'eq',\n",
    "                'fun' : lambda u: volume_constraint(u, faces, tgt_vol).cpu().numpy(),\n",
    "                'jac' : lambda u: volume_constraint_grad(u, faces).cpu().numpy()\n",
    "            }\n",
    "\n",
    "            res = opt.minimize(\n",
    "                lambda u: least_squares(u, tgt_vtx),\n",
    "                verts,\n",
    "                method='SLSQP',\n",
    "                jac=lambda u: least_squares_grad(u, tgt_vtx),\n",
    "                constraints=[eq_constraint],\n",
    "                options={'ftol': 1e-6, 'iprint': 2, 'maxiter': 100}\n",
    "            )\n",
    "\n",
    "            if not res.success:\n",
    "                print(\"FAILED:\", res.message)\n",
    "            results[start:end, :] = torch.tensor(res.x, dtype=torch.double, requires_grad=True).view(-1,3)\n",
    "        return results,None\n",
    "    \n",
    "\n",
    "class ConstrainedProjectionFunction(DeclarativeFunction):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo code:\n",
    "- load in the meshes\n",
    "- inner problem needs access to the vertices, number of meshes, faces, and indexing\n",
    "- outer problem needs access to projected vertices, number of meshes, and indexing. Also needs projection matrices, and edge maps of renders, so perform edge detection of renders beforehand.\n",
    "\n",
    "just provide both with the meshes lol\n",
    "\n",
    "Projection:\n",
    "Get the indexing correct for the vertices, take the projection of these vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer problem\n",
    "def create_padded_tensor(vertices, vert2mesh, max_V, B):\n",
    "    padded = torch.zeros((B, max_V, 3),device=vertices.device)\n",
    "    for i in range(B):\n",
    "        mesh_vertices = vertices[vert2mesh == i]\n",
    "        num_vertices = mesh_vertices.shape[0]\n",
    "        padded[i, :num_vertices, :] = mesh_vertices\n",
    "    return padded\n",
    "\n",
    "class PyTorchChamferLoss(nn.Module):\n",
    "    def __init__(self, src: Meshes, tgt: Meshes, projmatrices, edgemap_info):\n",
    "        super().__init__()\n",
    "        self.src = src  # (B meshes)\n",
    "        self.tgt = tgt  # (B meshes)\n",
    "        self.projmatrices = projmatrices # (P, 3, 4)\n",
    "        self.edgemaps = edgemap_info[0] # (P, max_Ni, 2)\n",
    "        self.edgemaps_len = edgemap_info[1] # (P,)\n",
    "    \n",
    "    def project_vertices(self, vertices):\n",
    "        \"\"\"\n",
    "        Projects a set of vertices into multiple views using different projection matrices.\n",
    "\n",
    "        Args:\n",
    "            vertices: Tensor of shape (N, 3), representing 3D vertex positions.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (P, N, 2), containing projected 2D points in each view.\n",
    "        \"\"\"\n",
    "        V = vertices.shape[0]\n",
    "        projection_matrices = self.projmatrices\n",
    "\n",
    "        ones = torch.ones((V, 1), dtype=vertices.dtype, device=vertices.device)\n",
    "        vertices_homogeneous = torch.cat([vertices, ones], dim=1).double()  # Shape: (V, 4)\n",
    "\n",
    "        # Perform batched matrix multiplication (P, 3, 4) @ (V, 4, 1) -> (P, V, 3)\n",
    "        projected = torch.einsum(\"pij,vj->pvi\", projection_matrices, vertices_homogeneous)  # (P, V, 3)\n",
    "        \n",
    "        projected_cartesian = projected[:, :, :2] / projected[:, :, 2:3]  # (P, V, 2)\n",
    "\n",
    "        return projected_cartesian\n",
    "\n",
    "    def get_boundary(self, projected_pts, alpha=10.0):\n",
    "        shaper = Alpha_Shaper(projected_pts.detach())\n",
    "        alpha_shape = shaper.get_shape(alpha)\n",
    "        boundary = torch.tensor(alpha_shape.exterior.coords.xy, dtype=torch.double)\n",
    "        boundary_pts = projected_pts[\n",
    "            torch.any(torch.isclose(projected_pts[:, None], boundary.T, atol=1e-6).all(dim=-1), dim=1)\n",
    "        ]\n",
    "        return boundary_pts\n",
    "\n",
    "    def forward(self, y):\n",
    "        # y Shape: (sum Vi, 3) -> reshape nicely into (B, maxV, 3)\n",
    "        B, P, max_V = len(self.src), self.projmatrices.size(0), self.src.num_verts_per_mesh().max().item()\n",
    "        vertices = create_padded_tensor(y, self.src.verts_packed_to_mesh_idx(), max_V, B) # (B, maxV, 3)\n",
    "\n",
    "        # project vertices\n",
    "        num_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "        projected_vertices = [] # (B, P, V, 2)\n",
    "        for b in range(B):\n",
    "            end = num_verts_per_mesh[b]\n",
    "            projverts = self.project_vertices(vertices[b][:end,:])  # Shape: (P, V, 2)\n",
    "            projected_vertices.append(projverts)  # Store without padding\n",
    "\n",
    "        # get boundaries\n",
    "        boundaries = [] \n",
    "        boundary_lengths = torch.zeros(B, P)\n",
    "        for b, batch in enumerate(projected_vertices):\n",
    "            boundaries_b = []\n",
    "            for p, projverts in enumerate(batch):\n",
    "                boundary = self.get_boundary(projverts)\n",
    "                boundaries_b.append(boundary)\n",
    "                boundary_lengths[b,p] = len(boundary)\n",
    "            # stacked_boundaries = torch.stack(boundaries_b)\n",
    "            padded_boundaries = torch.nn.utils.rnn.pad_sequence(boundaries_b, batch_first=True, padding_value=0.0)\n",
    "            boundaries.append(padded_boundaries)\n",
    "\n",
    "        # perform chamfer\n",
    "        chamfer_loss = torch.zeros(B)\n",
    "        for b in range(B):\n",
    "            boundaries_b = boundaries[b].float()\n",
    "            edgemaps_b = self.edgemaps[b].float()\n",
    "            print(boundaries_b.dtype, edgemaps_b.dtype)\n",
    "            print(boundary_lengths[b], self.edgemaps_len[b])\n",
    "            res, _ = chamfer_distance(  x=boundaries_b,\n",
    "                                        y=edgemaps_b,\n",
    "                                        x_lengths=boundary_lengths[b].long(),\n",
    "                                        y_lengths=self.edgemaps_len[b].long(),\n",
    "                                        batch_reduction=\"mean\",\n",
    "                                        point_reduction=\"mean\")\n",
    "            chamfer_loss[b] = res.sum()\n",
    "        return chamfer_loss.double()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = [os.path.join(\"../../../Blender/\", f\"{name}_2.obj\") for name in [\"sphere\", \"balloon\", \"parabola\", \"rstrawberry\"]]\n",
    "sphere, balloon, parabola, rstrawberry = load_objs_as_meshes(paths)\n",
    "\n",
    "def outer_problem(src: Meshes, tgt: Meshes, projmats, edgemap_info, n_iters, lr, moment, verbose=True):\n",
    "    node = ConstrainedProjectionNode(src, tgt)\n",
    "    verts_init = src.verts_packed() # (sum Vi, 3)\n",
    "    verts_init.requires_grad = True\n",
    "    # apply solve\n",
    "    projverts_init = ConstrainedProjectionFunction.apply(node, verts_init) # (sum Vi, 3)\n",
    "\n",
    "    chamfer_loss = PyTorchChamferLoss(src, tgt, projmats, edgemap_info)\n",
    "    history = [projverts_init]\n",
    "    verts = verts_init.clone().detach().requires_grad_(True)\n",
    "    optimiser = torch.optim.SGD([verts], lr=lr, momentum=moment)\n",
    "\n",
    "    # verts_prev = None\n",
    "    for i in range(n_iters):\n",
    "        optimiser.zero_grad()\n",
    "        projverts = ConstrainedProjectionFunction.apply(node, verts)\n",
    "        history.append(projverts.detach().clone())\n",
    "        # verts_prev = projverts\n",
    "\n",
    "        loss = chamfer_loss(projverts)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{i:4d} Loss: {loss.item()} Gradient: {verts.grad}\")\n",
    "    return verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_renders, load_camera_matrices\n",
    "import cv2\n",
    "from cv2.typing import MatLike\n",
    "\n",
    "# Apply Canny edge detection\n",
    "def canny_edge_map(img: MatLike):\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=50, threshold2=250)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "def get_edgemaps(renders):\n",
    "    edgemaps = {}\n",
    "    edgemaps_len = {}\n",
    "    for k,v in renders.items():\n",
    "        views = {}\n",
    "        views_len = {}\n",
    "        for num, img in v.items():\n",
    "            edges = canny_edge_map(img)\n",
    "            edge_coords = np.argwhere(edges > 0)\n",
    "            views[num] = torch.tensor(edge_coords)\n",
    "            views_len[num] = len(edge_coords)\n",
    "        edgemaps[k] = views\n",
    "        edgemaps_len[k] = views_len\n",
    "    return edgemaps, edgemaps_len\n",
    "\n",
    "renders_path = \"../../../Blender/renders/\"\n",
    "renders = load_renders(renders_path)\n",
    "edgemaps, edgemaps_len = get_edgemaps(renders)\n",
    "matrices_path = \"../../../Blender/cameras\"\n",
    "matrices = load_camera_matrices(matrices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projmats = torch.stack([matrices[\"Camera0\"][\"P\"], \n",
    "                        matrices[\"Camera2\"][\"P\"],\n",
    "                        matrices[\"Camera3\"][\"P\"]])\n",
    "\n",
    "view_idx = [1,3,4]\n",
    "tgt_edgemaps = torch.nn.utils.rnn.pad_sequence([edgemaps[\"balloon\"][i] for i in view_idx], batch_first=True, padding_value=0.0)\n",
    "tgt_edgemaps_len = torch.tensor([edgemaps_len[\"balloon\"][i] for i in view_idx])\n",
    "tgt_edgemap_info = [tgt_edgemaps], [tgt_edgemaps_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_problem(sphere, parabola, projmats, tgt_edgemap_info, n_iters=20, lr=1e-4,moment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
