{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torch import cos, sin\n",
    "import scipy.optimize as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ddn/\")\n",
    "from ddn.pytorch.node import *\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import sample_farthest_points\n",
    "from descartes import PolygonPatch\n",
    "from pytorch3d.io import IO, load_obj, save_obj,load_objs_as_meshes\n",
    "from pytorch3d.structures import join_meshes_as_batch, Meshes, Pointclouds\n",
    "\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from alpha_shapes import Alpha_Shaper, plot_alpha_shape\n",
    "from torch import Tensor, tensor\n",
    "\n",
    "import shapely\n",
    "import os\n",
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def least_squares(u0, tgt_vtxs):\n",
    "    \"\"\"\n",
    "    u0 are vertices\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(u0):\n",
    "        u0 = torch.tensor(u0)\n",
    "    if not torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "    res = torch.square(u0 - tgt_vtxs.flatten()).sum()\n",
    "    return res.double()\n",
    "\n",
    "def least_squares_grad(u0, tgt_vtxs):\n",
    "    if torch.is_tensor(u0):\n",
    "        u0 = u0.detach().clone()\n",
    "    else:\n",
    "        u0 = torch.tensor(u0)\n",
    "    if torch.is_tensor(tgt_vtxs):\n",
    "        tgt_vtxs = tgt_vtxs.detach().clone()\n",
    "    else:\n",
    "        tgt_vtxs = torch.tensor(tgt_vtxs)\n",
    "        \n",
    "    # Ensure that u0 requires gradients\n",
    "    gradient = 2 * (u0 - tgt_vtxs.flatten())\n",
    "    return gradient.double()\n",
    "\n",
    "\n",
    "def calculate_volume(vertices, faces):\n",
    "    face_vertices = vertices[faces]  # (F, 3, 3)\n",
    "    v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "    \n",
    "    # Compute determinant of the 3x3 matrix [v0, v1, v2]\n",
    "    face_volumes = torch.det(torch.stack([v0, v1, v2], dim=-1)) / 6.0  # Shape: (F,)\n",
    "    volume = face_volumes.sum()\n",
    "    return volume.abs()\n",
    "\n",
    "\n",
    "def volume_constraint(x, faces, tgt_vol):\n",
    "    \"\"\"\n",
    "    Calculate the volume of a mesh using PyTorch tensors.\n",
    "    Args:\n",
    "        vertices_torch: Nx3 tensor of vertex coordinates\n",
    "        faces: Mx3 array of face indices\n",
    "    Returns:\n",
    "        volume: Total volume of the mesh as a PyTorch scalar\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x)\n",
    "    if not torch.is_tensor(faces):\n",
    "        faces = torch.tensor(faces)\n",
    "    if not torch.is_tensor(tgt_vol):\n",
    "        tgt_vol = torch.tensor(tgt_vol)\n",
    "\n",
    "    vertices = x.view(-1,3)\n",
    "    faces = faces.view(-1,3).int()\n",
    "    volume = calculate_volume(vertices, faces)\n",
    "    res = volume.abs() - tgt_vol\n",
    "    return res.double()\n",
    "\n",
    "def volume_constraint_grad(x, faces):\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.detach().clone()\n",
    "    else:\n",
    "        x = torch.tensor(x)\n",
    "    if torch.is_tensor(faces):\n",
    "        faces = faces.detach().clone()\n",
    "    else:\n",
    "        faces = torch.tensor(faces)\n",
    "    faces = faces.to(dtype=torch.int64)\n",
    "\n",
    "    vertices_torch = x.view(-1, 3)\n",
    "    p0 = vertices_torch[faces[:, 0]]  # (F, 3)\n",
    "    p1 = vertices_torch[faces[:, 1]]  # (F, 3)\n",
    "    p2 = vertices_torch[faces[:, 2]]  # (F, 3)\n",
    "\n",
    "    grad_p0 = torch.cross(p1, p2, dim=1) / 6.0\n",
    "    grad_p1 = torch.cross(p2, p0, dim=1) / 6.0\n",
    "    grad_p2 = torch.cross(p0, p1, dim=1) / 6.0\n",
    "\n",
    "    grad_verts = torch.zeros_like(vertices_torch)\n",
    "    grad_verts.scatter_add_(0, faces[:, 0].unsqueeze(1).expand(-1, 3), grad_p0)\n",
    "    grad_verts.scatter_add_(0, faces[:, 1].unsqueeze(1).expand(-1, 3), grad_p1)\n",
    "    grad_verts.scatter_add_(0, faces[:, 2].unsqueeze(1).expand(-1, 3), grad_p2)\n",
    "\n",
    "    analytical_grad = grad_verts.flatten()\n",
    "    return analytical_grad \n",
    "\n",
    "def padded_to_packed(xs, lengths):\n",
    "    packed = []\n",
    "    batch_size = xs.size(0)\n",
    "    for b in range(batch_size):\n",
    "        n = lengths[b]\n",
    "        packed.append(xs[b][:n])\n",
    "    packed = torch.cat(packed, dim=0)\n",
    "    return packed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y* = argmin ||X - tgt||^2\n",
    "\n",
    "target depends on input X\n",
    "\n",
    "We have mesh points in 3D <-- X\n",
    "2D edge maps <-- upper level targets\n",
    "\n",
    "lower level: find Y closest to X that satisfy volume constraint, so Y is being optimised in the lower point\n",
    "\n",
    "argmin ||X - Y||^2 s.t. vol(Y) = constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedProjectionNode(EqConstDeclarativeNode):\n",
    "    \"\"\"\n",
    "    Performs a projection of the input points X onto the nearest points Y such that the volume of Y is constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, src: Meshes, tgt: Meshes):\n",
    "        super().__init__(eps=1.0e-6) # relax tolerance on optimality test \n",
    "        self.src = src # source meshes (B,)\n",
    "        # self.tgt = tgt # target meshes (B,)\n",
    "        self.b = len(src)\n",
    "\n",
    "    def objective(self, xs: torch.Tensor, y: torch.Tensor, scatter_add=False):\n",
    "        \"\"\"\n",
    "        Calculates sum of squared differences between source and target meshes.\n",
    "\n",
    "        Args:\n",
    "            xs (torch.Tensor): a padded (B, max Vi, 3) tensor of the original vertices\n",
    "            y (torch.Tensor): a padded (B, max Vi, 3) tensor of the projected vertices        \n",
    "        \"\"\"\n",
    "        src_verts = padded_to_packed(xs, self.src.num_verts_per_mesh()).view(-1,3)\n",
    "        tgt_verts = padded_to_packed(y, self.src.num_verts_per_mesh()).view(-1,3)\n",
    "\n",
    "        sqr_diffs = torch.square(src_verts - tgt_verts).sum(dim=-1) # (sum(V_i))\n",
    "        n_batches = len(self.src)\n",
    "        sse = torch.zeros(n_batches, dtype=sqr_diffs.dtype)\n",
    "        if scatter_add:\n",
    "            sse.scatter_add_(0, self.src.verts_packed_to_mesh_idx(), sqr_diffs)\n",
    "        else:\n",
    "            n_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_vert = self.src.mesh_to_verts_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_vert[i]\n",
    "                end = start + n_verts_per_mesh[i]\n",
    "                sse[i] = sqr_diffs[start:end].sum()  # Sum over all faces\n",
    "        return sse\n",
    "\n",
    "    def equality_constraints(self, xs, y, scatter_add=False):\n",
    "        \"\"\"\n",
    "        Enforces volume constraint of projected points\n",
    "        Assumes same number of vertices in each projected mesh currently\n",
    "\n",
    "        Args:\n",
    "            xs (torch.Tensor): a padded (B, max Vi, 3) tensor of the original vertices\n",
    "            y (torch.Tensor): a padded (B, max Vi, 3) tensor of the projected vertices\n",
    "        \"\"\"\n",
    "        n_batches = len(self.src)\n",
    "        y_packed = padded_to_packed(y, self.src.num_verts_per_mesh())\n",
    "        verts_packed = y_packed.view(-1,3) # (sum(V_i), 3)\n",
    "\n",
    "        faces_packed = self.src.faces_packed()  # (sum(F_i), 3)\n",
    "        face_vertices = verts_packed[faces_packed]  # (sum(F_i), 3, 3)\n",
    "        \n",
    "        # Calculate tetrahedron volumes for each face\n",
    "        v0, v1, v2 = face_vertices[:, 0, :], face_vertices[:, 1, :], face_vertices[:, 2, :]\n",
    "        cross_product = torch.cross(v0, v1, dim=-1)  # (F, 3)\n",
    "        face_volumes = torch.sum(cross_product * v2, dim=-1) / 6.0  # (F,)\n",
    "        volumes = torch.zeros(n_batches, device=verts_packed.device, dtype=face_volumes.dtype)\n",
    "        if scatter_add:\n",
    "            volumes.scatter_add_(0, self.src.faces_packed_to_mesh_idx(), face_volumes)\n",
    "        else:\n",
    "            n_faces_per_mesh = self.src.num_faces_per_mesh()\n",
    "            for i in range(n_batches):\n",
    "                mesh_to_face = self.src.mesh_to_faces_packed_first_idx()  # Index of first face per mesh\n",
    "                start = mesh_to_face[i]\n",
    "                end = start + n_faces_per_mesh[i]\n",
    "                volumes[i] = face_volumes[start:end].sum()  # Sum over all faces\n",
    "\n",
    "        volumes = volumes.abs()\n",
    "        return volumes  # Shape: (B,)    \n",
    "    \n",
    "    def solve(self, xs: torch.Tensor):\n",
    "        \"\"\"Projects the vertices onto the target mesh vertices across batches.\n",
    "\n",
    "        Args:\n",
    "            xs (torch.Tensor): a padded (B, max Vi, 3) tensor of vertices in the batched meshes\n",
    "\n",
    "        Returns:\n",
    "            results (torch.Tensor): a padded (B, max Vi, 3) tensor of the projected vertices\n",
    "        \"\"\"\n",
    "        n_batches = len(self.src)\n",
    "        num_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "        results = torch.zeros((n_batches, num_verts_per_mesh.max(), 3), dtype=torch.double)\n",
    "        for batch in range(n_batches):\n",
    "            n_verts = num_verts_per_mesh[batch]\n",
    "            verts = xs[batch][:n_verts].flatten().detach().double().cpu().numpy()\n",
    "            faces = self.src[batch].faces_packed().detach().int().cpu().numpy()\n",
    "            \n",
    "            # Y = xs[batch][:n_verts].flatten().detach().double().cpu() * 2\n",
    "            # Y = Y.numpy()\n",
    "            Y = xs[batch][:n_verts].flatten().detach().double().cpu().numpy() \n",
    "\n",
    "            with torch.no_grad():\n",
    "                src_vtx = self.src[batch].verts_packed().detach()\n",
    "                src_faces = self.src[batch].faces_packed().detach()\n",
    "                vol = calculate_volume(src_vtx, src_faces)\n",
    "\n",
    "            eq_constraint = {\n",
    "                'type': 'eq',\n",
    "                'fun' : lambda u: volume_constraint(u, faces, vol).cpu().numpy(),\n",
    "                'jac' : lambda u: volume_constraint_grad(u, faces).cpu().numpy(),\n",
    "            }\n",
    "\n",
    "            res = opt.minimize(\n",
    "                lambda u: least_squares(u, verts).detach().cpu().numpy(),\n",
    "                Y,\n",
    "                method='SLSQP',\n",
    "                jac=lambda u: least_squares_grad(u, verts).cpu().numpy(),\n",
    "                constraints=[eq_constraint],\n",
    "                options={'ftol': 1e-4, 'iprint': 2, 'maxiter': 100}\n",
    "            )\n",
    "\n",
    "            if not res.success:\n",
    "                print(\"FAILED:\", res.message)\n",
    "            results[batch] = torch.tensor(res.x, dtype=torch.double, requires_grad=True).view(-1,3)\n",
    "        results = torch.nn.utils.rnn.pad_sequence(results, batch_first=True)\n",
    "        return results,None\n",
    "    \n",
    "\n",
    "class ConstrainedProjectionFunction(DeclarativeFunction):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo code:\n",
    "- load in the meshes\n",
    "- inner problem needs access to the vertices, number of meshes, faces, and indexing\n",
    "- outer problem needs access to projected vertices, number of meshes, and indexing. Also needs projection matrices, and edge maps of renders, so perform edge detection of renders beforehand.\n",
    "\n",
    "just provide both with the meshes lol\n",
    "\n",
    "Projection:\n",
    "Get the indexing correct for the vertices, take the projection of these vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer problem\n",
    "\n",
    "def create_padded_tensor(vertices, vert2mesh, max_V, B):\n",
    "    padded = torch.zeros((B, max_V, 3),device=vertices.device)\n",
    "    for i in range(B):\n",
    "        mesh_vertices = vertices[vert2mesh == i]\n",
    "        num_vertices = mesh_vertices.shape[0]\n",
    "        padded[i, :num_vertices, :] = mesh_vertices\n",
    "    return padded\n",
    "\n",
    "def get_boundary(projected_pts, alpha=5.0):\n",
    "    # Create a detached copy for Alpha_Shaper\n",
    "    projected_pts_detached = projected_pts.detach().clone()\n",
    "    \n",
    "    # Use the detached copy with Alpha_Shaper\n",
    "    shaper = Alpha_Shaper(projected_pts_detached)\n",
    "    alpha_shape = shaper.get_shape(alpha)\n",
    "    while isinstance(alpha_shape, shapely.MultiPolygon) or isinstance(alpha_shape, shapely.GeometryCollection):\n",
    "        alpha -= 1\n",
    "        alpha_shape = shaper.get_shape(alpha)\n",
    "    boundary = torch.tensor(alpha_shape.exterior.coords.xy, dtype=torch.double)\n",
    "    \n",
    "    # Find indices of boundary points\n",
    "    boundary_indices = torch.where(\n",
    "        torch.any(torch.isclose(projected_pts_detached[:, None], boundary.T, atol=1e-6).all(dim=-1), dim=1)\n",
    "    )[0]\n",
    "    \n",
    "    # Index back into the original tensor with gradients\n",
    "    boundary_pts = projected_pts[boundary_indices]\n",
    "    return boundary_pts\n",
    "\n",
    "class PyTorchChamferLoss(nn.Module):\n",
    "    def __init__(self, src: Meshes, tgt: Meshes, projmatrices, edgemap_info):\n",
    "        super().__init__()\n",
    "        self.src = src  # (B meshes)\n",
    "        self.tgt = tgt  # (B meshes)\n",
    "        self.projmatrices = projmatrices # (P, 3, 4)\n",
    "        self.edgemaps = edgemap_info[0] # (P, max_Ni, 2)\n",
    "        self.edgemaps_len = edgemap_info[1] # (P,)\n",
    "    \n",
    "    def project_vertices(self, vertices):\n",
    "        \"\"\"\n",
    "        Projects a set of vertices into multiple views using different projection matrices.\n",
    "        Args:\n",
    "            vertices: Tensor of shape (N, 3), representing 3D vertex positions.\n",
    "        Returns:\n",
    "            Tensor of shape (P, N, 2), containing projected 2D points in each view.\n",
    "        \"\"\"\n",
    "        V = vertices.shape[0]\n",
    "        projection_matrices = self.projmatrices\n",
    "\n",
    "        ones = torch.ones((V, 1), dtype=vertices.dtype, device=vertices.device)\n",
    "        vertices_homogeneous = torch.cat([vertices, ones], dim=1).double()  # Shape: (V, 4)\n",
    "\n",
    "        # Perform batched matrix multiplication (P, 3, 4) @ (V, 4, 1) -> (P, V, 3)\n",
    "        projected = torch.einsum(\"pij,vj->pvi\", projection_matrices, vertices_homogeneous)  # (P, V, 3)\n",
    "        \n",
    "        projected_cartesian = projected[:, :, :2] / projected[:, :, 2:3]  # (P, V, 2)\n",
    "\n",
    "        return projected_cartesian\n",
    "\n",
    "        \n",
    "    def forward(self, y):\n",
    "        B, P = len(self.src), self.projmatrices.size(0)\n",
    "        vertices = y\n",
    "        # project vertices\n",
    "        num_verts_per_mesh = self.src.num_verts_per_mesh()\n",
    "        projected_vertices = [] # (B, P, V, 2)\n",
    "        for b in range(B):\n",
    "            end = num_verts_per_mesh[b]\n",
    "            projverts = self.project_vertices(vertices[b][:end,:])  # Shape: (P, V, 2)\n",
    "            projected_vertices.append(projverts)  # Store without padding\n",
    "\n",
    "        # get boundaries\n",
    "        boundaries = [] \n",
    "        boundary_lengths = torch.zeros(B, P)\n",
    "        for b, batch in enumerate(projected_vertices):\n",
    "            boundaries_b = []\n",
    "            for p, projverts in enumerate(batch):\n",
    "                boundary = get_boundary(projverts)\n",
    "                boundaries_b.append(boundary)\n",
    "                boundary_lengths[b,p] = len(boundary)\n",
    "            padded_boundaries = torch.nn.utils.rnn.pad_sequence(boundaries_b, batch_first=True, padding_value=0.0)\n",
    "            boundaries.append(padded_boundaries)\n",
    "\n",
    "        # perform chamfer\n",
    "        chamfer_loss = torch.zeros(B)\n",
    "        for b in range(B):\n",
    "            boundaries_b = boundaries[b].float()\n",
    "            edgemaps_b = self.edgemaps[b].float()\n",
    "            res, _ = chamfer_distance(  x=boundaries_b,\n",
    "                                        y=edgemaps_b,\n",
    "                                        x_lengths=boundary_lengths[b].long(),\n",
    "                                        y_lengths=self.edgemaps_len[b].long(),\n",
    "                                        batch_reduction=\"mean\",\n",
    "                                        point_reduction=\"mean\")\n",
    "            chamfer_loss[b] = res.sum()\n",
    "        return chamfer_loss.double() * 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_gt(mesh, src:Meshes, tgt:Meshes):\n",
    "    res,_ = chamfer_distance(x=mesh.detach().float(), \n",
    "                             y=tgt.verts_padded().float().detach(),\n",
    "                             x_lengths=src.num_verts_per_mesh(),\n",
    "                             y_lengths=tgt.num_verts_per_mesh(),\n",
    "                             batch_reduction=None,\n",
    "                             point_reduction=\"mean\")\n",
    "    # print(\"Chamfer\", res.size())\n",
    "    return res.tolist() # (B,)\n",
    "\n",
    "\n",
    "def sse_gt(mesh, src:Meshes, tgt:Meshes):\n",
    "    sqr_diff = torch.square(mesh - tgt.verts_padded().detach())\n",
    "    sse = sqr_diff.sum(dim=(1, 2))\n",
    "    # print(\"sqrdiff\", sqr_diff.size(),\"sse\", sse.size(), \"tgt\", tgt.verts_padded().size())\n",
    "    return sse.tolist() # (B,)\n",
    "\n",
    "\n",
    "def iou_gt(mesh, src:Meshes, tgt:Meshes,engine='manifold'):\n",
    "    batch_size = len(mesh)\n",
    "    ious = []\n",
    "    gt = tgt.verts_padded()\n",
    "    for b in range(batch_size):\n",
    "        num_verts_src = src.num_verts_per_mesh()[b].item()\n",
    "        num_verts_tgt = tgt.num_verts_per_mesh()[b].item()\n",
    "        \n",
    "        mesh_trimesh = trimesh.Trimesh(vertices=mesh[b][:num_verts_src].detach().cpu().numpy(), \n",
    "                                       faces=src[b].faces_packed().detach().cpu().numpy())\n",
    "        gt_trimesh = trimesh.Trimesh(vertices=gt[b][:num_verts_tgt].detach().cpu().numpy(), \n",
    "                                     faces=tgt[b].faces_packed().detach().cpu().numpy())\n",
    "        intersection = mesh_trimesh.intersection(other=gt_trimesh, engine=engine)\n",
    "        union = mesh_trimesh.union(other=gt_trimesh, engine=engine)\n",
    "        \n",
    "        if union.volume == 0:  # Handle edge case\n",
    "            iou = 0.0\n",
    "        else:\n",
    "            iou = intersection.volume / union.volume\n",
    "        ious.append(iou)\n",
    "    return ious # (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projections(projverts, projmats, edgemaps):\n",
    "    plt.ioff()  # Disable interactive mode\n",
    "\n",
    "    P, _, _ = projmats.shape\n",
    "    edge_coords, edge_lens = edgemaps\n",
    "\n",
    "    # Choose grid layout (e.g., 3x4 for 12)\n",
    "    cols = 4\n",
    "    rows = math.ceil(P / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes = axes.flatten()  # Flatten for easy indexing\n",
    "\n",
    "    for i in range(P):\n",
    "        proj_2d_hom = (projmats[i] @ torch.cat([projverts, torch.ones(projverts.shape[0], 1)], dim=1).T).T\n",
    "        proj_2d = proj_2d_hom[:, :2] / proj_2d_hom[:, 2:3]  # Normalize by depth\n",
    "\n",
    "        boundary_pts = get_boundary(proj_2d)\n",
    "        valid_edges = edge_coords[i, :edge_lens[i]]\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.scatter(proj_2d[:, 0], proj_2d[:, 1], c='b', s=8, label=\"Projected Vertices\")\n",
    "        ax.scatter(valid_edges[:, 0], valid_edges[:, 1], c='r', s=1, label=\"Edge Coordinates\")\n",
    "        ax.scatter(boundary_pts[:, 0], boundary_pts[:, 1], c='g', s=3, label=\"Boundary Points\")\n",
    "\n",
    "        ax.set_title(f\"Projection {i+1}\", fontsize=10)\n",
    "        ax.set_xlabel(\"x\", fontsize=8)\n",
    "        ax.set_ylabel(\"y\", fontsize=8)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "        ax.axis(\"equal\")\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    # Turn off any unused subplots\n",
    "    for j in range(P, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def visualise_meshes(srcmesh, tgtmesh):\n",
    "    vertices = np.asarray(srcmesh.verts_packed())\n",
    "    faces = np.asarray(srcmesh.faces_packed())\n",
    "\n",
    "    # Create a Plotly 3D mesh\n",
    "    fig = go.Figure(data=[go.Mesh3d(\n",
    "        x=vertices[:, 0],\n",
    "        y=vertices[:, 1],\n",
    "        z=vertices[:, 2],\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        opacity=1,\n",
    "        color=\"lightblue\"\n",
    "    )])\n",
    "\n",
    "    vertices = np.asarray(tgtmesh.verts_packed())\n",
    "    faces = np.asarray(tgtmesh.faces_packed())\n",
    "\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=vertices[:, 0],\n",
    "        y=vertices[:, 1],\n",
    "        z=vertices[:, 2],\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        opacity=0.1,\n",
    "        color=\"red\"\n",
    "    ))\n",
    "\n",
    "    # Update layout for better presentation\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"X\"),\n",
    "            yaxis=dict(title=\"Y\"),\n",
    "            zaxis=dict(title=\"Z\"),\n",
    "        ),\n",
    "        title=\"3D Mesh Visualization\"\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "def visualise_heatmap(src: Meshes, tgt: Meshes, cmin=None, cmax=None):\n",
    "    mesh_X = trimesh.Trimesh(vertices=src[0].verts_packed().detach().cpu().numpy(), \n",
    "                                faces=src[0].faces_packed().detach().cpu().numpy())\n",
    "    mesh_Y = trimesh.Trimesh(vertices=tgt[0].verts_packed().detach().cpu().numpy(), \n",
    "                                faces=tgt[0].faces_packed().detach().cpu().numpy())\n",
    "\n",
    "    # Get vertices\n",
    "    X_vertices = mesh_X.vertices\n",
    "    Y_tree = trimesh.proximity.ProximityQuery(mesh_Y)\n",
    "\n",
    "    # For each vertex in X, find closest point on Y\n",
    "    closest_points, _, _ = Y_tree.on_surface(X_vertices)\n",
    "\n",
    "    # Compute signed distance based on norm from origin\n",
    "    X_norms = np.linalg.norm(X_vertices, axis=1)\n",
    "    Y_norms = np.linalg.norm(closest_points, axis=1)\n",
    "    signed_dists = X_norms - Y_norms  # positive = further out than Y\n",
    "\n",
    "    # Normalize or clip for better colormap contrast if needed\n",
    "    max_val = np.max(np.abs(signed_dists))\n",
    "    if cmin is None or cmax is None:\n",
    "        cmin, cmax = -max_val, max_val  # white will now be centered at 0\n",
    "\n",
    "    # Plot using Plotly\n",
    "    i, j, k = mesh_X.faces.T\n",
    "    fig = go.Figure(data=[\n",
    "        go.Mesh3d(\n",
    "            x=X_vertices[:, 0],\n",
    "            y=X_vertices[:, 1],\n",
    "            z=X_vertices[:, 2],\n",
    "            i=i, j=j, k=k,\n",
    "            intensity=signed_dists,\n",
    "            colorscale='RdBu',\n",
    "            reversescale=True,\n",
    "            cmin=cmin,\n",
    "            cmax=cmax,\n",
    "            colorbar=dict(title='Signed Distance'),\n",
    "            showscale=True,\n",
    "            # flatshading=True,\n",
    "            lighting=dict(ambient=0.8, diffuse=0.9),\n",
    "            lightposition=dict(x=100, y=200, z=0),\n",
    "            opacity=1.0\n",
    "        )\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "        title='Mesh X Colored by Signed Distance from Mesh Y',\n",
    "        scene=dict(aspectmode='data')\n",
    "    )\n",
    "    fig.show()\n",
    "    return cmin,cmax\n",
    "\n",
    "\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def outer_problem(src: Meshes, tgt: Meshes, projmats, edgemap_info, n_iters, lr, moment, verbose=True):\n",
    "    node = ConstrainedProjectionNode(src, tgt)\n",
    "    verts_init = src.verts_padded() # (B, max Vi, 3)\n",
    "    verts_init.requires_grad = True\n",
    "    projverts_init = node.solve(verts_init)\n",
    "    # apply solve\n",
    "    projverts_init = ConstrainedProjectionFunction.apply(node, verts_init) # (B, max Vi, 3)\n",
    "\n",
    "    chamfer_loss = PyTorchChamferLoss(src, tgt, projmats, edgemap_info)\n",
    "\n",
    "    history = [projverts_init]\n",
    "    verts = verts_init.clone().detach().requires_grad_(True)\n",
    "\n",
    "    optimiser = torch.optim.SGD([verts], lr=lr, momentum=moment)\n",
    "    a,b = edgemap_info\n",
    "    a,b = a[0], b[0]\n",
    "\n",
    "    plot_projections(verts.detach().squeeze().double(), projmats, (a,b))\n",
    "    cmin, cmax = None,None\n",
    "    min_loss = float(\"inf\")\n",
    "    best_verts = None\n",
    "    # verts_prev = None\n",
    "    for i in range(n_iters):\n",
    "        optimiser.zero_grad(set_to_none=True)\n",
    "        projverts = ConstrainedProjectionFunction.apply(node, verts)\n",
    "        history.append(projverts.detach().clone())\n",
    "        loss = chamfer_loss(projverts)\n",
    "        colour = bcolors.FAIL\n",
    "        if loss.item() < min_loss:\n",
    "            min_loss = loss.item()\n",
    "            best_verts = projverts.detach().clone()\n",
    "            colour = bcolors.OKGREEN\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        if verbose:\n",
    "            # print(f\"{i:4d} Loss: {loss.item()} Gradient: {verts.grad}\")\n",
    "            # SSE: {(torch.norm(projverts - verts_init)**2).sum()} Chamfer: {chamfer_distance(projverts.float(),verts_init.float())[0].sum()}\n",
    "            print(f\"{i:4d} Loss: {colour}{loss.item():.3f}{bcolors.ENDC} Volume: {calculate_volume(projverts[0], src[0].faces_packed()):.3f}\")\n",
    "            print(f\"GT Chamfer: [{', '.join(f'{x:.3f}' for x in chamfer_gt(projverts, src, tgt))}] \"\n",
    "                # f\"GT SSE: [{', '.join(f'{x:.3f}' for x in sse_gt(projverts, src, tgt))}] \"\n",
    "                f\"GT IoU: [{', '.join(f'{x:.3f}' for x in iou_gt(projverts, src, tgt))}]\")\n",
    "            if i % 10 == 9:\n",
    "                cmin, cmax = visualise_heatmap(Meshes(verts=projverts.detach(), faces=src[0].faces_packed().unsqueeze(0)), tgt[0], cmin,cmax)\n",
    "                plot_projections(projverts.detach().squeeze().double(), gt_projmats, gt_edgemap_info)\n",
    "    return best_verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_renders, load_camera_matrices, get_projmats_and_edgemap_info\n",
    "import cv2\n",
    "from cv2.typing import MatLike\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "# Apply Canny edge detection\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    # edge_map = cv2.Canny(img_greyscale, threshold1=20, threshold2=100)\n",
    "    # edge_map = cv2.Canny(img_greyscale, threshold1=15, threshold2=250)\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "def get_edgemaps(renders, mesh_name, options):\n",
    "    edgemaps = {}\n",
    "    edgemaps_len = {}\n",
    "    if mesh_name in renders:\n",
    "        views = {}\n",
    "        views_len = {}\n",
    "        for num, img in renders[mesh_name].items():\n",
    "            edges = canny_edge_map(img, options[num])\n",
    "            if False:\n",
    "                edge_coords = np.argwhere(edges > 0)\n",
    "                edge_coords = edge_coords[:, [1,0]]\n",
    "            else:\n",
    "                contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                all_subpixel_edges = []\n",
    "                print(\"number of contours\", len(contours))\n",
    "                for contour in contours:\n",
    "                    if len(contour) < 5:\n",
    "                        continue\n",
    "                    contour = contour.squeeze()  # Remove single-dim (N,1,2) -> (N,2)\n",
    "                    x, y = contour[:, 0], contour[:, 1]\n",
    "\n",
    "                    # Fit a spline to the contour\n",
    "                    try:\n",
    "                        tck, u = splprep([x, y], s=1.0)  # s controls smoothing\n",
    "                        u_fine = np.linspace(0, 1, len(x)*2)  # More points = higher \"resolution\"\n",
    "                        x_fine, y_fine = splev(u_fine, tck)\n",
    "\n",
    "                        subpixel_points = np.vstack((x_fine, y_fine)).T\n",
    "                        all_subpixel_edges.append(subpixel_points)\n",
    "                        edge_coords = np.concatenate(all_subpixel_edges)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Skipping a contour due to error: {e}\")\n",
    "                        continue\n",
    "            views[num] = torch.tensor(edge_coords)\n",
    "            views_len[num] = len(edge_coords)\n",
    "        edgemaps[mesh_name] = views\n",
    "        edgemaps_len[mesh_name] = views_len\n",
    "    return edgemaps, edgemaps_len\n",
    "\n",
    "\n",
    "paths = [os.path.join(\"../data/meshes/\", f\"{name}_2.obj\") for name in [\"sphere\", \"balloon\", \"parabola\", \"rstrawberry\"]]\n",
    "sphere, balloon, parabola, rstrawberry = load_objs_as_meshes(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertices(verts_list):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if not isinstance(verts_list, list):\n",
    "        x, y, z = verts_list.clone().detach().cpu().squeeze().unbind(1)\n",
    "        ax.scatter3D(x, z, -y)\n",
    "    else:\n",
    "        colors = ['b',  'g', 'r' , 'm', 'c', 'y']  # Define some colors for different sets\n",
    "        marker_size = 5  # Make points smaller\n",
    "    \n",
    "        for i, verts in enumerate(verts_list):\n",
    "            x, y, z = verts.clone().detach().cpu().squeeze().unbind(1)\n",
    "            ax.scatter3D(x, z, -y, color=colors[i % len(colors)], s=marker_size, label=f\"Set {i+1}\")    \n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.view_init(190, 30)\n",
    "    ax.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renders_path = \"../data/urban/renders\"\n",
    "renders = load_renders(renders_path)\n",
    "options = [\n",
    "    (False, 40, 250),\n",
    "    (False, 40, 250), # skip, bad one\n",
    "    (False, 40, 250),\n",
    "    (False, 10, 300)\n",
    "]\n",
    "edgemaps, edgemaps_len = get_edgemaps(renders,options)\n",
    "matrices_path = \"../data/urban/cameras\"\n",
    "matrices = load_camera_matrices(matrices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_volume(sphere.verts_packed(), sphere.faces_packed()), calculate_volume(balloon.verts_packed(), balloon.faces_packed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_idx = [0,2,3]\n",
    "tgt = \"balloon\"\n",
    "projmats, tgt_edgemap_info = get_projmats_and_edgemap_info(view_idx, tgt, matrices, edgemaps, edgemaps_len)\n",
    "batch_tgt_edgemap_info = ([tgt_edgemap_info[0]],[tgt_edgemap_info[1]])\n",
    "final_verts = outer_problem(sphere, balloon, projmats, batch_tgt_edgemap_info, n_iters=50, lr=1e-6,moment=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = np.asarray(final_verts.squeeze())\n",
    "# vertices = np.asarray(balloon.verts_packed())\n",
    "faces = np.asarray(sphere.faces_packed())\n",
    "\n",
    "# Create a Plotly 3D mesh\n",
    "fig = go.Figure(data=[go.Mesh3d(\n",
    "    x=vertices[:, 0],\n",
    "    y=vertices[:, 1],\n",
    "    z=vertices[:, 2],\n",
    "    i=faces[:, 0],\n",
    "    j=faces[:, 1],\n",
    "    k=faces[:, 2],\n",
    "    opacity=1,\n",
    "    color=\"lightblue\"\n",
    ")])\n",
    "\n",
    "vertices = np.asarray(balloon.verts_packed())\n",
    "faces = np.asarray(sphere.faces_packed())\n",
    "\n",
    "fig.add_trace(go.Mesh3d(\n",
    "    x=vertices[:, 0],\n",
    "    y=vertices[:, 1],\n",
    "    z=vertices[:, 2],\n",
    "    i=faces[:, 0],\n",
    "    j=faces[:, 1],\n",
    "    k=faces[:, 2],\n",
    "    opacity=0.1,\n",
    "    color=\"red\"\n",
    "))\n",
    "\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#     x=vertices[:, 0],\n",
    "#     y=vertices[:, 1],\n",
    "#     z=vertices[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=4,  # Adjust size of the points\n",
    "#         color='red',  # Color of the vertices\n",
    "#         opacity=1\n",
    "#     )\n",
    "# ))\n",
    "\n",
    "# Update layout for better presentation\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"X\"),\n",
    "        yaxis=dict(title=\"Y\"),\n",
    "        zaxis=dict(title=\"Z\"),\n",
    "    ),\n",
    "    title=\"3D Mesh Visualization\"\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vertices(sphere.verts_packed())\n",
    "plot_vertices(final_verts)\n",
    "plot_vertices(balloon.verts_packed())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sky background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renders_path = \"../data/sky/renders\"\n",
    "renders = load_renders(renders_path)\n",
    "# edgemaps, edgemaps_len = get_edgemaps(renders,t1=20,t2=150)\n",
    "matrices_path = \"../data/sky/cameras\"\n",
    "matrices = load_camera_matrices(matrices_path)\n",
    "paths = [os.path.join(\"../data/meshes/\", f\"{name}_3.obj\") for name in [\"sphere\"]]\n",
    "sphere = load_objs_as_meshes(paths)\n",
    "paths = [os.path.join(\"../data/meshes/\", f\"{name}.obj\") for name in [\"balloon\", \"parabola\", \"rstrawberry\"]]\n",
    "balloon, parabola, rstrawberry = load_objs_as_meshes(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "view_idx = [0,1,2,3,5,6,7,8,9,10,11]\n",
    "tgt = \"balloon\"\n",
    "options=[\n",
    "    (True, 80, 700), #0\n",
    "    (False, 5, 120),\n",
    "    (False, 10, 180),\n",
    "    (True, 40, 600),\n",
    "    (False, 10, 120),\n",
    "    (False, 0, 180), # bad\n",
    "    (True, 200, 900),\n",
    "    (False, 10, 200),\n",
    "    (False, 10, 200),\n",
    "    (False, 20, 250),\n",
    "    (False, 0, 300),\n",
    "    (True, 200, 900), # meh\n",
    "]\n",
    "edgemaps, edgemaps_len = get_edgemaps(renders,tgt,options)\n",
    "projmats, tgt_edgemap_info = get_projmats_and_edgemap_info(view_idx, tgt, matrices, edgemaps, edgemaps_len)\n",
    "batch_tgt_edgemap_info = ([tgt_edgemap_info[0]],[tgt_edgemap_info[1]])\n",
    "\n",
    "gt_projmats, gt_edgemap_info = get_projmats_and_edgemap_info(list(range(12)), tgt, matrices, edgemaps, edgemaps_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projections(sphere.verts_packed().detach().double(), gt_projmats, gt_edgemap_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_verts = outer_problem(sphere, balloon, projmats, batch_tgt_edgemap_info, n_iters=50, lr=1e-6,moment=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def crop_img(img, bg_color=(255, 255, 255), threshold=5):\n",
    "    bg = Image.new(img.mode, img.size, bg_color)\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    mask = diff.convert('L').point(lambda p: 255 if p > threshold else 0)\n",
    "    bbox = mask.getbbox()\n",
    "    return img.crop(bbox) if bbox else img\n",
    "\n",
    "\n",
    "def scale_and_crop(img, target_w, target_h):\n",
    "    original_w, original_h = img.size\n",
    "    scale_factor = max(target_w / original_w, target_h / original_h) + 0.1\n",
    "    scaled_img = img.resize((int(original_w * scale_factor), int(original_h * scale_factor)), Image.LANCZOS)\n",
    "\n",
    "    left = (scaled_img.width - target_w) // 2\n",
    "    upper = (scaled_img.height - target_h) // 2\n",
    "    return scaled_img.crop((left, upper, left + target_w, upper + target_h))\n",
    "\n",
    "\n",
    "def compute_signed_distances(src, tgt):\n",
    "    mesh_X = trimesh.Trimesh(vertices=src[0].verts_packed().cpu().numpy(), faces=src[0].faces_packed().cpu().numpy())\n",
    "    mesh_Y = trimesh.Trimesh(vertices=tgt[0].verts_packed().cpu().numpy(), faces=tgt[0].faces_packed().cpu().numpy())\n",
    "    X_vertices = mesh_X.vertices\n",
    "    Y_tree = trimesh.proximity.ProximityQuery(mesh_Y)\n",
    "    closest_points, _, _ = Y_tree.on_surface(X_vertices)\n",
    "    \n",
    "    X_norms = np.linalg.norm(X_vertices, axis=1)\n",
    "    Y_norms = np.linalg.norm(closest_points, axis=1)\n",
    "    return X_norms - Y_norms\n",
    "\n",
    "\n",
    "def generate_3d_visualization(src, tgt, signed_dists, cmin, cmax):\n",
    "    mesh_X = trimesh.Trimesh(vertices=src[0].verts_packed().cpu().numpy(), faces=src[0].faces_packed().cpu().numpy())\n",
    "    i, j, k = mesh_X.faces.T\n",
    "    return go.Figure(data=[\n",
    "        go.Mesh3d(\n",
    "            x=mesh_X.vertices[:, 0],\n",
    "            y=mesh_X.vertices[:, 1],\n",
    "            z=mesh_X.vertices[:, 2],\n",
    "            i=i, j=j, k=k,\n",
    "            intensity=signed_dists,\n",
    "            colorscale='RdBu',\n",
    "            reversescale=True,\n",
    "            cmin=cmin, cmax=cmax,\n",
    "            colorbar=dict(title='Signed Distance'),\n",
    "            showscale=False,\n",
    "            flatshading=True,\n",
    "            lighting=dict(ambient=0.8, diffuse=0.7),\n",
    "            lightposition=dict(x=100, y=200, z=0),\n",
    "            opacity=1.0\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "def capture_camera_views(fig, camera_views, target_w, target_h):\n",
    "    images = []\n",
    "    for cam in camera_views:\n",
    "        fig.update_layout(scene_camera=cam)\n",
    "        png_bytes = pio.to_image(fig, format='png', width=400, height=400)\n",
    "        img = Image.open(BytesIO(png_bytes)).convert('RGB')\n",
    "        img = crop_img(img)\n",
    "        images.append(scale_and_crop(img, target_w, target_h))\n",
    "    return images\n",
    "\n",
    "\n",
    "def create_colorbar(cmin, cmax):\n",
    "    dummy_fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=[0], y=[0], z=[0],\n",
    "        mode='markers',\n",
    "        marker=dict(size=0.0001, color=[0], colorscale='RdBu', cmin=cmin, cmax=cmax, colorbar=dict(title=' '))\n",
    "    )])\n",
    "    dummy_fig.update_layout(scene=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)),\n",
    "                            margin=dict(l=0, r=0, t=0, b=0), showlegend=False)\n",
    "    colorbar_img = Image.open(BytesIO(pio.to_image(dummy_fig, format='png', width=200, height=400)))\n",
    "    return crop_img(colorbar_img)\n",
    "\n",
    "\n",
    "def create_final_image(images, colorbar_img, target_w, target_h):\n",
    "    grid = Image.new('RGB', (2 * target_w, 2 * target_h))\n",
    "    grid.paste(images[0], (0, 0))\n",
    "    grid.paste(images[1], (target_w, 0))\n",
    "    grid.paste(images[2], (0, target_h))\n",
    "    grid.paste(images[3], (target_w, target_h))\n",
    "\n",
    "    final_img = Image.new('RGB', (2 * target_w + colorbar_img.width, 2 * target_h), color=(255, 255, 255))\n",
    "    final_img.paste(grid, (0, 0))\n",
    "    final_img.paste(colorbar_img, (2 * target_w, (2 * target_h - colorbar_img.height) // 2))\n",
    "    return final_img\n",
    "\n",
    "\n",
    "def visualise_heatmap(src, tgt, cmin=None, cmax=None):\n",
    "    signed_dists = compute_signed_distances(src, tgt)\n",
    "    if cmin is None or cmax is None:\n",
    "        max_val = np.max(np.abs(signed_dists))\n",
    "        cmin, cmax = -max_val, max_val\n",
    "\n",
    "    fig = generate_3d_visualization(src, tgt, signed_dists, cmin, cmax)\n",
    "    camera_views = [\n",
    "        dict(eye=dict(x=1.2, y=1.2, z=1.2)),\n",
    "        dict(eye=dict(x=-1.2, y=1.2, z=1.2)),\n",
    "        dict(eye=dict(x=1.2, y=-1.2, z=1.2)),\n",
    "        dict(eye=dict(x=0.0, y=0.0, z=2.4)),\n",
    "    ]\n",
    "    \n",
    "    images = capture_camera_views(fig, camera_views, 256, 256)\n",
    "    colorbar_img = create_colorbar(cmin, cmax)\n",
    "    final_img = create_final_image(images, colorbar_img, 256, 256)\n",
    "\n",
    "    # Display the final image\n",
    "    dpi = 100  # You can adjust this if needed\n",
    "    figsize = (final_img.width / dpi, final_img.height / dpi)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0, 0, 1, 1])  # [left, bottom, width, height] in figure coordinates\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(final_img)\n",
    "    plt.show()\n",
    "\n",
    "    return cmin, cmax\n",
    "\n",
    "cmin, cmax = visualise_heatmap(Meshes(verts=final_verts.detach(), faces=sphere.faces_packed().unsqueeze(0)), balloon)\n",
    "cmin, cmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_idx = [0,1,2,3,5,6,7,8,11]\n",
    "# view_idx = list(range(12))\n",
    "tgt = \"rstrawberry\"\n",
    "options = [\n",
    "    (True, 40, 400),\n",
    "    (False, 5, 250),\n",
    "    (False, 10, 200),\n",
    "    (True, 100, 400), # 3, bad\n",
    "    (False, 5, 200), # 4, meh\n",
    "    (False, 10, 200),\n",
    "    (False, 15, 220),\n",
    "    (False, 15, 250),\n",
    "    (False, 15, 200),\n",
    "    (True, 150, 500), # 9, bad\n",
    "    (False, 0, 320),\n",
    "    (False, 0, 250)\n",
    "]\n",
    "edgemaps, edgemaps_len = get_edgemaps(renders, options)\n",
    "projmats, tgt_edgemap_info = get_projmats_and_edgemap_info(view_idx, tgt, matrices, edgemaps, edgemaps_len)\n",
    "batch_tgt_edgemap_info = ([tgt_edgemap_info[0]],[tgt_edgemap_info[1]])\n",
    "\n",
    "\n",
    "plot_projections(balloon.verts_packed().double(), projmats, tgt_edgemap_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renders_path = \"../data/sky/renders\"\n",
    "renders = load_renders(renders_path)\n",
    "matrices_path = \"../data/sky/cameras\"\n",
    "matrices = load_camera_matrices(matrices_path)\n",
    "\n",
    "options=[[\n",
    "    (True, 50, 200), #0\n",
    "    (False, 5, 120),\n",
    "    (False, 10, 180),\n",
    "    (True, 40, 600),\n",
    "    (True, 40, 600),\n",
    "    (False, 0, 180), # bad\n",
    "    (True, 200, 900),\n",
    "    (False, 10, 200),\n",
    "    (False, 10, 200),\n",
    "    (False, 20, 250),\n",
    "    (False, 0, 300),\n",
    "    (True, 100, 900), # meh\n",
    "], [\n",
    "    (True, 40, 400),\n",
    "    (False, 5, 250),\n",
    "    (False, 10, 200),\n",
    "    (True, 100, 400), # 3, bad\n",
    "    (False, 5, 200), # 4, meh\n",
    "    (False, 10, 200),\n",
    "    (False, 15, 220),\n",
    "    (False, 15, 250),\n",
    "    (False, 15, 200),\n",
    "    (True, 150, 500), # 9, bad\n",
    "    (False, 0, 320),\n",
    "    (False, 0, 250)\n",
    "]]\n",
    "\n",
    "views = [[0,1,2,3,5,6,7,8,9,10,11],\n",
    "         [0,1,2,3,5,6,7,8,11] \n",
    "         ]\n",
    "\n",
    "\n",
    "def pipeline(src, tgts, tgt_names, views, options):\n",
    "    T = len(tgts)\n",
    "    print(T)\n",
    "    src_mesh = src\n",
    "    renders_path = \"../data/sky/renders\"\n",
    "    renders = load_renders(renders_path)\n",
    "    matrices_path = \"../data/sky/cameras\"\n",
    "    matrices = load_camera_matrices(matrices_path)\n",
    "    for t in range(T):\n",
    "        view_idx = views[t]\n",
    "        tgt_mesh = tgts[t]\n",
    "        edgemaps, edgemaps_len = get_edgemaps(renders, options[t])\n",
    "        projmats, tgt_edgemap_info = get_projmats_and_edgemap_info(view_idx, tgt_names[t], matrices, edgemaps, edgemaps_len)\n",
    "        batch_tgt_edgemap_info = ([tgt_edgemap_info[0]],[tgt_edgemap_info[1]])\n",
    "        final_verts = outer_problem(src_mesh, tgt_mesh, projmats, batch_tgt_edgemap_info, n_iters=20, lr=5e-6,moment=0.5)\n",
    "        src_mesh = Meshes(verts=final_verts, faces=tgt_mesh.faces_padded())\n",
    "        visualise_meshes(src_mesh, tgt_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgts = join_meshes_as_batch([balloon, rstrawberry,parabola])\n",
    "tgt_names = [\"balloon\", \"rstrawberry\",\"parabola\"]\n",
    "pipeline(sphere, tgts, tgt_names, views, options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
