{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torch import cos, sin\n",
    "import scipy.optimize as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../ddn/\")\n",
    "from ddn.pytorch.node import *\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import sample_farthest_points\n",
    "import alpha_shapes\n",
    "from descartes import PolygonPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ellipse area and circumferencce\n",
    "def ellipsoid_volume(a, b,c):\n",
    "    \"\"\"Returns the volume of an ellipsoid parametrized as (x/a)^2 + (y/b)^2 + (z/c)^2 = 1.\"\"\"\n",
    "    return 4/3 * torch.pi * a * b * c\n",
    "\n",
    "def ellipsoid_surface_area(a, b, c, p=1.6075):\n",
    "    \"\"\"Returns the approximate surface area of an ellipsoid.\"\"\"\n",
    "    a_p = a**p\n",
    "    b_p = b**p\n",
    "    c_p = c**p\n",
    "    return 4 * torch.pi * (1/3 * (a_p*b_p + a_p*c_p + b_p*c_p))**(1/p)\n",
    "\n",
    "\n",
    "def rotation_matrix_3d(angles):\n",
    "    alpha, beta, gamma = angles[0], angles[1], angles[2] # yaw, pitch, roll\n",
    "    R = torch.stack([\n",
    "        torch.stack([cos(alpha)*cos(beta), cos(alpha)*sin(beta)*sin(gamma)-sin(alpha)*cos(gamma), cos(alpha)*sin(beta)*cos(gamma)+sin(alpha)*sin(gamma)]),\n",
    "        torch.stack([sin(alpha)*cos(beta), sin(alpha)*sin(beta)*sin(gamma)+cos(alpha)*cos(gamma), sin(alpha)*sin(beta)*cos(gamma)-cos(alpha)*sin(gamma)]),\n",
    "        torch.stack([-sin(beta), cos(beta)*sin(gamma), cos(beta)*cos(gamma)])\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "def generate_ellipsoid_coords(sqrt_m, a, b, c, yaw, pitch, roll):\n",
    "    phi = 2.0 * math.pi * torch.linspace(0.0, 1.0, sqrt_m).double()\n",
    "    theta = math.pi * torch.linspace(0.00, 1.0, sqrt_m).double()\n",
    "    phi, theta = torch.meshgrid(phi, theta)\n",
    "    x = a * torch.sin(theta) * torch.cos(phi)\n",
    "    y = b * torch.sin(theta) * torch.sin(phi)\n",
    "    z = c * torch.cos(theta)\n",
    "    x_flat = x.flatten()\n",
    "    y_flat = y.flatten()\n",
    "    z_flat = z.flatten()\n",
    "    coords = torch.stack((x_flat, y_flat, z_flat), dim=0).double()\n",
    "    angles = torch.tensor([yaw, pitch, roll], requires_grad=True, dtype=torch.float)\n",
    "    rotation_matrix = rotation_matrix_3d(torch.deg2rad(angles)).double()\n",
    "    rotated_coords = rotation_matrix @ coords\n",
    "    return rotated_coords\n",
    "\n",
    "def plot_ellipsoid(ax, a, b, c, yaw, pitch, roll, color='blue', linestyle='-', linewidth=0.5, alpha=0.5, sqrt_m=25):\n",
    "    coords = generate_ellipsoid_coords(sqrt_m, a, b, c, yaw, pitch, roll).T.detach()\n",
    "    x_rot = coords[:, 0].reshape(sqrt_m,sqrt_m)\n",
    "    y_rot = coords[:, 1].reshape(sqrt_m,sqrt_m)\n",
    "    z_rot = coords[:, 2].reshape(sqrt_m,sqrt_m)\n",
    "    ax.set_xlabel('$X$')\n",
    "    ax.set_ylabel('$Y$')\n",
    "    ax.set_zlabel('$Z$')\n",
    "\n",
    "    ax.plot_wireframe(x_rot.numpy(), y_rot.numpy(), z_rot.numpy(),\n",
    "                      color=color, linestyle=linestyle, linewidth=linewidth, alpha=alpha)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "def generate_data(sqrt_m, m, a, b, c, yaw, pitch, roll, nu, p):\n",
    "    coords = generate_ellipsoid_coords(sqrt_m, a, b, c, yaw, pitch, roll).detach()\n",
    "    data = coords + nu * torch.randn(3, m, dtype=torch.double)\n",
    "    data = data.unsqueeze(0)\n",
    "    return data\n",
    "\n",
    "def constraint_function(u, p=1.6075):\n",
    "    if not torch.is_tensor(u):\n",
    "        u = torch.tensor(u)\n",
    "    a = u[0]\n",
    "    b = u[1]\n",
    "    c = u[2]\n",
    "    res = 4/3 * torch.pi * (a*b*c) - 1\n",
    "    return res\n",
    "\n",
    "def constraint_function_grad(u):\n",
    "    if torch.is_tensor(u):\n",
    "        u = u.detach().clone()\n",
    "    else:\n",
    "        u = torch.tensor(u)\n",
    "    u.requires_grad = True\n",
    "    with torch.enable_grad():\n",
    "        res = constraint_function(u)\n",
    "    constr_grad = torch.autograd.grad(res, u)[0]\n",
    "    return constr_grad\n",
    "\n",
    "def objective_function(u, X, u_prev=None):\n",
    "    if not torch.is_tensor(u):\n",
    "        u = torch.tensor(u).double()\n",
    "    if not torch.is_tensor(X):\n",
    "        X = torch.tensor(X).double()\n",
    "    L = torch.diag(1/u[:3]**2).double()\n",
    "    R = rotation_matrix_3d(u[3:6]).double() # assumes radians\n",
    "    A = R @ L @ R.T\n",
    "    XT_AX = torch.einsum('ji,jk,ki->i', X, A, X)\n",
    "    b = torch.ones(X.shape[1])\n",
    "    if u_prev is None:\n",
    "        u_prev = u \n",
    "    elif not torch.is_tensor(u_prev):   \n",
    "        u_prev = torch.tensor(u_prev).double()\n",
    "    res = torch.sum((XT_AX - b) ** 2)/100 + torch.norm(u_prev - u)**2/100\n",
    "    # print(res)\n",
    "    return res\n",
    "\n",
    "def objective_function_grad(u, X, u_prev=None):\n",
    "    if torch.is_tensor(u):\n",
    "        u = u.detach().clone()\n",
    "    else:\n",
    "        u = torch.tensor(u)\n",
    "    if torch.is_tensor(X):\n",
    "        X = X.detach().clone()\n",
    "    else:\n",
    "        X = torch.tensor(X).double()\n",
    "    if u_prev is not None:\n",
    "        if torch.is_tensor(u_prev):\n",
    "            u_prev = u_prev.detach().clone()\n",
    "        else:\n",
    "            u_prev = torch.tensor(u_prev)\n",
    "    else:\n",
    "        u_prev = u\n",
    "    u.requires_grad = True\n",
    "    with torch.enable_grad():\n",
    "        res = objective_function(u, X, u_prev).double()\n",
    "    obj_grad = torch.autograd.grad(res, u)[0].double()\n",
    "    return obj_grad\n",
    "\n",
    "# ellipse fitting\n",
    "def fit_ellipsoid(xs, p=1.6075, method=\"default\", with_jac=False, u_prev=None):\n",
    "    \"\"\"Find ellipsoid parameters u = (1/a^2, 1/b^2, 1/c^2) that best fit the data.\"\"\"\n",
    "    n_batches = xs.size(0)\n",
    "    results = torch.zeros(n_batches, 6, dtype=torch.double)\n",
    "    losses = torch.zeros(n_batches, 1, dtype=torch.double)\n",
    "    for batch_number, x in enumerate(xs):\n",
    "        X = x.detach().numpy()\n",
    "        if u_prev is not None:\n",
    "            u0 = u_prev[batch_number].detach().numpy()\n",
    "        else:\n",
    "            u0 = initialise_u(X, method)\n",
    "        if with_jac:\n",
    "            eq_const = {'type': 'eq',\n",
    "                        'fun' : lambda u: constraint_function(u).cpu().numpy(),\n",
    "                        'jac' : lambda u: constraint_function_grad(u).cpu().numpy()\n",
    "                        }\n",
    "            ineq_const = {'type': 'ineq',\n",
    "                        'fun' : lambda u: np.array([2*np.pi - u[3], 2*np.pi - u[4], 2*np.pi - u[5], u[3], u[4], u[5]])}\n",
    "            res = opt.minimize(lambda u: objective_function(u, X, u_prev).detach().cpu().numpy(), u0, jac=lambda u: objective_function_grad(u,X, u_prev).cpu().numpy(), \n",
    "                            method='SLSQP', constraints=[eq_const, ineq_const],\n",
    "                            options={'ftol': 1e-9, 'disp': False, 'maxiter': 200})\n",
    "        else:\n",
    "            eq_const = {'type': 'eq',\n",
    "                        'fun' : lambda u: constraint_function(u).cpu().numpy(),\n",
    "                        }\n",
    "            ineq_const = {'type': 'ineq',\n",
    "                        'fun' : lambda u: np.array([2*np.pi - u[3], 2*np.pi - u[4], 2*np.pi - u[5], u[3], u[4], u[5]])}\n",
    "            res = opt.minimize(lambda u: objective_function(u, X, u_prev).detach().cpu().numpy(), u0,\n",
    "                            method='SLSQP', constraints=[eq_const, ineq_const],\n",
    "                            options={'ftol': 1e-9, 'disp': False, 'maxiter': 200})\n",
    "        if not res.success:\n",
    "            print(\"FIT failed:\", res.message)\n",
    "        results[batch_number] = torch.tensor(res.x, dtype=torch.double, requires_grad=True)\n",
    "        losses[batch_number] = torch.tensor(res.fun, dtype=torch.double, requires_grad=False)\n",
    "    return results, losses\n",
    "\n",
    "\n",
    "def initialise_u(data, method):\n",
    "    if method == \"default\": # random initialisation\n",
    "        u0 = np.ones(6)\n",
    "    elif method == \"bb\":\n",
    "        h,w,l = get_bounding_box_dims(data)/2\n",
    "        u0 = np.zeros(6)\n",
    "        u0[:3] = np.array([h,w,l])\n",
    "        u0[3:] = np.random.uniform(low=0, high=90, size=3)\n",
    "    elif method == \"pca\":\n",
    "        u0 = pca(data)\n",
    "    return u0\n",
    "\n",
    "def get_angles(rotation):\n",
    "    pitch = - np.arcsin(rotation[2,0])\n",
    "    denom = 1/np.sqrt(1 - (rotation[2,0] ** 2))\n",
    "    roll = np.arctan2(rotation[2,1]/denom, rotation[2,2]/denom)\n",
    "    yaw = np.arctan2(rotation[1,0]/denom, rotation[0,0]/denom)\n",
    "    return np.rad2deg([yaw, pitch, roll])\n",
    "\n",
    "def pca(data):\n",
    "    \"\"\"\n",
    "    Get three dominant axes of data along with angles\n",
    "    \"\"\"\n",
    "    data = data.T\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(data)\n",
    "    semiaxes = np.sqrt(pca.explained_variance_ * np.array([2,4,4]))\n",
    "    rotation = np.fliplr(pca.components_)\n",
    "    angles = np.array(get_angles(rotation))\n",
    "    u0 = np.concatenate([semiaxes, angles])\n",
    "    return u0\n",
    "    \n",
    "def extract_params(u):\n",
    "    if torch.any(u) < 0:\n",
    "        print(\"WARNING: Negative axes lengths.\")\n",
    "    a, b, c = (torch.abs(u[:3])).tolist()\n",
    "    yaw, pitch, roll = np.rad2deg(u[3:].tolist()) % 360\n",
    "    return a,b,c,yaw,pitch,roll\n",
    "\n",
    "def get_bounding_box_dims(points):\n",
    "    min_x, min_y, min_z = np.min(points, axis=1)\n",
    "    max_x, max_y, max_z = np.max(points, axis=1)\n",
    "\n",
    "    # Calculate the dimensions of the bounding box\n",
    "    height = max_z - min_z\n",
    "    width = max_x - min_x\n",
    "    length = max_y - min_y\n",
    "    return np.sort([height, width, length])\n",
    "\n",
    "def plot_points(ax, data, color, alpha):\n",
    "    x,y,z = data[0,0:3].detach().numpy()\n",
    "    ax.scatter(x,y,z, color=color, alpha=alpha, s=1)\n",
    "\n",
    "def inner_problem(semiaxes, angles, sqrt_m, nu, p, method=\"default\", with_jac=False):\n",
    "    m = sqrt_m * sqrt_m\n",
    "    if method==\"pca\":\n",
    "        sorted_params = sorted(zip(semiaxes, angles), key=lambda u: u[0])\n",
    "        semiaxes, angles = zip(*sorted_params)\n",
    "    a, b, c = semiaxes\n",
    "    yaw, pitch, roll = np.array(angles)\n",
    "    print(f\"Ellipsoid (blue) ({a:0.3}, {b:0.3}, {c:0.3}, {float(yaw):0.3}\\N{DEGREE SIGN}, {float(pitch):0.3}\\N{DEGREE SIGN}, {float(roll):0.3}\\N{DEGREE SIGN}) has volume {ellipsoid_volume(a, b, c):0.3} and surface area {ellipsoid_surface_area(a, b, c, p):0.3}\")\n",
    "\n",
    "    data = generate_data(sqrt_m, m, a, b, c, yaw, pitch, roll, nu, p)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    plot_ellipsoid(ax, a, b, c, yaw, pitch, roll, color='b')\n",
    "    plot_points(ax, data, 'b', 0.8)\n",
    "\n",
    "    u,l = fit_ellipsoid(data, p, method, with_jac)\n",
    "    a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat = extract_params(u.squeeze().detach())\n",
    "    plot_ellipsoid(ax, a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat, color='r')\n",
    "    print(f\"Ellipsoid (red) ({a_hat:0.3}, {b_hat:0.3}, {c_hat:0.3}, {(yaw_hat):0.4}\\N{DEGREE SIGN}, {(pitch_hat):0.4}\\N{DEGREE SIGN}, {(roll_hat):0.4}\\N{DEGREE SIGN}) has volume {ellipsoid_volume(a_hat, b_hat, c_hat):0.3} and surface area {ellipsoid_surface_area(a_hat, b_hat, c_hat, p):0.3}\")\n",
    "    plt.show()\n",
    "\n",
    "    return m, data, np.array([a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set correct location for DDN repository code and import basic node functionality\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class EllipsoidConstrainedProjectionNode(EqConstDeclarativeNode):\n",
    "    \"\"\"A DDN node for the constrained ellipse projection problem. Gradients will be calculated automatically.\"\"\"\n",
    "\n",
    "    def __init__(self, m):\n",
    "        super().__init__(eps=1.0e-6) # relax tolerance on optimality test \n",
    "        # make sure node is properly constructed\n",
    "        self.n = tuple([3 * m]) # coordinate dimension x number of points\n",
    "        self.m = m # number of points\n",
    "        self.u_prev = None\n",
    "        \n",
    "    def objective(self, xs, y):\n",
    "        # xs: tensor of shape (batch_size, 3 * m)\n",
    "        # y: tensor of shape (batch_size, 6) or (batch_size, 12)\n",
    "        n_batches = xs.size(0)\n",
    "        data = xs.view(n_batches, 3, -1) # shape: (batch_size, 3, m)\n",
    "        # Reshape y to (batch_size, 6, 1) for L_diag and angles extraction\n",
    "        y_ = y[:,:6].view(n_batches, 6, 1)\n",
    "        # Extract L_diag and angles from y\n",
    "        L_diag = y_[:, :3, :].squeeze(2)  # shape: (batch_size, 3)\n",
    "        L_diag = 1/L_diag**2\n",
    "        angles = y_[:, 3:, :]   # shape: (batch_size, 3, 1)\n",
    "        # Compute L matrix for all batches\n",
    "        L = torch.diag_embed(L_diag).double()  # shape: (batch_size, 3, 3)\n",
    "        # Vectorized computation of R matrix for all batches\n",
    "        angles = angles.squeeze(2)  # shape: (batch_size, 3)\n",
    "        cos_angles = torch.cos(angles)\n",
    "        sin_angles = torch.sin(angles)\n",
    "        # Construct the rotation matrix R for all batches\n",
    "        R = torch.zeros((n_batches, 3, 3), dtype=torch.double, device=xs.device)\n",
    "        cos_yaw, cos_pitch, cos_roll = cos_angles[:, 0], cos_angles[:, 1], cos_angles[:, 2]\n",
    "        sin_yaw, sin_pitch, sin_roll = sin_angles[:, 0], sin_angles[:, 1], sin_angles[:, 2]\n",
    "        R[:, 0, 0] = cos_yaw * cos_pitch\n",
    "        R[:, 0, 1] = cos_yaw * sin_pitch * sin_roll - sin_yaw * cos_roll\n",
    "        R[:, 0, 2] = cos_yaw * sin_pitch * cos_roll + sin_yaw * sin_roll\n",
    "        R[:, 1, 0] = sin_yaw * cos_pitch\n",
    "        R[:, 1, 1] = sin_yaw * sin_pitch * sin_roll + cos_yaw * cos_roll\n",
    "        R[:, 1, 2] = sin_yaw * sin_pitch * cos_roll - cos_yaw * sin_roll\n",
    "        R[:, 2, 0] = -sin_pitch\n",
    "        R[:, 2, 1] = cos_pitch * sin_roll\n",
    "        R[:, 2, 2] = cos_pitch * cos_roll\n",
    "        # Compute A matrix for all batches\n",
    "        A = torch.bmm(R, torch.bmm(L, R.transpose(-1, -2)))  # shape: (batch_size, 3, 3)\n",
    "        # Compute XT_AX for all batches using torch.einsum\n",
    "        XT_AX = torch.einsum('bji,bjk,bki->bi', data, A, data)  # shape: (batch_size, m)\n",
    "        # Compute b tensor for all batches\n",
    "        b_ones = torch.ones_like(XT_AX)        \n",
    "        # print(\"Objective value:\", obj_val)\n",
    "        if self.u_prev is None or torch.equal(y[:,:], self.u_prev):\n",
    "            obj_val = torch.sum((XT_AX - b_ones).pow(2), dim=1)\n",
    "        else:\n",
    "            obj_val = torch.sum((XT_AX - b_ones).pow(2), dim=1) + torch.norm(y[:,:] - self.u_prev, p=2)**2\n",
    "        # obj_val = torch.sum((XT_AX - b_ones).pow(2), dim=1) \n",
    "            # print(torch.sum((XT_AX - b_ones).pow(2), dim=1).item(), (torch.norm(y[:,:] - self.u_prev, p=2)**2).item())\n",
    "        self.u_prev = y\n",
    "        if torch.isnan(obj_val).any():\n",
    "            print(\"XTAX\", torch.isnan(XT_AX).any())\n",
    "            print(\"A\", torch.isnan(A).any())\n",
    "            raise ValueError(\"NaNs detected in objective function\")\n",
    "        return obj_val\n",
    "    \n",
    "    def equality_constraints(self, xs, y):\n",
    "        # y is of shape [m x number of parameters] (same as u)  \n",
    "        a = y[:,0]\n",
    "        b = y[:,1]\n",
    "        c = y[:,2]\n",
    "        constraint_val = 4/3 * torch.pi * a * b * c - 1\n",
    "        if torch.isnan(constraint_val).any():\n",
    "            raise ValueError(\"NaNs detected in equality constraints\")\n",
    "        return constraint_val\n",
    "\n",
    "\n",
    "    def solve(self, xs, method=\"default\", with_jac=False):\n",
    "        # process batches independently\n",
    "        n_batches = xs.size(0)\n",
    "        results = torch.zeros(n_batches, 6, dtype=torch.double)\n",
    "        for batch_number, x in enumerate(xs):\n",
    "            assert(len(x) == self.n[0])\n",
    "            X = x.reshape(3, -1).detach().numpy()\n",
    "            if self.u_prev is not None:\n",
    "                # u0 = self.u_prev[batch_number].detach().numpy()\n",
    "                u0 = initialise_u(X, method)\n",
    "            else:\n",
    "                u0 = initialise_u(X, method)\n",
    "            if with_jac:\n",
    "                eq_const = {'type': 'eq',\n",
    "                            'fun' : lambda u: constraint_function(u).cpu().numpy(),\n",
    "                            'jac' : lambda u: constraint_function_grad(u).cpu().numpy()\n",
    "                            }\n",
    "                ineq_const = {'type': 'ineq',\n",
    "                            'fun' : lambda u: np.array([2*np.pi - u[3], 2*np.pi - u[4], 2*np.pi - u[5], u[3], u[4], u[5]])}\n",
    "                res = opt.minimize(lambda u: objective_function(u, X, self.u_prev).detach().cpu().numpy(), u0, jac=lambda u: objective_function_grad(u,X, self.u_prev).cpu().numpy(), \n",
    "                                method='SLSQP', constraints=[eq_const, ineq_const],\n",
    "                                options={'ftol': 1e-9, 'disp': False, 'maxiter': 200})\n",
    "            else:\n",
    "                eq_const = {'type': 'eq',\n",
    "                            'fun' : lambda u: constraint_function(u).cpu().numpy(),\n",
    "                            }\n",
    "                ineq_const = {'type': 'ineq',\n",
    "                            'fun' : lambda u: np.array([2*np.pi - u[3], 2*np.pi - u[4], 2*np.pi - u[5], u[3], u[4], u[5]])}\n",
    "                res = opt.minimize(lambda u: objective_function(u, X, self.u_prev).detach().cpu().numpy(), u0,\n",
    "                                method='SLSQP', constraints=[eq_const, ineq_const],\n",
    "                                options={'ftol': 1e-9, 'disp': False, 'maxiter': 200})\n",
    "            if not res.success:\n",
    "                print(\"SOLVE failed:\", res.message)\n",
    "            results[batch_number] = torch.tensor(res.x, dtype=torch.double, requires_grad=True)\n",
    "            print(\"results.requires_grad\", results.requires_grad)\n",
    "        return results, None\n",
    "\n",
    "\n",
    "class EllipseConstrainedProjectionFunction(DeclarativeFunction):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "def outer_problem(n_pts, data, views, original_params, loss_func, n_iters=20, lr=0.1, method=\"default\", with_jac=False, moment=0):\n",
    "    node = EllipsoidConstrainedProjectionNode(n_pts)\n",
    "\n",
    "    n_batches = data.size(0)\n",
    "    x_init = data.view(n_batches, -1)\n",
    "    x_init.requires_grad = True\n",
    "    y_init, _ = node.solve(x_init)\n",
    "    y_init = EllipseConstrainedProjectionFunction.apply(node, x_init)\n",
    "    loss_vals = {f\"e{i+1}\": [] for i in range(len(views[1]))}\n",
    "    loss_vals.update({\n",
    "        \"upper\": [],\n",
    "        \"lower\": []\n",
    "    })\n",
    "\n",
    "    surf_area_loss = loss_func(views, loss_vals=loss_vals)\n",
    "    history = [y_init]\n",
    "    x = x_init.clone().detach().requires_grad_(True)\n",
    "    torch_opt = torch.optim.SGD([x], lr=lr, momentum=moment)\n",
    "    lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(torch_opt, factor=0.5, patience=20, cooldown=0)\n",
    "    print(\"Theoretical min surface area is\", 4*np.pi*(.620350490899**2))\n",
    "    u_prev = None\n",
    "    for i in range(n_iters):\n",
    "        torch_opt.zero_grad(set_to_none=True)\n",
    "        y = EllipseConstrainedProjectionFunction.apply(node, x)\n",
    "        history.append(y.detach().clone())\n",
    "        if False:\n",
    "            # u,l = fit_ellipsoid(x.view(n_batches, 3, -1), method=method, with_jac=with_jac, u_prev=u_prev)\n",
    "            # loss_vals[\"lower\"].append(l[0])\n",
    "            a_hat = (y[:,0].item())\n",
    "            b_hat = (y[:,1].item())\n",
    "            c_hat = (y[:,2].item())\n",
    "            yaw_hat, pitch_hat, roll_hat = torch.rad2deg(y[:,3:6].squeeze())\n",
    "            if u_prev is None:\n",
    "                u_prev = y\n",
    "            l = objective_function(y.detach().clone().squeeze(), x.view(n_batches, 3, -1).detach().clone().squeeze(), u_prev.detach().clone().squeeze())\n",
    "            loss_vals[\"lower\"].append(l)\n",
    "            if True:\n",
    "                print(f\"{i:5d} ellipsoid estimate ({a_hat:0.3}, {b_hat:0.3}, {c_hat:0.3}, {yaw_hat:0.4}\\N{DEGREE SIGN}, {pitch_hat:0.4}\\N{DEGREE SIGN}, {roll_hat:0.4}\\N{DEGREE SIGN}) has volume {ellipsoid_volume(a_hat, b_hat, c_hat):0.3} and surface area {ellipsoid_surface_area(a_hat, b_hat, c_hat, p):0.5}. LR {torch_opt.param_groups[0]['lr']}\")\n",
    "\n",
    "        node.u_prev = y\n",
    "        u_prev = y\n",
    "\n",
    "        loss = surf_area_loss(y)\n",
    "        loss.backward()\n",
    "        torch_opt.step()\n",
    "        lr_sched.step(loss.item())\n",
    "        loss_vals[\"upper\"].append(loss.item())\n",
    "        print(loss.item(), x.grad)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    a, b, c, yaw, pitch, roll = original_params\n",
    "    plot_ellipsoid(ax, a, b, c, yaw, pitch, roll, color='blue')\n",
    "    ax.scatter(data[0, 0].numpy(), data[0, 1].numpy(), data[0, 2].numpy(), color='b', alpha=0.8, s=1)\n",
    "\n",
    "    final_data = x.reshape(1, 3, -1).detach()\n",
    "    ax.scatter(final_data[0, 0].numpy(), final_data[0, 1].numpy(), final_data[0, 2].numpy(), color='g', marker='+', alpha=0.8, s=1)\n",
    "\n",
    "    u, l = fit_ellipsoid(final_data, method=method, with_jac=with_jac)\n",
    "    a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat = extract_params(u.squeeze().detach())\n",
    "    plot_ellipsoid(ax, a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat, color='green')\n",
    "\n",
    "    print(\"Final ellipsoid ({:0.6}, {:0.6}, {:0.6}, {:0.4}, {:0.4}, {:0.4}) has volume {:0.3} and surface area {:0.6}.\".format(a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat, ellipsoid_volume(a_hat, b_hat, c_hat), ellipsoid_surface_area(a_hat, b_hat, c_hat, p)))\n",
    "    plt.legend(['initial true', 'initial samples', 'final samples', 'final projected'])\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.semilogy(surf_area_loss.loss_vals[\"e1\"], label = \"e1\")\n",
    "    plt.semilogy(surf_area_loss.loss_vals[\"e2\"], label = \"e2\")\n",
    "    plt.semilogy(loss_vals[\"upper\"], label = \"upper\")\n",
    "    plt.semilogy(loss_vals[\"lower\"], label = \"lower\")\n",
    "    plt.legend()\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "    return a_hat, b_hat, c_hat, yaw_hat, pitch_hat, roll_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_from_u_batch(u):\n",
    "    if not torch.is_tensor(u):\n",
    "        u = torch.tensor(u)\n",
    "    Lambda = torch.diag_embed(1/u[:,:3]**2)\n",
    "    Q = rotation_matrix_3d_batch(u[:,3:])\n",
    "    return Q @ Lambda @ Q.transpose(-1,-2)\n",
    "\n",
    "def rotation_matrix_3d_batch(angles):\n",
    "    alpha, beta, gamma = angles[:,0], angles[:,1], angles[:,2] # yaw, pitch, roll\n",
    "    R = torch.stack([\n",
    "        torch.stack([cos(alpha)*cos(beta), cos(alpha)*sin(beta)*sin(gamma)-sin(alpha)*cos(gamma), cos(alpha)*sin(beta)*cos(gamma)+sin(alpha)*sin(gamma)], dim=1),\n",
    "        torch.stack([sin(alpha)*cos(beta), sin(alpha)*sin(beta)*sin(gamma)+cos(alpha)*cos(gamma), sin(alpha)*sin(beta)*cos(gamma)-cos(alpha)*sin(gamma)], dim=1),\n",
    "        torch.stack([-sin(beta), cos(beta)*sin(gamma), cos(beta)*cos(gamma)], dim=1)\n",
    "    ], dim=1)\n",
    "    return R\n",
    "\n",
    "def schur_complement_batch(M):\n",
    "    A, B, C, D, E, F = M[:,0,0], M[:, 1,1], M[:, 2,2], M[:, 0,1], M[:, 0,2], M[:, 1,2]\n",
    "    return torch.stack([torch.stack([A - E**2/C, D - E*F/C], dim=1),\n",
    "                        torch.stack([D - E*F/C, B - F**2/C], dim=1)],\n",
    "                        dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveChamferLoss(nn.Module):\n",
    "    def __init__(self, views, loss_vals, m=50):\n",
    "        super().__init__()\n",
    "        rot_mats, contours = views\n",
    "        self.rot_mats = rot_mats\n",
    "        self.target_pts = contours\n",
    "        self.loss_vals = loss_vals\n",
    "        self.m = m # how many points to sample\n",
    "\n",
    "    def forward(self, input, p=1.6075):\n",
    "        A = A_from_u_batch(input).double()\n",
    "        \n",
    "        n = self.target_pts.size(0)\n",
    "        ellipses = torch.empty((n, 2, 2), dtype=torch.double)\n",
    "        for i, R in enumerate(self.rot_mats):\n",
    "            ellipse = schur_complement_batch(R @ A @ R.T)\n",
    "            ellipses[i] = ellipse\n",
    "        matrix_sqrts = pos_sqrt(ellipses)\n",
    "        sampled_pts = sample_pts(matrix_sqrts, m=self.m)\n",
    "        chamfer_dist = self.chamfer(sampled_pts)\n",
    "        return chamfer_dist\n",
    "\n",
    "    def chamfer(self, sampled_pts):\n",
    "        dist_matrix = torch.cdist(sampled_pts, self.target_pts, p=2)\n",
    "        min_d_sampled_to_target, _ = torch.min(dist_matrix, dim=1)\n",
    "        min_d_target_to_sampled, _ = torch.min(dist_matrix, dim=2)\n",
    "        chamfer_dist = min_d_sampled_to_target.mean(dim=1) + min_d_target_to_sampled.mean(dim=1)\n",
    "        for i, l in enumerate(chamfer_dist):\n",
    "            self.loss_vals[f\"e{i+1}\"].append(l.item())\n",
    "        # print(chamfer_dist.sum().item())\n",
    "        return chamfer_dist.sum()\n",
    "\n",
    "\n",
    "def sample_pts(sqrtA, m=50):\n",
    "    \"\"\"\n",
    "    assume an even sampling around a unit circle\n",
    "    m: number of points\n",
    "    \"\"\"\n",
    "    t = 2.0 * math.pi * torch.linspace(0.0, 1.0, m, dtype=torch.double)\n",
    "    points = torch.stack([torch.cos(t), torch.sin(t)])\n",
    "    inverse_sqrtA = torch.linalg.inv(sqrtA)\n",
    "    sampled_pts = inverse_sqrtA @ points\n",
    "    return sampled_pts.mT\n",
    "\n",
    "def pos_sqrt(A):\n",
    "    \"\"\"\n",
    "    A: a (batch_size x 3x3)\n",
    "    \"\"\"\n",
    "    L = torch.linalg.cholesky(A, upper=True)\n",
    "    return L\n",
    "\n",
    "\n",
    "def sample_target_ellipse(m, a=1, b=1):\n",
    "    \"\"\"\n",
    "    sample a set of points from a target ellipse\n",
    "    \"\"\"\n",
    "    t = 2.0 * math.pi * torch.linspace(0.0, 1.0, m, dtype=torch.double)\n",
    "    ellipse = torch.stack([a * torch.cos(t), b * torch.sin(t)], dim=1)\n",
    "    return ellipse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a noisy ellipse\n",
    "sqrt_m = 25\n",
    "a, b, c = 0.5, 0.6, 0.7\n",
    "yaw, pitch, roll =  0, 30, 30\n",
    "nu = 1.0e-4\n",
    "p = 1.6075\n",
    "\n",
    "m, data, u = inner_problem((a,b,c), (yaw,pitch,roll), sqrt_m, nu, p, method=\"default\", with_jac=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_angles = torch.deg2rad(torch.tensor([\n",
    "    [10,0,20],\n",
    "    [30,40,60],\n",
    "    # [10, 32, 96]\n",
    "], dtype=torch.double))\n",
    "rot_mats= rotation_matrix_3d_batch(view_angles)\n",
    "r=0.620350490899\n",
    "targets = torch.stack([\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "    \n",
    "])\n",
    "\n",
    "views = (rot_mats, targets)\n",
    "u_original = (a,b,c,yaw,pitch,roll)\n",
    "u = outer_problem(m, data, views=views, original_params=u_original, loss_func=NaiveChamferLoss, n_iters=30, with_jac=False, lr=0.3, moment=0.7, method=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PYTORCH3D VERSION\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "class PyTorchChamferLoss(nn.Module):\n",
    "    def __init__(self, views, loss_vals, m=50):\n",
    "        super().__init__()\n",
    "        rot_mats, contours = views\n",
    "        self.rot_mats = rot_mats\n",
    "        self.target_pts = contours\n",
    "        self.loss_vals = loss_vals\n",
    "        self.m = m # how many points to sample\n",
    "\n",
    "    def forward(self, input, p=1.6075):\n",
    "        A = A_from_u_batch(input).double()\n",
    "\n",
    "        n = self.target_pts.size(0)\n",
    "        ellipses = torch.empty((n, 2, 2), dtype=torch.double)\n",
    "        for i, R in enumerate(self.rot_mats):\n",
    "            ellipse = schur_complement_batch(R @ A @ R.T)\n",
    "            ellipses[i] = ellipse\n",
    "        matrix_sqrts = pos_sqrt(ellipses)\n",
    "        sampled_pts = sample_pts(matrix_sqrts, m=self.m)\n",
    "        chamfer_dist = self.chamfer(sampled_pts)\n",
    "        return chamfer_dist\n",
    "\n",
    "    def chamfer(self, sampled_pts):\n",
    "        print(sampled_pts.size(), self.target_pts.size())\n",
    "        res, _ = chamfer_distance(sampled_pts.float(), self.target_pts.float(),\n",
    "                                  batch_reduction=None,\n",
    "                                  point_reduction=\"mean\")\n",
    "        for i, l in enumerate(res):\n",
    "            self.loss_vals[f\"e{i+1}\"].append(l.item())\n",
    "\n",
    "        # print(res.sum().item())\n",
    "        return res.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a noisy ellipse\n",
    "sqrt_m = 25\n",
    "a, b, c = 0.5, 0.6, 0.7\n",
    "yaw, pitch, roll =  0, 30, 30\n",
    "nu = 1.0e-4\n",
    "p = 1.6075\n",
    "\n",
    "m, data, u = inner_problem((a,b,c), (yaw,pitch,roll), sqrt_m, nu, p, method=\"default\", with_jac=False)\n",
    "u = outer_problem(m, data, views=views, original_params=u_original, loss_func=PyTorchChamferLoss, n_iters=60, with_jac=False, lr=3, moment=0.7, method=\"default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamfer with Boundary Point Detection\n",
    "\n",
    "To detect boundary points, we are going to \n",
    "1. Sample points from another ellipsoid given the parametrisation from the lower level problem (the projected unit volume ellipsoid). \n",
    "2. Then, we project the points onto the x-y plane by setting the z-component of the points to 0. Optional: apply farthest point sampling to obtain a more uniformly distributed set of points. \n",
    "3. Following this, we find an alpha shape and extract the boundary points to perform our loss function on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PYTORCH3D VERSION\n",
    "\n",
    "\n",
    "class ChamferLossBoundary(nn.Module):\n",
    "    def __init__(self, views, loss_vals, m=50):\n",
    "        super().__init__()\n",
    "        rot_mats, contours = views\n",
    "        self.rot_mats = rot_mats\n",
    "        self.target_pts = contours\n",
    "        self.loss_vals = loss_vals\n",
    "        self.m = m # how many points to sample\n",
    "\n",
    "    def forward(self, input, p=1.6075):\n",
    "        A = A_from_u_batch(input).double()\n",
    "        # print(\"A\", A, \"angles\", np.deg2rad(get_angles(A.squeeze().detach().numpy())))\n",
    "        n_batches = A.size(0)\n",
    "        n_rot = self.rot_mats.size(0)\n",
    "        matrix_sqrts = torch.empty((n_rot, n_batches, 3, 3), dtype=torch.double) # n_rot x n_batches x 3 x 3\n",
    "        for i, R in enumerate(self.rot_mats):\n",
    "            rotated_A = R.mT @ A @ R\n",
    "            matrix_sqrts[i] = self.pos_sqrt(rotated_A)\n",
    "        matrix_sqrts = matrix_sqrts.transpose(0,1)\n",
    "        sampled_pts = self.sample_ellipsoid_pts(matrix_sqrts, m=12) # n_batches x n_rot x 3 x N\n",
    "        # sampled_pts = sampled_pts.squeeze().detach()\n",
    "        # for i, e in enumerate(sampled_pts):\n",
    "        #     u = fit_ellipsoid(e.unsqueeze(0))\n",
    "        #     print(u)\n",
    "        #     a,b,c,yaw,pitch,roll = u[0].squeeze()\n",
    "        #     yaw,pitch,roll = torch.rad2deg(torch.tensor([yaw,pitch,roll]))\n",
    "        #     fig = plt.figure()\n",
    "        #     ax = fig.add_subplot(111, projection='3d')\n",
    "        #     plot_ellipsoid(ax, a,b,c,yaw,pitch,roll)\n",
    "        #     ax.set_xlabel('$X$')\n",
    "        #     ax.set_ylabel('$Y$')\n",
    "        #     ax.set_zlabel('$Z$')\n",
    "        #     ax.scatter(e[0].numpy(), e[1].numpy(), e[2].numpy(), color='b', alpha=0.8, s=1)\n",
    "        #     ax.set_aspect('equal', adjustable='box')\n",
    "        #     plt.show()\n",
    "        # raise NotImplementedError\n",
    "        projected_pts = self.project(sampled_pts) # n_batches x n_rot x 2 x N\n",
    "        # print(\"projected points shape\", projected_pts.size(), projected_pts.dtype)\n",
    "        projected_pts_np = projected_pts.transpose(-1, -2).detach().cpu().numpy() # n_batches x n_rot x N x 2\n",
    "        hulls = []\n",
    "        alphas = []\n",
    "        boundary_points = []\n",
    "        lengths = []\n",
    "        for b, batch in enumerate(projected_pts_np):\n",
    "            batch_boundary_points = []      \n",
    "            batch_hull = []\n",
    "            for r, rot_pts in enumerate(batch):\n",
    "                # print(f\"Batch {b+1} Rotation {r+1}\")\n",
    "                # print(\"Optimising alpha\")\n",
    "                # alpha = alphashape.optimizealpha(rot_pts, max_iterations=50)\n",
    "                # alphas.append(alpha)\n",
    "                # print(\"Finding alpha shape\")\n",
    "                shaper = alpha_shapes.Alpha_Shaper(rot_pts)\n",
    "                hull = shaper.get_shape(alpha=0)\n",
    "                # print(\"Found alpha shape\")\n",
    "                batch_hull.append(hull)\n",
    "                boundary = hull.exterior.coords.xy # shape of 2 x N boundary points\n",
    "                boundary_torch = self.find_common_points(projected_pts[b,r,:,:], boundary)\n",
    "                # print(\"boundary torch size\", boundary_torch.size())\n",
    "                batch_boundary_points.append(boundary_torch)\n",
    "            hulls.append(batch_hull)\n",
    "            if False:\n",
    "                batch_lengths = torch.tensor([t.size(1) for t in batch_boundary_points])\n",
    "                lengths.append(batch_lengths)\n",
    "                max_length = batch_lengths.max()\n",
    "                padded = []\n",
    "                # print(\"maxlength\", max_length)\n",
    "                for t in batch_boundary_points:\n",
    "                    if max_length == t.size(1):\n",
    "                        padded.append(t)\n",
    "                    else:\n",
    "                        padded.append(torch.cat([t, torch.full((t.size(0), max_length - t.size(1)), float('nan'))], dim=1))\n",
    "                padded_batch_boundary_points = torch.stack(padded)\n",
    "                boundary_points.append(padded_batch_boundary_points)\n",
    "            else:\n",
    "                batch_lengths = torch.tensor([t.size(1) for t in batch_boundary_points])\n",
    "                lengths.append(batch_lengths)\n",
    "                min_length = batch_lengths.min()\n",
    "                truncated = torch.stack([t[:,:min_length] for t in batch_boundary_points])\n",
    "                boundary_points.append(truncated)\n",
    "        # print(\"Alphas:\", alphas)\n",
    "        self.plot_alpha_shapes(projected_pts, boundary_points, hulls)\n",
    "        chamfer_dist = 0\n",
    "        for batch, b_lengths in zip(boundary_points, lengths):\n",
    "            chamfer_dist += self.chamfer(batch.transpose(-1,-2), b_lengths)\n",
    "        return chamfer_dist\n",
    "\n",
    "    def project(self, points: torch.tensor):\n",
    "        # Assuming points shape is (n_batches x n_rot x 3 x N)\n",
    "        projection = points[:, :, :2, :]  # Keep only the first 2 coordinates for projection\n",
    "        return projection\n",
    "\n",
    "    def chamfer(self, sampled_pts, lengths):\n",
    "        res, _ = chamfer_distance(sampled_pts.float(), self.target_pts.float(),\n",
    "                                  batch_reduction=None,\n",
    "                                  point_reduction=\"mean\")\n",
    "        for i, l in enumerate(res):\n",
    "            self.loss_vals[f\"e{i+1}\"].append(l.item())\n",
    "        # print(res.sum().item())\n",
    "        return res.sum()\n",
    "    \n",
    "    def find_common_points(self, pts_torch, pts_np):\n",
    "        \"\"\"\n",
    "        shape of both input arrays/tensors is d x N, where d is the dimension of the point\n",
    "        \"\"\"\n",
    "        np_to_torch = torch.tensor(pts_np, device=pts_torch.device, dtype=pts_torch.dtype)\n",
    "        selected_points = []\n",
    "        for i in range(pts_torch.shape[1]): \n",
    "            point = pts_torch[:, i]  \n",
    "            if any(torch.allclose(point, np_to_torch[:, j], atol=1e-6) for j in range(np_to_torch.shape[1])):\n",
    "                selected_points.append(point)  \n",
    "        if selected_points:\n",
    "            selected_points_tensor = torch.stack(selected_points, dim=1) \n",
    "        else:\n",
    "            selected_points_tensor = torch.empty(2, 0, device=pts_torch.device)\n",
    "        \n",
    "        return selected_points_tensor\n",
    "\n",
    "    def sample_ellipsoid_pts(self, sqrtA, m=50):\n",
    "        phi = 2.0 * math.pi * torch.linspace(0.0, 1.0, m).double()\n",
    "        theta = math.pi * torch.linspace(0.0, 1.0, m).double()\n",
    "        phi, theta = torch.meshgrid(phi, theta)\n",
    "        x = torch.sin(theta) * torch.cos(phi)\n",
    "        y = torch.sin(theta) * torch.sin(phi)\n",
    "        z = torch.cos(theta)\n",
    "        coords = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=0).double().to(sqrtA.device)\n",
    "        x = torch.sin(phi) * torch.cos(theta)\n",
    "        y = torch.sin(phi) * torch.sin(theta)\n",
    "        z = torch.cos(phi)\n",
    "        coords2 = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=0).double().to(sqrtA.device)\n",
    "        coords = torch.cat([coords, coords2], dim=1)\n",
    "        inverse_sqrtA = torch.linalg.inv(sqrtA)#.transpose(-1,-2)\n",
    "        sampled_pts = inverse_sqrtA @ coords\n",
    "        return sampled_pts\n",
    "\n",
    "    def pos_sqrt(self, A):\n",
    "        \"\"\"\n",
    "        A: a (batch_size x dxd) tensor where d is the dimension of the data\n",
    "        \"\"\"\n",
    "        L = torch.linalg.cholesky(A, upper=True)\n",
    "        # U,S,Vh = torch.linalg.svd(A)\n",
    "        # S = torch.sqrt(S)\n",
    "        # L = U @ torch.diagflat(S) @ Vh\n",
    "        return L\n",
    "    \n",
    "\n",
    "    def plot_alpha_shapes(self, projected_pts, boundary_points, hulls):\n",
    "            print(projected_pts.size())\n",
    "            n_batches, n_rot, _, _ = projected_pts.size()\n",
    "            fig, axs = plt.subplots(n_batches, n_rot, figsize=(4 * n_rot, 4 * n_batches), squeeze=False)\n",
    "\n",
    "            for b in range(n_batches):\n",
    "                for r in range(n_rot):\n",
    "                    # Get the projected points for the current batch and rotation\n",
    "                    rot_pts = projected_pts[b, r, :, :].detach().cpu().numpy()  # shape (2, N)\n",
    "\n",
    "                    # Plot the alpha shape\n",
    "                    print(type(hulls[b]), type(hulls[b][r]))\n",
    "                    hull = hulls[b][r]  # Access the corresponding hull\n",
    "                    patch = PolygonPatch(hull, alpha=0.5, color='lightblue', edgecolor='blue')\n",
    "                    axs[b, r].add_patch(patch)\n",
    "\n",
    "                    # Plot the projected points\n",
    "                    axs[b, r].scatter(rot_pts[0], rot_pts[1], color='orange', label='Projected Points', s=2)\n",
    "\n",
    "                    # Get and plot boundary points for the current batch and rotation\n",
    "                    batch_boundary_points = boundary_points[b][r].detach().cpu().numpy()  # shape (2, M)\n",
    "                    axs[b, r].scatter(batch_boundary_points[0], batch_boundary_points[1], color='red', label='Boundary Points', s=2)\n",
    "\n",
    "                    # Plot the target shape\n",
    "                    target_contour = self.target_pts[r].mT\n",
    "                    axs[b, r].scatter(target_contour[0], target_contour[1], color='blue', label ='Target Points', s=2)\n",
    "\n",
    "                    # Set titles and labels\n",
    "                    axs[b, r].set_title(f'Batch {b+1}, Rotation {r+1}')\n",
    "                    axs[b, r].set_xlabel('X-axis')\n",
    "                    axs[b, r].set_ylabel('Y-axis')\n",
    "                    axs[b, r].set_xlim(-1, 1)  # Adjust limits based on your data\n",
    "                    axs[b, r].set_ylim(-1, 1)\n",
    "                    axs[b, r].grid()\n",
    "                    axs[b, r].legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a noisy ellipse\n",
    "view_angles = torch.deg2rad(torch.tensor([\n",
    "    [0,0,0],\n",
    "    [0,0,90],\n",
    "    # [10, 32, 96]\n",
    "], dtype=torch.double))\n",
    "rot_mats= rotation_matrix_3d_batch(view_angles)\n",
    "r=0.620350490899\n",
    "targets = torch.stack([\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "])\n",
    "\n",
    "views = (rot_mats, targets)\n",
    "u_original = (a,b,c,yaw,pitch,roll)\n",
    "\n",
    "sqrt_m = 25\n",
    "a, b, c = 0.5, 0.6, 0.7\n",
    "yaw, pitch, roll = 30, 40, 50\n",
    "nu = 1.0e-4\n",
    "p = 1.6075\n",
    "\n",
    "m, data, u = inner_problem((a,b,c), (yaw,pitch,roll), sqrt_m, nu, p, method=\"default\", with_jac=False)\n",
    "u = outer_problem(m, data, views=views, original_params=u_original, loss_func=ChamferLossBoundary, n_iters=50, with_jac=False, lr=1, moment=0.6, method=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PYTORCH3D VERSION\n",
    "\n",
    "\n",
    "class NaiveChamferLossBoundary(nn.Module):\n",
    "    def __init__(self, views, loss_vals, m=50):\n",
    "        super().__init__()\n",
    "        rot_mats, contours = views\n",
    "        self.rot_mats = rot_mats\n",
    "        self.target_pts = contours\n",
    "        self.loss_vals = loss_vals\n",
    "        self.m = m # how many points to sample\n",
    "\n",
    "    def forward(self, input, p=1.6075):\n",
    "        A = A_from_u_batch(input).double()\n",
    "        # print(\"A\", A, \"angles\", np.deg2rad(get_angles(A.squeeze().detach().numpy())))\n",
    "        n_batches = A.size(0)\n",
    "        n_rot = self.rot_mats.size(0)\n",
    "        matrix_sqrts = torch.empty((n_rot, n_batches, 3, 3), dtype=torch.double) # n_rot x n_batches x 3 x 3\n",
    "        for i, R in enumerate(self.rot_mats):\n",
    "            rotated_A = R.mT @ A @ R\n",
    "            matrix_sqrts[i] = self.pos_sqrt(rotated_A)\n",
    "        matrix_sqrts = matrix_sqrts.transpose(0,1)\n",
    "        sampled_pts = self.sample_ellipsoid_pts(matrix_sqrts, m=12) # n_batches x n_rot x 3 x N\n",
    "        # sampled_pts = sampled_pts.squeeze().detach()\n",
    "        # for i, e in enumerate(sampled_pts):\n",
    "        #     u = fit_ellipsoid(e.unsqueeze(0))\n",
    "        #     print(u)\n",
    "        #     a,b,c,yaw,pitch,roll = u[0].squeeze()\n",
    "        #     yaw,pitch,roll = torch.rad2deg(torch.tensor([yaw,pitch,roll]))\n",
    "        #     fig = plt.figure()\n",
    "        #     ax = fig.add_subplot(111, projection='3d')\n",
    "        #     plot_ellipsoid(ax, a,b,c,yaw,pitch,roll)\n",
    "        #     ax.set_xlabel('$X$')\n",
    "        #     ax.set_ylabel('$Y$')\n",
    "        #     ax.set_zlabel('$Z$')\n",
    "        #     ax.scatter(e[0].numpy(), e[1].numpy(), e[2].numpy(), color='b', alpha=0.8, s=1)\n",
    "        #     ax.set_aspect('equal', adjustable='box')\n",
    "        #     plt.show()\n",
    "        # raise NotImplementedError\n",
    "        projected_pts = self.project(sampled_pts) # n_batches x n_rot x 2 x N\n",
    "        # print(\"projected points shape\", projected_pts.size(), projected_pts.dtype)\n",
    "        projected_pts_np = projected_pts.transpose(-1, -2).detach().cpu().numpy() # n_batches x n_rot x N x 2\n",
    "        hulls = []\n",
    "        alphas = []\n",
    "        boundary_points = []\n",
    "        lengths = []\n",
    "        for b, batch in enumerate(projected_pts_np):\n",
    "            batch_boundary_points = []      \n",
    "            batch_hull = []\n",
    "            for r, rot_pts in enumerate(batch):\n",
    "                # print(f\"Batch {b+1} Rotation {r+1}\")\n",
    "                # print(\"Optimising alpha\")\n",
    "                # alpha = alphashape.optimizealpha(rot_pts, max_iterations=50)\n",
    "                # alphas.append(alpha)\n",
    "                # print(\"Finding alpha shape\")\n",
    "                shaper = alpha_shapes.Alpha_Shaper(rot_pts)\n",
    "                hull = shaper.get_shape(alpha=0)\n",
    "                # print(\"Found alpha shape\")\n",
    "                batch_hull.append(hull)\n",
    "                boundary = hull.exterior.coords.xy # shape of 2 x N boundary points\n",
    "                boundary_torch = self.find_common_points(projected_pts[b,r,:,:], boundary)\n",
    "                # print(\"boundary torch size\", boundary_torch.size())\n",
    "                batch_boundary_points.append(boundary_torch)\n",
    "            hulls.append(batch_hull)\n",
    "            if False:\n",
    "                batch_lengths = torch.tensor([t.size(1) for t in batch_boundary_points])\n",
    "                lengths.append(batch_lengths)\n",
    "                max_length = batch_lengths.max()\n",
    "                padded = []\n",
    "                # print(\"maxlength\", max_length)\n",
    "                for t in batch_boundary_points:\n",
    "                    if max_length == t.size(1):\n",
    "                        padded.append(t)\n",
    "                    else:\n",
    "                        padded.append(torch.cat([t, torch.full((t.size(0), max_length - t.size(1)), float('nan'))], dim=1))\n",
    "                padded_batch_boundary_points = torch.stack(padded)\n",
    "                boundary_points.append(padded_batch_boundary_points)\n",
    "            else:\n",
    "                batch_lengths = torch.tensor([t.size(1) for t in batch_boundary_points])\n",
    "                lengths.append(batch_lengths)\n",
    "                min_length = batch_lengths.min()\n",
    "                truncated = torch.stack([t[:,:min_length] for t in batch_boundary_points])\n",
    "                boundary_points.append(truncated)\n",
    "        # print(\"Alphas:\", alphas)\n",
    "        # self.plot_alpha_shapes(projected_pts, boundary_points, hulls)\n",
    "        chamfer_dist = 0\n",
    "        for batch, b_lengths in zip(boundary_points, lengths):\n",
    "            chamfer_dist += self.chamfer(batch.transpose(-1,-2), b_lengths)\n",
    "        return chamfer_dist\n",
    "\n",
    "    def project(self, points: torch.tensor):\n",
    "        # Assuming points shape is (n_batches x n_rot x 3 x N)\n",
    "        projection = points[:, :, :2, :]  # Keep only the first 2 coordinates for projection\n",
    "        return projection\n",
    "\n",
    "    def chamfer(self, sampled_pts, lengths):\n",
    "        dist_matrix = torch.cdist(sampled_pts, self.target_pts, p=2)\n",
    "        min_d_sampled_to_target, _ = torch.min(dist_matrix, dim=1)\n",
    "        min_d_target_to_sampled, _ = torch.min(dist_matrix, dim=2)\n",
    "        chamfer_dist = min_d_sampled_to_target.mean(dim=1) + min_d_target_to_sampled.mean(dim=1)\n",
    "        for i, l in enumerate(chamfer_dist):\n",
    "            self.loss_vals[f\"e{i+1}\"].append(l.item())\n",
    "        print(chamfer_dist.sum().item())\n",
    "        return chamfer_dist.sum()\n",
    "    \n",
    "    def find_common_points(self, pts_torch, pts_np):\n",
    "        \"\"\"\n",
    "        shape of both input arrays/tensors is d x N, where d is the dimension of the point\n",
    "        \"\"\"\n",
    "        np_to_torch = torch.tensor(pts_np, device=pts_torch.device, dtype=pts_torch.dtype)\n",
    "        selected_points = []\n",
    "        for i in range(pts_torch.shape[1]): \n",
    "            point = pts_torch[:, i]  \n",
    "            if any(torch.allclose(point, np_to_torch[:, j], atol=1e-6) for j in range(np_to_torch.shape[1])):\n",
    "                selected_points.append(point)  \n",
    "        if selected_points:\n",
    "            selected_points_tensor = torch.stack(selected_points, dim=1) \n",
    "        else:\n",
    "            selected_points_tensor = torch.empty(2, 0, device=pts_torch.device)\n",
    "        \n",
    "        return selected_points_tensor\n",
    "\n",
    "    def sample_ellipsoid_pts(self, sqrtA, m=50):\n",
    "        phi = 2.0 * math.pi * torch.linspace(0.0, 1.0, m).double()\n",
    "        theta = math.pi * torch.linspace(0.0, 1.0, m).double()\n",
    "        phi, theta = torch.meshgrid(phi, theta)\n",
    "        x = torch.sin(theta) * torch.cos(phi)\n",
    "        y = torch.sin(theta) * torch.sin(phi)\n",
    "        z = torch.cos(theta)\n",
    "        coords = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=0).double().to(sqrtA.device)\n",
    "        x = torch.sin(phi) * torch.cos(theta)\n",
    "        y = torch.sin(phi) * torch.sin(theta)\n",
    "        z = torch.cos(phi)\n",
    "        coords2 = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=0).double().to(sqrtA.device)\n",
    "        coords = torch.cat([coords, coords2], dim=1)\n",
    "        inverse_sqrtA = torch.linalg.inv(sqrtA)#.transpose(-1,-2)\n",
    "        sampled_pts = inverse_sqrtA @ coords\n",
    "        return sampled_pts\n",
    "\n",
    "    def pos_sqrt(self, A):\n",
    "        \"\"\"\n",
    "        A: a (batch_size x dxd) tensor where d is the dimension of the data\n",
    "        \"\"\"\n",
    "        L = torch.linalg.cholesky(A, upper=True)\n",
    "        # U,S,Vh = torch.linalg.svd(A)\n",
    "        # S = torch.sqrt(S)\n",
    "        # L = U @ torch.diagflat(S) @ Vh\n",
    "        return L\n",
    "    \n",
    "\n",
    "    def plot_alpha_shapes(self, projected_pts, boundary_points, hulls):\n",
    "            print(projected_pts.size())\n",
    "            n_batches, n_rot, _, _ = projected_pts.size()\n",
    "            fig, axs = plt.subplots(n_batches, n_rot, figsize=(4 * n_rot, 4 * n_batches), squeeze=False)\n",
    "\n",
    "            for b in range(n_batches):\n",
    "                for r in range(n_rot):\n",
    "                    # Get the projected points for the current batch and rotation\n",
    "                    rot_pts = projected_pts[b, r, :, :].detach().cpu().numpy()  # shape (2, N)\n",
    "\n",
    "                    # Plot the alpha shape\n",
    "                    hull = hulls[b][r]  # Access the corresponding hull\n",
    "                    patch = PolygonPatch(hull, alpha=0.5, color='lightblue', edgecolor='blue')\n",
    "                    axs[b, r].add_patch(patch)\n",
    "\n",
    "                    # Plot the projected points\n",
    "                    axs[b, r].scatter(rot_pts[0], rot_pts[1], color='orange', label='Projected Points', s=2)\n",
    "\n",
    "                    # Get and plot boundary points for the current batch and rotation\n",
    "                    batch_boundary_points = boundary_points[b][r].detach().cpu().numpy()  # shape (2, M)\n",
    "                    axs[b, r].scatter(batch_boundary_points[0], batch_boundary_points[1], color='red', label='Boundary Points', s=2)\n",
    "\n",
    "                    # Plot the target shape\n",
    "                    target_contour = self.target_pts[r].mT\n",
    "                    axs[b, r].scatter(target_contour[0], target_contour[1], color='blue', label ='Target Points', s=2)\n",
    "\n",
    "                    # Set titles and labels\n",
    "                    axs[b, r].set_title(f'Batch {b+1}, Rotation {r+1}')\n",
    "                    axs[b, r].set_xlabel('X-axis')\n",
    "                    axs[b, r].set_ylabel('Y-axis')\n",
    "                    axs[b, r].set_xlim(-1, 1)  # Adjust limits based on your data\n",
    "                    axs[b, r].set_ylim(-1, 1)\n",
    "                    axs[b, r].grid()\n",
    "                    axs[b, r].legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# sample a noisy ellipse\n",
    "view_angles = torch.deg2rad(torch.tensor([\n",
    "    [0,0,0],\n",
    "    [0,0,90],\n",
    "    # [10, 32, 96]\n",
    "], dtype=torch.double))\n",
    "rot_mats= rotation_matrix_3d_batch(view_angles)\n",
    "r=0.620350490899\n",
    "targets = torch.stack([\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "    sample_target_ellipse(50,a=r,b=r),\n",
    "])\n",
    "\n",
    "views = (rot_mats, targets)\n",
    "u_original = (a,b,c,yaw,pitch,roll)\n",
    "\n",
    "sqrt_m = 25\n",
    "a, b, c = 0.5, 0.6, 0.7\n",
    "yaw, pitch, roll = 30, 40, 50\n",
    "nu = 1.0e-4\n",
    "p = 1.6075\n",
    "\n",
    "m, data, u = inner_problem((a,b,c), (yaw,pitch,roll), sqrt_m, nu, p, method=\"default\", with_jac=False)\n",
    "u = outer_problem(m, data, views=views, original_params=u_original, loss_func=ChamferLossBoundary, n_iters=0, with_jac=False, lr=2, moment=0.8, method=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
