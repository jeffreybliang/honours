{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_matrices(path, matrix_types=None):\n",
    "    \"\"\"\n",
    "    Loads camera matrices from .npy files in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the directory containing camera matrix files.\n",
    "        matrix_types (set or list, optional): Specifies which matrix types to load (e.g., {'K', 'RT'}).\n",
    "        If None, all available matrices ('K', 'RT', 'P') will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping camera numbers to their respective matrices.\n",
    "    \"\"\"\n",
    "    cameras = defaultdict(dict)\n",
    "    file_pattern = re.compile(r\"^Camera_(\\d+)_(K|RT|P)\\.npy$\")\n",
    "    \n",
    "    if matrix_types is not None:\n",
    "        matrix_types = set(matrix_types)  # Ensure it's a set for quick lookup\n",
    "    \n",
    "    for filename in sorted(os.listdir(path)):  # Sort filenames alphabetically\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            cam_number, matrix_type = match.groups()\n",
    "            cam_number = int(cam_number)  # Convert camera number to integer\n",
    "            if matrix_types is None or matrix_type in matrix_types:\n",
    "                filepath = os.path.join(path, filename)\n",
    "                cameras[cam_number][matrix_type] = torch.tensor(np.load(filepath))\n",
    "    \n",
    "    return cameras\n",
    "\n",
    "def load_renders(renders_path):\n",
    "    renders = defaultdict(dict)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\\.png\")\n",
    "    for filename in sorted(os.listdir(renders_path), key=lambda x: (re.match(pattern, x).group(1), int(re.match(pattern, x).group(2))) if re.match(pattern, x) else (x, float('inf'))):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            word, number = match.groups()\n",
    "            number = int(number)  # Convert number to integer for sorting\n",
    "\n",
    "            image_path = os.path.join(renders_path, filename)\n",
    "            image = cv2.imread(image_path)  # Load image using OpenCV\n",
    "            if image is not None:\n",
    "                renders[word][number] = image  # Store image in the nested dictionary\n",
    "\n",
    "    return renders\n",
    "\n",
    "def get_projmats_and_edgemap_info(view_idx, target_mesh: str, matrices, edgemaps, edgemaps_len):\n",
    "    \"\"\"\n",
    "    Retrieves the projection matrices and target edgemap information for the specified view indices and target mesh.\n",
    "\n",
    "    Parameters:\n",
    "        view_idx (list): List of indices for which to retrieve projection matrices and edgemaps.\n",
    "        target_mesh (str): The target mesh name (e.g., 'balloon') to extract edgemaps and lengths for.\n",
    "        matrices (dict): Dictionary containing camera matrices.\n",
    "        edgemaps (dict): Dictionary containing edgemaps for various meshes.\n",
    "        edgemaps_len (dict): Dictionary containing the lengths of the edgemaps for each mesh.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the projection matrices (torch.Tensor) and the target edgemap information (tuple of torch.Tensors).\n",
    "    \"\"\"\n",
    "    # Get the projection matrices for the specified view indices\n",
    "    projmats = torch.stack([matrices[view_idx[i]][\"P\"] for i in range(len(view_idx))])\n",
    "\n",
    "    # Get the target edgemaps for the specified target mesh\n",
    "    tgt_edgemaps = torch.nn.utils.rnn.pad_sequence([edgemaps[target_mesh][i] for i in view_idx], batch_first=True, padding_value=0.0)\n",
    "    tgt_edgemaps_len = torch.tensor([edgemaps_len[target_mesh][i] for i in view_idx])\n",
    "\n",
    "    # Pack the target edgemaps and their lengths\n",
    "    tgt_edgemap_info = (tgt_edgemaps, tgt_edgemaps_len)\n",
    "\n",
    "    return projmats, tgt_edgemap_info\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "\n",
    "def visualize_edges(renders, edgemap_options, target_mesh):\n",
    "    num_views = 12  # assuming 12 views per mesh\n",
    "    rows, cols = 6, 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    mesh_renders = renders.get(target_mesh, {})\n",
    "    mesh_options = edgemap_options.get(target_mesh, {})\n",
    "\n",
    "    for view_idx in range(num_views):\n",
    "        row, col = divmod(view_idx, cols)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        img = mesh_renders.get(view_idx)\n",
    "        if img is not None and str(view_idx) in mesh_options:\n",
    "            edge_option = mesh_options[str(view_idx)]\n",
    "            edges = canny_edge_map(img, edge_option)\n",
    "            ax.imshow(edges, cmap='gray')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "        ax.set_title(f\"View {view_idx}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Canny edges for mesh: {target_mesh}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open(\"/Users/jeffreyliang/Documents/Honours/honours/src/experiments/skyconfig_local.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "mesh_dir = cfg[\"paths\"][\"mesh_dir\"]\n",
    "mesh_res = cfg[\"paths\"][\"mesh_res\"]\n",
    "renders_path = cfg[\"paths\"][\"renders_path\"]\n",
    "matrices_path = cfg[\"paths\"][\"matrices_path\"]\n",
    "\n",
    "# Fix edgemap_options to be a dictionary where keys are mesh names and values are dictionaries of view indices\n",
    "edgemap_options = {mesh[\"name\"]: {str(k): v for k, v in mesh[\"edgemap_options\"].items()} for mesh in cfg[\"meshes\"]}\n",
    "\n",
    "# Load renders and camera matrices\n",
    "renders = load_renders(renders_path)\n",
    "matrices = load_camera_matrices(matrices_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_edges(renders, edgemap_options, target_mesh=\"balloon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img_greyscale = cv2.GaussianBlur(img_greyscale, (3,3), 1)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_renders_for_material(renders_path, material, object_name):\n",
    "    \"\"\"\n",
    "    Loads renders for a specific object and material by navigating the material folder.\n",
    "    \n",
    "    Parameters:\n",
    "        renders_path (str): Path to the directory containing the render images.\n",
    "        material (str): Material name to filter the renders (e.g., \"Diffuse\").\n",
    "        object_name (str): The object name (e.g., \"Oblique6\") to filter the renders.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping view names (\"Above_3\", \"Ground_1\", etc.) to their corresponding images.\n",
    "    \"\"\"\n",
    "    renders = defaultdict(list)\n",
    "    material_path = os.path.join(renders_path, material)  # Construct path for the material folder\n",
    "    \n",
    "    if not os.path.exists(material_path):\n",
    "        print(f\"Material folder {material_path} not found!\")\n",
    "        return renders\n",
    "\n",
    "    # Regex pattern: Extract Object<number> and View_<number>, ignoring _Cam_.\n",
    "    # Example: Oblique6_Cam_Above_3.png -> object_name: Oblique6, view_name: Above_3\n",
    "    pattern = re.compile(rf\"^({object_name})_Camera_(\\d+)\\.png\")\n",
    "\n",
    "    for filename in sorted(os.listdir(material_path)):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            obj,  view_number = match.groups()\n",
    "            if obj == object_name:\n",
    "                # Construct the view name as \"Above_3\", \"Ground_1\", etc.\n",
    "                full_view_name = f\"{view_number}\"\n",
    "                image_path = os.path.join(material_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    renders[full_view_name] = image  # Store images under view name\n",
    "\n",
    "    return renders\n",
    "\n",
    "\n",
    "def apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material):\n",
    "    \"\"\"\n",
    "    Applies Canny edge detection to renders for a specific object and material using the provided edgemap_options.\n",
    "\n",
    "    Parameters:\n",
    "        renders (dict): Dictionary containing render images.\n",
    "        edgemap_options (dict): Dictionary containing edge map options.\n",
    "        object_name (str): The object name (e.g., 'Oblique1').\n",
    "        material (str): The material name (e.g., 'Diffuse').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping view indices to their corresponding Canny edge map results.\n",
    "    \"\"\"\n",
    "    edge_maps = {}\n",
    "\n",
    "    for view_name, options in edgemap_options.get(object_name, {}).items():\n",
    "        # Get the edge map for this specific view name\n",
    "        edge_map = renders.get(view_name)  # Get the image by the full view name (e.g., \"Overhead_1\")\n",
    "        \n",
    "        if edge_map is not None:\n",
    "            # Apply Canny edge map with the options\n",
    "            edge_maps[view_name] = canny_edge_map(edge_map, options)\n",
    "\n",
    "    return edge_maps\n",
    "\n",
    "def plot_edge_maps(edge_maps):\n",
    "    \"\"\"\n",
    "    Plots the edge maps in a grid with minimal white space and titles indicating the view names.\n",
    "\n",
    "    Parameters:\n",
    "        edge_maps (dict): A dictionary mapping view names to their corresponding edge map results.\n",
    "    \"\"\"\n",
    "    # Calculate number of rows and columns based on the number of edge maps\n",
    "    num_views = len(edge_maps)\n",
    "    rows = (num_views + 1) // 2  # N rows, 2 columns\n",
    "    cols = 2\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, (view_name, edge_map) in enumerate(edge_maps.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(edge_map, cmap='gray')\n",
    "        ax.set_title(view_name)  # Title with the view name (e.g., \"Overhead_1\")\n",
    "        ax.axis('off')  # Remove axis labels and ticks\n",
    "    \n",
    "    # Turn off any unused axes\n",
    "    for ax in axes[num_views:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=1.0)  # Minimal white space\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `edge_maps` is the dictionary containing the edge maps (e.g., {\"Overhead_1\": edge_map1, \"Above_1\": edge_map2, ...})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '11', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# Define edge map options using dictionary comprehension\n",
    "import json\n",
    "renders_path = \"/Users/jeffreyliang/Documents/Honours/Blender/shape_reconstruction/renders\"\n",
    "material = \"Diffuse\"  # Example material\n",
    "object_name = \"Spiky\"  # Example object name\n",
    "renders = load_renders_for_material(renders_path, material, object_name)\n",
    "print([k for k in renders.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m edge_maps \u001b[39m=\u001b[39m apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(edge_maps))\n\u001b[0;32m---> 26\u001b[0m plot_edge_maps(edge_maps)\n",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m, in \u001b[0;36mplot_edge_maps\u001b[0;34m(edge_maps)\u001b[0m\n\u001b[1;32m     98\u001b[0m cols \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[39m# Create the plot\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49msubplots(rows, cols, figsize\u001b[39m=\u001b[39;49m(cols \u001b[39m*\u001b[39;49m \u001b[39m6\u001b[39;49m, rows \u001b[39m*\u001b[39;49m \u001b[39m4\u001b[39;49m))\n\u001b[1;32m    102\u001b[0m axes \u001b[39m=\u001b[39m axes\u001b[39m.\u001b[39mflatten()  \u001b[39m# Flatten the axes array to easily index it\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m idx, (view_name, edge_map) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(edge_maps\u001b[39m.\u001b[39mitems()):\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/matplotlib/pyplot.py:1760\u001b[0m, in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[39mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \n\u001b[1;32m   1758\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m fig \u001b[39m=\u001b[39m figure(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfig_kw)\n\u001b[0;32m-> 1760\u001b[0m axs \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msubplots(nrows\u001b[39m=\u001b[39;49mnrows, ncols\u001b[39m=\u001b[39;49mncols, sharex\u001b[39m=\u001b[39;49msharex, sharey\u001b[39m=\u001b[39;49msharey,\n\u001b[1;32m   1761\u001b[0m                    squeeze\u001b[39m=\u001b[39;49msqueeze, subplot_kw\u001b[39m=\u001b[39;49msubplot_kw,\n\u001b[1;32m   1762\u001b[0m                    gridspec_kw\u001b[39m=\u001b[39;49mgridspec_kw, height_ratios\u001b[39m=\u001b[39;49mheight_ratios,\n\u001b[1;32m   1763\u001b[0m                    width_ratios\u001b[39m=\u001b[39;49mwidth_ratios)\n\u001b[1;32m   1764\u001b[0m \u001b[39mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/matplotlib/figure.py:860\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwidth_ratios\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must not be defined both as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    857\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mparameter and as key in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mgridspec_kw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    858\u001b[0m     gridspec_kw[\u001b[39m'\u001b[39m\u001b[39mwidth_ratios\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m width_ratios\n\u001b[0;32m--> 860\u001b[0m gs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_gridspec(nrows, ncols, figure\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgridspec_kw)\n\u001b[1;32m    861\u001b[0m axs \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39msubplots(sharex\u001b[39m=\u001b[39msharex, sharey\u001b[39m=\u001b[39msharey, squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[1;32m    862\u001b[0m                   subplot_kw\u001b[39m=\u001b[39msubplot_kw)\n\u001b[1;32m    863\u001b[0m \u001b[39mreturn\u001b[39;00m axs\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/matplotlib/figure.py:1538\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[0;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m \u001b[39mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \n\u001b[1;32m   1535\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m _ \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfigure\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# pop in case user has added this...\u001b[39;00m\n\u001b[0;32m-> 1538\u001b[0m gs \u001b[39m=\u001b[39m GridSpec(nrows\u001b[39m=\u001b[39;49mnrows, ncols\u001b[39m=\u001b[39;49mncols, figure\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mreturn\u001b[39;00m gs\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/matplotlib/gridspec.py:363\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[0;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhspace \u001b[39m=\u001b[39m hspace\n\u001b[1;32m    361\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure \u001b[39m=\u001b[39m figure\n\u001b[0;32m--> 363\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(nrows, ncols,\n\u001b[1;32m    364\u001b[0m                  width_ratios\u001b[39m=\u001b[39;49mwidth_ratios,\n\u001b[1;32m    365\u001b[0m                  height_ratios\u001b[39m=\u001b[39;49mheight_ratios)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/matplotlib/gridspec.py:48\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[0;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(nrows, Integral) \u001b[39mor\u001b[39;00m nrows \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     49\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of rows must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mnrows\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(ncols, Integral) \u001b[39mor\u001b[39;00m ncols \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of columns must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mncols\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of rows must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "json_string = f'''{{\n",
    "  \"{object_name}\": {{\n",
    "        \"0\": [false,  20, 60],\n",
    "        \"1\": [false,  20, 60],\n",
    "        \"2\": [false,  15, 40],\n",
    "        \"3\": [false,  20, 60],\n",
    "        \"4\": [false,  20, 60],\n",
    "        \"5\": [false,  20, 60],\n",
    "        \"6\": [false,  20, 60],\n",
    "        \"7\": [false,  20, 60],\n",
    "        \"8\": [false,  20, 60],\n",
    "        \"9\": [false,  20, 60],\n",
    "        \"10\": [false, 20, 60],\n",
    "        \"11\": [false, 20, 60]\n",
    "        }}\n",
    "}}'''.replace(\"false\", \"false\")  # leave as is, JSON uses `false`\n",
    "\n",
    "edgemap_options = json.loads(json_string)\n",
    "\n",
    "# edgemap_options = defaultdict(lambda: (False, 15, 200))  # Default option: (False, 0, 0) for equalisation, low, high thresholds\n",
    "\n",
    "# Apply Canny edge detection to the filtered renders based on material and object\n",
    "edge_maps = apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material)\n",
    "print(len(edge_maps))\n",
    "\n",
    "plot_edge_maps(edge_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_options = {\n",
    "    \"Overhead_0\": (True, 15, 250),  # (hist_eq=True, low_thresh=15, high_thresh=250)\n",
    "\n",
    "    \"Above_0\": (True, 25, 250),\n",
    "    \"Above_1\": (True, 25, 250),\n",
    "    \"Above_2\": (False, 15, 200),\n",
    "    \"Above_3\": (True, 20, 240),\n",
    "    \"Above_4\": (True, 25, 250),\n",
    "    \"Above_5\": (True, 25, 250),\n",
    "    \"Above_6\": (True, 25, 250),\n",
    "\n",
    "    \"Ground_0\": (False, 10, 150),\n",
    "    \"Ground_1\": (False, 10, 150),\n",
    "    \"Ground_2\": (True, 18, 210),\n",
    "    \"Ground_3\": (True, 12, 180),\n",
    "    \"Ground_4\": (False, 10, 150),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = [f\"Icosphere{i}\" for i in range(9)]\n",
    "material = \"\"  # Set your actual material name here\n",
    "view_name = \"Ground_0\"\n",
    "renders_path = \"/Users/jeffreyliang/Documents/Honours/Blender/translation/renders\"\n",
    "\n",
    "# Set common Canny parameters\n",
    "canny_params = (False, 15, 100)\n",
    "\n",
    "all_edge_maps = {}\n",
    "\n",
    "for obj in object_names:\n",
    "    renders = load_renders_for_material(renders_path, material, obj)\n",
    "    if view_name in renders:\n",
    "        img = renders[view_name]\n",
    "        edge_map = canny_edge_map(img, canny_params)\n",
    "        all_edge_maps[obj] = edge_map\n",
    "    else:\n",
    "        print(f\"{view_name} not found for {obj}\")\n",
    "\n",
    "# Plot all objects' Ground_0 edge maps\n",
    "def plot_objects_edge_maps(edge_maps):\n",
    "    num_objects = len(edge_maps)\n",
    "    cols = 3\n",
    "    rows = (num_objects + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 8, rows * 5))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (obj_name, edge_map) in enumerate(edge_maps.items()):\n",
    "        axes[idx].imshow(edge_map, cmap='gray')\n",
    "        axes[idx].set_title(obj_name)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for ax in axes[num_objects:]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_objects_edge_maps(all_edge_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0daf5460e7e70b267b98b1da0f26ec996de3765b5ed627292ed8b6734d003d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
