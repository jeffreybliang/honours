{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_matrices(path, matrix_types=None):\n",
    "    \"\"\"\n",
    "    Loads camera matrices from .npy files in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the directory containing camera matrix files.\n",
    "        matrix_types (set or list, optional): Specifies which matrix types to load (e.g., {'K', 'RT'}).\n",
    "        If None, all available matrices ('K', 'RT', 'P') will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping camera numbers to their respective matrices.\n",
    "    \"\"\"\n",
    "    cameras = defaultdict(dict)\n",
    "    file_pattern = re.compile(r\"^Camera_(\\d+)_(K|RT|P)\\.npy$\")\n",
    "    \n",
    "    if matrix_types is not None:\n",
    "        matrix_types = set(matrix_types)  # Ensure it's a set for quick lookup\n",
    "    \n",
    "    for filename in sorted(os.listdir(path)):  # Sort filenames alphabetically\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            cam_number, matrix_type = match.groups()\n",
    "            cam_number = int(cam_number)  # Convert camera number to integer\n",
    "            if matrix_types is None or matrix_type in matrix_types:\n",
    "                filepath = os.path.join(path, filename)\n",
    "                cameras[cam_number][matrix_type] = torch.tensor(np.load(filepath))\n",
    "    \n",
    "    return cameras\n",
    "\n",
    "def load_renders(renders_path):\n",
    "    renders = defaultdict(dict)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\\.png\")\n",
    "    for filename in sorted(os.listdir(renders_path), key=lambda x: (re.match(pattern, x).group(1), int(re.match(pattern, x).group(2))) if re.match(pattern, x) else (x, float('inf'))):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            word, number = match.groups()\n",
    "            number = int(number)  # Convert number to integer for sorting\n",
    "\n",
    "            image_path = os.path.join(renders_path, filename)\n",
    "            image = cv2.imread(image_path)  # Load image using OpenCV\n",
    "            if image is not None:\n",
    "                renders[word][number] = image  # Store image in the nested dictionary\n",
    "\n",
    "    return renders\n",
    "\n",
    "def get_projmats_and_edgemap_info(view_idx, target_mesh: str, matrices, edgemaps, edgemaps_len):\n",
    "    \"\"\"\n",
    "    Retrieves the projection matrices and target edgemap information for the specified view indices and target mesh.\n",
    "\n",
    "    Parameters:\n",
    "        view_idx (list): List of indices for which to retrieve projection matrices and edgemaps.\n",
    "        target_mesh (str): The target mesh name (e.g., 'balloon') to extract edgemaps and lengths for.\n",
    "        matrices (dict): Dictionary containing camera matrices.\n",
    "        edgemaps (dict): Dictionary containing edgemaps for various meshes.\n",
    "        edgemaps_len (dict): Dictionary containing the lengths of the edgemaps for each mesh.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the projection matrices (torch.Tensor) and the target edgemap information (tuple of torch.Tensors).\n",
    "    \"\"\"\n",
    "    # Get the projection matrices for the specified view indices\n",
    "    projmats = torch.stack([matrices[view_idx[i]][\"P\"] for i in range(len(view_idx))])\n",
    "\n",
    "    # Get the target edgemaps for the specified target mesh\n",
    "    tgt_edgemaps = torch.nn.utils.rnn.pad_sequence([edgemaps[target_mesh][i] for i in view_idx], batch_first=True, padding_value=0.0)\n",
    "    tgt_edgemaps_len = torch.tensor([edgemaps_len[target_mesh][i] for i in view_idx])\n",
    "\n",
    "    # Pack the target edgemaps and their lengths\n",
    "    tgt_edgemap_info = (tgt_edgemaps, tgt_edgemaps_len)\n",
    "\n",
    "    return projmats, tgt_edgemap_info\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "\n",
    "def visualize_edges(renders, edgemap_options, target_mesh):\n",
    "    num_views = 12  # assuming 12 views per mesh\n",
    "    rows, cols = 6, 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    mesh_renders = renders.get(target_mesh, {})\n",
    "    mesh_options = edgemap_options.get(target_mesh, {})\n",
    "\n",
    "    for view_idx in range(num_views):\n",
    "        row, col = divmod(view_idx, cols)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        img = mesh_renders.get(view_idx)\n",
    "        if img is not None and str(view_idx) in mesh_options:\n",
    "            edge_option = mesh_options[str(view_idx)]\n",
    "            edges = canny_edge_map(img, edge_option)\n",
    "            ax.imshow(edges, cmap='gray')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "        ax.set_title(f\"View {view_idx}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Canny edges for mesh: {target_mesh}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open(\"/Users/jeffreyliang/Documents/Honours/honours/src/experiments/skyconfig_local.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "mesh_dir = cfg[\"paths\"][\"mesh_dir\"]\n",
    "mesh_res = cfg[\"paths\"][\"mesh_res\"]\n",
    "renders_path = cfg[\"paths\"][\"renders_path\"]\n",
    "matrices_path = cfg[\"paths\"][\"matrices_path\"]\n",
    "\n",
    "# Fix edgemap_options to be a dictionary where keys are mesh names and values are dictionaries of view indices\n",
    "edgemap_options = {mesh[\"name\"]: {str(k): v for k, v in mesh[\"edgemap_options\"].items()} for mesh in cfg[\"meshes\"]}\n",
    "\n",
    "# Load renders and camera matrices\n",
    "renders = load_renders(renders_path)\n",
    "matrices = load_camera_matrices(matrices_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_edges(renders, edgemap_options, target_mesh=\"balloon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img_greyscale = cv2.GaussianBlur(img_greyscale, (3,3), 1)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_renders_for_material(renders_path, material, object_name):\n",
    "    \"\"\"\n",
    "    Loads renders for a specific object and material by navigating the material folder.\n",
    "    \n",
    "    Parameters:\n",
    "        renders_path (str): Path to the directory containing the render images.\n",
    "        material (str): Material name to filter the renders (e.g., \"Diffuse\").\n",
    "        object_name (str): The object name (e.g., \"Oblique6\") to filter the renders.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping view names (\"Above_3\", \"Ground_1\", etc.) to their corresponding images.\n",
    "    \"\"\"\n",
    "    renders = defaultdict(list)\n",
    "    material_path = os.path.join(renders_path, material)  # Construct path for the material folder\n",
    "    \n",
    "    if not os.path.exists(material_path):\n",
    "        print(f\"Material folder {material_path} not found!\")\n",
    "        return renders\n",
    "\n",
    "    # Regex pattern: Extract Object<number> and View_<number>, ignoring _Cam_.\n",
    "    # Example: Oblique6_Cam_Above_3.png -> object_name: Oblique6, view_name: Above_3\n",
    "    pattern = re.compile(rf\"^({object_name})_Camera_(\\d+)\\.png\")\n",
    "\n",
    "    for filename in sorted(os.listdir(material_path)):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            obj,  view_number = match.groups()\n",
    "            if obj == object_name:\n",
    "                # Construct the view name as \"Above_3\", \"Ground_1\", etc.\n",
    "                full_view_name = f\"{view_number}\"\n",
    "                image_path = os.path.join(material_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    renders[full_view_name] = image  # Store images under view name\n",
    "\n",
    "    return renders\n",
    "\n",
    "\n",
    "def apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material):\n",
    "    \"\"\"\n",
    "    Applies Canny edge detection to renders for a specific object and material using the provided edgemap_options.\n",
    "\n",
    "    Parameters:\n",
    "        renders (dict): Dictionary containing render images.\n",
    "        edgemap_options (dict): Dictionary containing edge map options.\n",
    "        object_name (str): The object name (e.g., 'Oblique1').\n",
    "        material (str): The material name (e.g., 'Diffuse').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping view indices to their corresponding Canny edge map results.\n",
    "    \"\"\"\n",
    "    edge_maps = {}\n",
    "\n",
    "    for view_name, options in edgemap_options.get(object_name, {}).items():\n",
    "        # Get the edge map for this specific view name\n",
    "        edge_map = renders.get(view_name)  # Get the image by the full view name (e.g., \"Overhead_1\")\n",
    "        \n",
    "        if edge_map is not None:\n",
    "            # Apply Canny edge map with the options\n",
    "            edge_maps[view_name] = canny_edge_map(edge_map, options)\n",
    "\n",
    "    return edge_maps\n",
    "\n",
    "def plot_edge_maps(edge_maps):\n",
    "    \"\"\"\n",
    "    Plots the edge maps in a grid with minimal white space and titles indicating the view names.\n",
    "\n",
    "    Parameters:\n",
    "        edge_maps (dict): A dictionary mapping view names to their corresponding edge map results.\n",
    "    \"\"\"\n",
    "    # Calculate number of rows and columns based on the number of edge maps\n",
    "    num_views = len(edge_maps)\n",
    "    rows = (num_views + 1) // 2  # N rows, 2 columns\n",
    "    cols = 2\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, (view_name, edge_map) in enumerate(edge_maps.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(edge_map, cmap='gray')\n",
    "        ax.set_title(view_name)  # Title with the view name (e.g., \"Overhead_1\")\n",
    "        ax.axis('off')  # Remove axis labels and ticks\n",
    "    \n",
    "    # Turn off any unused axes\n",
    "    for ax in axes[num_views:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=1.0)  # Minimal white space\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `edge_maps` is the dictionary containing the edge maps (e.g., {\"Overhead_1\": edge_map1, \"Above_1\": edge_map2, ...})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define edge map options using dictionary comprehension\n",
    "import json\n",
    "renders_path = \"/Users/jeffreyliang/Documents/Honours/Blender/shape_reconstruction/renders\"\n",
    "material = \"Diffuse\"  # Example material\n",
    "object_name = \"Cylinder\"  # Example object name\n",
    "renders = load_renders_for_material(renders_path, material, object_name)\n",
    "print([k for k in renders.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_string = f'''{{\n",
    "  \"{object_name}\": {{\n",
    "        \"0\": [false, 10, 80],\n",
    "        \"1\": [false, 10, 80],\n",
    "        \"2\": [false, 10, 80],\n",
    "        \"3\": [false, 10, 80],\n",
    "        \"4\": [false, 10, 80],\n",
    "        \"5\": [true, 50, 796],\n",
    "        \"6\": [false, 10, 80],\n",
    "        \"7\": [false, 10, 80],\n",
    "        \"8\": [false, 10, 80],\n",
    "        \"9\": [false, 10, 80],\n",
    "        \"10\": [false, 10, 80],\n",
    "        \"11\": [false, 10, 80]\n",
    "        }}\n",
    "}}'''.replace(\"false\", \"false\")  # leave as is, JSON uses `false`\n",
    "\n",
    "edgemap_options = json.loads(json_string)\n",
    "\n",
    "# edgemap_options = defaultdict(lambda: (False, 15, 200))  # Default option: (False, 0, 0) for equalisation, low, high thresholds\n",
    "\n",
    "# Apply Canny edge detection to the filtered renders based on material and object\n",
    "edge_maps = apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material)\n",
    "print(len(edge_maps))\n",
    "\n",
    "plot_edge_maps(edge_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_options = {\n",
    "    \"Overhead_0\": (True, 15, 250),  # (hist_eq=True, low_thresh=15, high_thresh=250)\n",
    "\n",
    "    \"Above_0\": (True, 25, 250),\n",
    "    \"Above_1\": (True, 25, 250),\n",
    "    \"Above_2\": (False, 15, 200),\n",
    "    \"Above_3\": (True, 20, 240),\n",
    "    \"Above_4\": (True, 25, 250),\n",
    "    \"Above_5\": (True, 25, 250),\n",
    "    \"Above_6\": (True, 25, 250),\n",
    "\n",
    "    \"Ground_0\": (False, 10, 150),\n",
    "    \"Ground_1\": (False, 10, 150),\n",
    "    \"Ground_2\": (True, 18, 210),\n",
    "    \"Ground_3\": (True, 12, 180),\n",
    "    \"Ground_4\": (False, 10, 150),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = [f\"Icosphere{i}\" for i in range(9)]\n",
    "material = \"\"  # Set your actual material name here\n",
    "view_name = \"Ground_0\"\n",
    "renders_path = \"/Users/jeffreyliang/Documents/Honours/Blender/translation/renders\"\n",
    "\n",
    "# Set common Canny parameters\n",
    "canny_params = (False, 15, 100)\n",
    "\n",
    "all_edge_maps = {}\n",
    "\n",
    "for obj in object_names:\n",
    "    renders = load_renders_for_material(renders_path, material, obj)\n",
    "    if view_name in renders:\n",
    "        img = renders[view_name]\n",
    "        edge_map = canny_edge_map(img, canny_params)\n",
    "        all_edge_maps[obj] = edge_map\n",
    "    else:\n",
    "        print(f\"{view_name} not found for {obj}\")\n",
    "\n",
    "# Plot all objects' Ground_0 edge maps\n",
    "def plot_objects_edge_maps(edge_maps):\n",
    "    num_objects = len(edge_maps)\n",
    "    cols = 3\n",
    "    rows = (num_objects + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 8, rows * 5))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (obj_name, edge_map) in enumerate(edge_maps.items()):\n",
    "        axes[idx].imshow(edge_map, cmap='gray')\n",
    "        axes[idx].set_title(obj_name)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    for ax in axes[num_objects:]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_objects_edge_maps(all_edge_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
