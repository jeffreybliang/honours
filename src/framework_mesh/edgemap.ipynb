{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_matrices(path, matrix_types=None):\n",
    "    \"\"\"\n",
    "    Loads camera matrices from .npy files in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the directory containing camera matrix files.\n",
    "        matrix_types (set or list, optional): Specifies which matrix types to load (e.g., {'K', 'RT'}).\n",
    "        If None, all available matrices ('K', 'RT', 'P') will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping camera numbers to their respective matrices.\n",
    "    \"\"\"\n",
    "    cameras = defaultdict(dict)\n",
    "    file_pattern = re.compile(r\"^Camera_(\\d+)_(K|RT|P)\\.npy$\")\n",
    "    \n",
    "    if matrix_types is not None:\n",
    "        matrix_types = set(matrix_types)  # Ensure it's a set for quick lookup\n",
    "    \n",
    "    for filename in sorted(os.listdir(path)):  # Sort filenames alphabetically\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            cam_number, matrix_type = match.groups()\n",
    "            cam_number = int(cam_number)  # Convert camera number to integer\n",
    "            if matrix_types is None or matrix_type in matrix_types:\n",
    "                filepath = os.path.join(path, filename)\n",
    "                cameras[cam_number][matrix_type] = torch.tensor(np.load(filepath))\n",
    "    \n",
    "    return cameras\n",
    "\n",
    "def load_renders(renders_path):\n",
    "    renders = defaultdict(dict)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\\.png\")\n",
    "    for filename in sorted(os.listdir(renders_path), key=lambda x: (re.match(pattern, x).group(1), int(re.match(pattern, x).group(2))) if re.match(pattern, x) else (x, float('inf'))):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            word, number = match.groups()\n",
    "            number = int(number)  # Convert number to integer for sorting\n",
    "\n",
    "            image_path = os.path.join(renders_path, filename)\n",
    "            image = cv2.imread(image_path)  # Load image using OpenCV\n",
    "            if image is not None:\n",
    "                renders[word][number] = image  # Store image in the nested dictionary\n",
    "\n",
    "    return renders\n",
    "\n",
    "def get_projmats_and_edgemap_info(view_idx, target_mesh: str, matrices, edgemaps, edgemaps_len):\n",
    "    \"\"\"\n",
    "    Retrieves the projection matrices and target edgemap information for the specified view indices and target mesh.\n",
    "\n",
    "    Parameters:\n",
    "        view_idx (list): List of indices for which to retrieve projection matrices and edgemaps.\n",
    "        target_mesh (str): The target mesh name (e.g., 'balloon') to extract edgemaps and lengths for.\n",
    "        matrices (dict): Dictionary containing camera matrices.\n",
    "        edgemaps (dict): Dictionary containing edgemaps for various meshes.\n",
    "        edgemaps_len (dict): Dictionary containing the lengths of the edgemaps for each mesh.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the projection matrices (torch.Tensor) and the target edgemap information (tuple of torch.Tensors).\n",
    "    \"\"\"\n",
    "    # Get the projection matrices for the specified view indices\n",
    "    projmats = torch.stack([matrices[view_idx[i]][\"P\"] for i in range(len(view_idx))])\n",
    "\n",
    "    # Get the target edgemaps for the specified target mesh\n",
    "    tgt_edgemaps = torch.nn.utils.rnn.pad_sequence([edgemaps[target_mesh][i] for i in view_idx], batch_first=True, padding_value=0.0)\n",
    "    tgt_edgemaps_len = torch.tensor([edgemaps_len[target_mesh][i] for i in view_idx])\n",
    "\n",
    "    # Pack the target edgemaps and their lengths\n",
    "    tgt_edgemap_info = (tgt_edgemaps, tgt_edgemaps_len)\n",
    "\n",
    "    return projmats, tgt_edgemap_info\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    # edge_map = cv2.Canny(img_greyscale, threshold1=20, threshold2=100)\n",
    "    # edge_map = cv2.Canny(img_greyscale, threshold1=15, threshold2=250)\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "\n",
    "def visualize_edges(renders, edgemap_options, target_mesh):\n",
    "    num_views = 12  # assuming 12 views per mesh\n",
    "    rows, cols = 6, 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    mesh_renders = renders.get(target_mesh, {})\n",
    "    mesh_options = edgemap_options.get(target_mesh, {})\n",
    "\n",
    "    for view_idx in range(num_views):\n",
    "        row, col = divmod(view_idx, cols)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        img = mesh_renders.get(view_idx)\n",
    "        if img is not None and str(view_idx) in mesh_options:\n",
    "            edge_option = mesh_options[str(view_idx)]\n",
    "            edges = canny_edge_map(img, edge_option)\n",
    "            ax.imshow(edges, cmap='gray')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "        ax.set_title(f\"View {view_idx}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Canny edges for mesh: {target_mesh}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open(\"/Users/jeffreyliang/Documents/Honours/honours/src/experiments/skyconfig_local.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "mesh_dir = cfg[\"paths\"][\"mesh_dir\"]\n",
    "mesh_res = cfg[\"paths\"][\"mesh_res\"]\n",
    "renders_path = cfg[\"paths\"][\"renders_path\"]\n",
    "matrices_path = cfg[\"paths\"][\"matrices_path\"]\n",
    "\n",
    "# Fix edgemap_options to be a dictionary where keys are mesh names and values are dictionaries of view indices\n",
    "edgemap_options = {mesh[\"name\"]: {str(k): v for k, v in mesh[\"edgemap_options\"].items()} for mesh in cfg[\"meshes\"]}\n",
    "\n",
    "# Load renders and camera matrices\n",
    "renders = load_renders(renders_path)\n",
    "matrices = load_camera_matrices(matrices_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_edges(renders, edgemap_options, target_mesh=\"balloon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c5e5b74b02413c78a36d1154fc177d57260c9d451ea89539c66d8b3bbae5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
