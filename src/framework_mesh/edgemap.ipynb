{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_matrices(path, matrix_types=None):\n",
    "    \"\"\"\n",
    "    Loads camera matrices from .npy files in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the directory containing camera matrix files.\n",
    "        matrix_types (set or list, optional): Specifies which matrix types to load (e.g., {'K', 'RT'}).\n",
    "        If None, all available matrices ('K', 'RT', 'P') will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping camera numbers to their respective matrices.\n",
    "    \"\"\"\n",
    "    cameras = defaultdict(dict)\n",
    "    file_pattern = re.compile(r\"^Camera_(\\d+)_(K|RT|P)\\.npy$\")\n",
    "    \n",
    "    if matrix_types is not None:\n",
    "        matrix_types = set(matrix_types)  # Ensure it's a set for quick lookup\n",
    "    \n",
    "    for filename in sorted(os.listdir(path)):  # Sort filenames alphabetically\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            cam_number, matrix_type = match.groups()\n",
    "            cam_number = int(cam_number)  # Convert camera number to integer\n",
    "            if matrix_types is None or matrix_type in matrix_types:\n",
    "                filepath = os.path.join(path, filename)\n",
    "                cameras[cam_number][matrix_type] = torch.tensor(np.load(filepath))\n",
    "    \n",
    "    return cameras\n",
    "\n",
    "def load_renders(renders_path):\n",
    "    renders = defaultdict(dict)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\\.png\")\n",
    "    for filename in sorted(os.listdir(renders_path), key=lambda x: (re.match(pattern, x).group(1), int(re.match(pattern, x).group(2))) if re.match(pattern, x) else (x, float('inf'))):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            word, number = match.groups()\n",
    "            number = int(number)  # Convert number to integer for sorting\n",
    "\n",
    "            image_path = os.path.join(renders_path, filename)\n",
    "            image = cv2.imread(image_path)  # Load image using OpenCV\n",
    "            if image is not None:\n",
    "                renders[word][number] = image  # Store image in the nested dictionary\n",
    "\n",
    "    return renders\n",
    "\n",
    "def get_projmats_and_edgemap_info(view_idx, target_mesh: str, matrices, edgemaps, edgemaps_len):\n",
    "    \"\"\"\n",
    "    Retrieves the projection matrices and target edgemap information for the specified view indices and target mesh.\n",
    "\n",
    "    Parameters:\n",
    "        view_idx (list): List of indices for which to retrieve projection matrices and edgemaps.\n",
    "        target_mesh (str): The target mesh name (e.g., 'balloon') to extract edgemaps and lengths for.\n",
    "        matrices (dict): Dictionary containing camera matrices.\n",
    "        edgemaps (dict): Dictionary containing edgemaps for various meshes.\n",
    "        edgemaps_len (dict): Dictionary containing the lengths of the edgemaps for each mesh.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the projection matrices (torch.Tensor) and the target edgemap information (tuple of torch.Tensors).\n",
    "    \"\"\"\n",
    "    # Get the projection matrices for the specified view indices\n",
    "    projmats = torch.stack([matrices[view_idx[i]][\"P\"] for i in range(len(view_idx))])\n",
    "\n",
    "    # Get the target edgemaps for the specified target mesh\n",
    "    tgt_edgemaps = torch.nn.utils.rnn.pad_sequence([edgemaps[target_mesh][i] for i in view_idx], batch_first=True, padding_value=0.0)\n",
    "    tgt_edgemaps_len = torch.tensor([edgemaps_len[target_mesh][i] for i in view_idx])\n",
    "\n",
    "    # Pack the target edgemaps and their lengths\n",
    "    tgt_edgemap_info = (tgt_edgemaps, tgt_edgemaps_len)\n",
    "\n",
    "    return projmats, tgt_edgemap_info\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "\n",
    "def visualize_edges(renders, edgemap_options, target_mesh):\n",
    "    num_views = 12  # assuming 12 views per mesh\n",
    "    rows, cols = 6, 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    mesh_renders = renders.get(target_mesh, {})\n",
    "    mesh_options = edgemap_options.get(target_mesh, {})\n",
    "\n",
    "    for view_idx in range(num_views):\n",
    "        row, col = divmod(view_idx, cols)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        img = mesh_renders.get(view_idx)\n",
    "        if img is not None and str(view_idx) in mesh_options:\n",
    "            edge_option = mesh_options[str(view_idx)]\n",
    "            edges = canny_edge_map(img, edge_option)\n",
    "            ax.imshow(edges, cmap='gray')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "        ax.set_title(f\"View {view_idx}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Canny edges for mesh: {target_mesh}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open(\"/Users/jeffreyliang/Documents/Honours/honours/src/experiments/skyconfig_local.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "mesh_dir = cfg[\"paths\"][\"mesh_dir\"]\n",
    "mesh_res = cfg[\"paths\"][\"mesh_res\"]\n",
    "renders_path = cfg[\"paths\"][\"renders_path\"]\n",
    "matrices_path = cfg[\"paths\"][\"matrices_path\"]\n",
    "\n",
    "# Fix edgemap_options to be a dictionary where keys are mesh names and values are dictionaries of view indices\n",
    "edgemap_options = {mesh[\"name\"]: {str(k): v for k, v in mesh[\"edgemap_options\"].items()} for mesh in cfg[\"meshes\"]}\n",
    "\n",
    "# Load renders and camera matrices\n",
    "renders = load_renders(renders_path)\n",
    "matrices = load_camera_matrices(matrices_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_edges(renders, edgemap_options, target_mesh=\"balloon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Material folder /Users/jeffreyliang/Documents/Honours/Blender/oblique/renders/Diffuse not found!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch, re, os, cv2\n",
    "from collections import defaultdict\n",
    "from cv2.typing import MatLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def canny_edge_map(img: MatLike, options):\n",
    "    equalise, t1, t2 = options\n",
    "    # convert to grayscale\n",
    "    img_greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img_greyscale = cv2.GaussianBlur(img_greyscale, (3,3), 1)\n",
    "    if equalise:\n",
    "        img_greyscale = cv2.equalizeHist(img_greyscale)\n",
    "    # apply edge detection\n",
    "    edge_map = cv2.Canny(img_greyscale, threshold1=t1, threshold2=t2)\n",
    "    # return edge map\n",
    "    return edge_map\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_renders_for_material(renders_path, material, object_name):\n",
    "    \"\"\"\n",
    "    Loads renders for a specific object and material by navigating the material folder.\n",
    "    \n",
    "    Parameters:\n",
    "        renders_path (str): Path to the directory containing the render images.\n",
    "        material (str): Material name to filter the renders (e.g., \"Diffuse\").\n",
    "        object_name (str): The object name (e.g., \"Oblique6\") to filter the renders.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping view names (\"Above_3\", \"Ground_1\", etc.) to their corresponding images.\n",
    "    \"\"\"\n",
    "    renders = defaultdict(list)\n",
    "    material_path = os.path.join(renders_path, material)  # Construct path for the material folder\n",
    "    \n",
    "    if not os.path.exists(material_path):\n",
    "        print(f\"Material folder {material_path} not found!\")\n",
    "        return renders\n",
    "\n",
    "    # Regex pattern: Extract Object<number> and View_<number>, ignoring _Cam_.\n",
    "    # Example: Oblique6_Cam_Above_3.png -> object_name: Oblique6, view_name: Above_3\n",
    "    pattern = re.compile(rf\"^({object_name})_Cam_(Overhead|Above|Ground)_(\\d+)\\.png\")\n",
    "\n",
    "    for filename in sorted(os.listdir(material_path)):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            obj, view_type, view_number = match.groups()\n",
    "            if obj == object_name:\n",
    "                # Construct the view name as \"Above_3\", \"Ground_1\", etc.\n",
    "                full_view_name = f\"{view_type}_{view_number}\"\n",
    "                image_path = os.path.join(material_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    renders[full_view_name] = image  # Store images under view name\n",
    "\n",
    "    return renders\n",
    "\n",
    "\n",
    "def apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material):\n",
    "    \"\"\"\n",
    "    Applies Canny edge detection to renders for a specific object and material using the provided edgemap_options.\n",
    "\n",
    "    Parameters:\n",
    "        renders (dict): Dictionary containing render images.\n",
    "        edgemap_options (dict): Dictionary containing edge map options.\n",
    "        object_name (str): The object name (e.g., 'Oblique1').\n",
    "        material (str): The material name (e.g., 'Diffuse').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping view indices to their corresponding Canny edge map results.\n",
    "    \"\"\"\n",
    "    edge_maps = {}\n",
    "\n",
    "    for view_name, options in edgemap_options.get(object_name, {}).items():\n",
    "        # Get the edge map for this specific view name\n",
    "        edge_map = renders.get(view_name)  # Get the image by the full view name (e.g., \"Overhead_1\")\n",
    "        \n",
    "        if edge_map is not None:\n",
    "            # Apply Canny edge map with the options\n",
    "            edge_maps[view_name] = canny_edge_map(edge_map, options)\n",
    "\n",
    "    return edge_maps\n",
    "\n",
    "def plot_edge_maps(edge_maps):\n",
    "    \"\"\"\n",
    "    Plots the edge maps in a grid with minimal white space and titles indicating the view names.\n",
    "\n",
    "    Parameters:\n",
    "        edge_maps (dict): A dictionary mapping view names to their corresponding edge map results.\n",
    "    \"\"\"\n",
    "    # Calculate number of rows and columns based on the number of edge maps\n",
    "    num_views = len(edge_maps)\n",
    "    rows = (num_views + 1) // 2  # N rows, 2 columns\n",
    "    cols = 2\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array to easily index it\n",
    "    \n",
    "    for idx, (view_name, edge_map) in enumerate(edge_maps.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(edge_map, cmap='gray')\n",
    "        ax.set_title(view_name)  # Title with the view name (e.g., \"Overhead_1\")\n",
    "        ax.axis('off')  # Remove axis labels and ticks\n",
    "    \n",
    "    # Turn off any unused axes\n",
    "    for ax in axes[num_views:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=1.0)  # Minimal white space\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `edge_maps` is the dictionary containing the edge maps (e.g., {\"Overhead_1\": edge_map1, \"Above_1\": edge_map2, ...})\n",
    "\n",
    "\n",
    "renders_path = \"/Users/jeffreyliang/Documents/Honours/Blender/oblique/renders\"\n",
    "material = \"Diffuse\"  # Example material\n",
    "object_name = \"Oblique2\"  # Example object name\n",
    "renders = load_renders_for_material(renders_path, material, object_name)\n",
    "print([k for k in renders.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m edge_maps = apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(edge_maps))\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mplot_edge_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_maps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mplot_edge_maps\u001b[39m\u001b[34m(edge_maps)\u001b[39m\n\u001b[32m     98\u001b[39m cols = \u001b[32m2\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Create the plot\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m fig, axes = \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m axes = axes.flatten()  \u001b[38;5;66;03m# Flatten the axes array to easily index it\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, (view_name, edge_map) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(edge_maps.items()):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv/lib/python3.11/site-packages/matplotlib/pyplot.py:1776\u001b[39m, in \u001b[36msubplots\u001b[39m\u001b[34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[39m\n\u001b[32m   1631\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1632\u001b[39m \u001b[33;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[32m   1633\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1773\u001b[39m \n\u001b[32m   1774\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1775\u001b[39m fig = figure(**fig_kw)\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m axs = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m=\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv/lib/python3.11/site-packages/matplotlib/figure.py:918\u001b[39m, in \u001b[36mFigureBase.subplots\u001b[39m\u001b[34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[39m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mwidth_ratios\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must not be defined both as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    915\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33mparameter and as key in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgridspec_kw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    916\u001b[39m     gridspec_kw[\u001b[33m'\u001b[39m\u001b[33mwidth_ratios\u001b[39m\u001b[33m'\u001b[39m] = width_ratios\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m gs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_gridspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[32m    920\u001b[39m                   subplot_kw=subplot_kw)\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv/lib/python3.11/site-packages/matplotlib/figure.py:1600\u001b[39m, in \u001b[36mFigureBase.add_gridspec\u001b[39m\u001b[34m(self, nrows, ncols, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[33;03mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m \n\u001b[32m   1597\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m _ = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m gs = \u001b[43mGridSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv/lib/python3.11/site-packages/matplotlib/gridspec.py:363\u001b[39m, in \u001b[36mGridSpec.__init__\u001b[39m\u001b[34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28mself\u001b[39m.hspace = hspace\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.figure = figure\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv/lib/python3.11/site-packages/matplotlib/gridspec.py:48\u001b[39m, in \u001b[36mGridSpecBase.__init__\u001b[39m\u001b[34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m----------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nrows, Integral) \u001b[38;5;129;01mor\u001b[39;00m nrows <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     49\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols <= \u001b[32m0\u001b[39m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Number of rows must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define edge map options using dictionary comprehension\n",
    "edgemap_options = {\n",
    "    object_name: {\n",
    "        \"Above_0\":      (False, 15, 220),\n",
    "        \"Above_1\":      (False, 15, 220),\n",
    "        \"Above_2\":      (False, 15, 220),\n",
    "        \"Above_3\":      (False, 15, 220),\n",
    "        \"Above_4\":      (False, 15, 220),\n",
    "        \"Above_5\":      (False, 6 , 100),\n",
    "        \"Above_6\":      (False, 15, 220),    \n",
    "        \"Ground_0\":     (False, 6,  100),\n",
    "        \"Ground_1\":     (False, 15,  30),\n",
    "        \"Ground_2\":     (False, 15, 30 ),\n",
    "        \"Ground_3\":     (False, 15, 40 ),\n",
    "        \"Ground_4\":     (False, 15, 220),\n",
    "        \"Overhead_0\":   (False, 15, 220), # (hist_eq=True, low_thresh=15, high_thresh=250)\n",
    "    }\n",
    "}\n",
    "\n",
    "# edgemap_options = defaultdict(lambda: (False, 15, 200))  # Default option: (False, 0, 0) for equalisation, low, high thresholds\n",
    "\n",
    "# Apply Canny edge detection to the filtered renders based on material and object\n",
    "edge_maps = apply_canny_to_renders_for_material(renders, edgemap_options, object_name, material)\n",
    "print(len(edge_maps))\n",
    "\n",
    "plot_edge_maps(edge_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_options = {\n",
    "    \"Overhead_0\": (True, 15, 250),  # (hist_eq=True, low_thresh=15, high_thresh=250)\n",
    "\n",
    "    \"Above_0\": (True, 25, 250),\n",
    "    \"Above_1\": (True, 25, 250),\n",
    "    \"Above_2\": (False, 15, 200),\n",
    "    \"Above_3\": (True, 20, 240),\n",
    "    \"Above_4\": (True, 25, 250),\n",
    "    \"Above_5\": (True, 25, 250),\n",
    "    \"Above_6\": (True, 25, 250),\n",
    "\n",
    "    \"Ground_0\": (False, 10, 150),\n",
    "    \"Ground_1\": (False, 10, 150),\n",
    "    \"Ground_2\": (True, 18, 210),\n",
    "    \"Ground_3\": (True, 12, 180),\n",
    "    \"Ground_4\": (False, 10, 150),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0daf5460e7e70b267b98b1da0f26ec996de3765b5ed627292ed8b6734d003d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
